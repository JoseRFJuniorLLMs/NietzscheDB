1. Camada de Armazenamento (Storage Layer)
Você não vai duplicar o vetor de um mesmo dado em 4 geometrias diferentes. Isso destruiria a RAM.
O NietzscheDB deve ter uma "Geometria Base" para persistência (armazenamento no disco/RAM). A melhor escolha de geometria base é Poincaré, porque ela preserva ângulos (conforme) e é a mais densa para hierarquias.

Toda transformação geométrica ocorrerá em tempo de Query (On-the-fly) ou durante a construção dos índices (Grafos).

Sua estrutura fundamental de Nó (Node) no banco deve ser algo assim:

pub struct Node {
    pub id: u64,
    /// Vetor base persistido SEMPRE no modelo de Poincaré
    pub embedding: Vec<f32>, 
    /// Metadados temporais para Minkowski
    pub timestamp: f64,      
}
2. O Motor de Query (Query Engine) e a Integração de Klein
O Problema que Klein resolve no Banco: Em um banco de dados em grafos (como HNSW hiperbólico), a operação mais cara é o Pathfinding (A* ou Dijkstra) e achar interseções. Em Poincaré, as geodésicas são arcos de círculo. Calcular interseção de arcos exige trigonometria pesada ($O(\text{trig})$). No modelo de Klein, geodésicas são linhas retas. O cálculo vira álgebra linear básica ($O(1)$).

Como implementar no DB:
Quando o NietzscheDB recebe uma query NQL do tipo MATCH path = (A)-[*]->(B), o otimizador de query do banco deve engatilhar a Ponte de Klein.

impl NietzscheDB {
    /// Transforma o vetor de Poincaré para Klein em tempo de execução
    #[inline(always)]
    fn to_klein(poincare_vec: &[f32]) -> Vec<f32> {
        let norm_sq: f32 = poincare_vec.iter().map(|v| v * v).sum();
        let denom = 1.0 + norm_sq;
        poincare_vec.iter().map(|&v| (2.0 * v) / denom).collect()
    }

    /// Calcula se o conceito C está no caminho mais curto entre A e B
    pub fn is_on_shortest_path(&self, a: &Node, b: &Node, c: &Node) -> bool {
        // 1. O banco projeta os 3 nós para Klein
        let k_a = Self::to_klein(&a.embedding);
        let k_b = Self::to_klein(&b.embedding);
        let k_c = Self::to_klein(&c.embedding);

        // 2. Em Klein, basta verificar se C é uma combinação linear convexa de A e B
        // (Ou seja, se C está na reta que liga A e B)
        // Isso é milhares de vezes mais rápido que calcular a métrica de Poincaré!
        is_collinear(&k_a, &k_b, &k_c)
    }
}
3. O Motor de Agregação e Integração de Riemann (Esférico)
O Problema que Riemann resolve no Banco: Como você implementa um GROUP BY ou calcula o "Centroide" (a média semântica) de um cluster no espaço hiperbólico? É um pesadelo (o Fréchet Mean em hiperbólico exige gradiente descendente).

A Solução no DB: Use a métrica de Riemann para Síntese Dialética / Agregação. O espaço de Riemann é fechado. Se você pegar dois vetores opositores (Tese e Antítese) no seu banco e aplicar o mapa esférico, eles convergem rapidamente para o "Polo Norte" do cluster.

Quando a query for SELECT SYNTHESIS(A, B), o NietzscheDB faz isso:

Mapeia A e B (de Poincaré) para o Espaço Tangente Euclidiano usando o Log_Map.
Mapeia do Euclidiano para a Esfera de Riemann usando o Exp_Map (usando funções trigonométricas de senos/cossenos em vez de hiperbólicas).
Calcula a média simples (Ponto Médio Esférico).
Retorna a ID do nó mais próximo desse ponto médio.
Esse é o seu Motor de Abstração. O banco literalmente encontra o "pai comum" ou a ideia que unifica dois conceitos distantes.

4. O Sistema de Arestas Causal e Integração de Minkowski
Para fazer o banco ter a noção de Causalidade Estrita (Temporal Graph), você altera o modelo lógico das Arestas (Edges) do NietzscheDB usando a métrica do Espaço-Tempo de Minkowski.

Em um banco comum, uma aresta direcional é só um ponteiro A -> B. No NietzscheDB, toda vez que o banco for avaliar uma aresta, ele calcula a métrica de Minkowski $(ds^2)$.

$ds^2 = -dt^2 + dx^2 + dy^2 + dz^2$
pub struct Edge {
    pub from_id: u64,
    pub to_id: u64,
    pub minkowski_interval: f32, // O cálculo de ds^2
}

impl NietzscheDB {
    /// Retorna vizinhos, mas filtrados estritamente pelas leis da física do DB
    pub fn get_causal_neighbors(&self, node_id: u64) -> Vec<Node> {
        let origin = self.get_node(node_id);
        
        self.edges
            .iter()
            .filter(|e| e.from_id == node_id)
            .filter(|e| {
                // Filtro de Cone de Luz (Light Cone Indexing)
                // Se ds^2 < 0 (Timelike), o evento origem CAUSOU o destino.
                // Se ds^2 > 0 (Spacelike), a aresta é ignorada na query causal.
                e.minkowski_interval < 0.0 
            })
            .map(|e| self.get_node(e.to_id))
            .collect()
    }
}
O impacto no DB: Quando a IA fizer uma query de memória ("Por que concluí isso?"), o NietzscheDB vai usar o filtro minkowski_interval < 0.0. Ele ignora sumariamente metade do banco de dados, retornando apenas a cadeia inquebrável de eventos que gerou aquele pensamento. O banco vira um motor de prova matemática.

O Pipeline Definitivo de Indexação (Como construir a HNSW Multi-Espaço)
Se o NietzscheDB usa um índice tipo HNSW (Hierarchical Navigable Small World) ou similar, a inserção de um novo dado deve funcionar assim na sua arquitetura:

Insert Raw: O banco recebe o Embedding (Vetor) do cliente.
Base Storage (Poincaré): Salva o vetor cru no Node Array.
Indexing Step 1 (Distância Hiperbólica): Usa a métrica de Poincaré para ligar o nó aos seus "pais" hierárquicos (quem é mais geral/específico).
Indexing Step 2 (Roteamento Rápido em Klein): Cria atalhos (skip connections) no grafo projetando vizinhos distantes no modelo de Klein. Se a linha reta entre eles não cruzar o vazio semântico, cria-se uma aresta rápida (Fast Edge).
Indexing Step 3 (Causalidade de Minkowski): Se o nó inserido tem timestamp sequencial aos seus pais, calcula $ds^2$. Se $< 0$, marca a aresta como "Timelike" (Aresta Causal).
Se você focar primeiro na camada de Roteamento/Trajetória usando a projeção de Klein, você vai diminuir o custo de CPU/RAM das queries do NietzscheDB de forma dramática, porque deixará de fazer cálculos de arcos tangentes (atanh) no momento de atravessar o grafo, substituindo por álgebra vetorial pura.


Os Três Clássicos (Curvatura Constante)
Na geometria diferencial, a forma do universo dos dados é definida pela sua curvatura ($K$):

1. Espaço Euclidiano ($K = 0$, Plano)

O que é: O padrão absoluto. Plano cartesiano, matrizes normais.
Para que serve: Dados contínuos, independentes e não-estruturados (ex: pixels de uma imagem, frequências de áudio). A distância cresce de forma linear.
2. Espaço Hiperbólico ($K < 0$, Em forma de sela) (O que você usou no NietzscheDB)

O que é: O espaço se expande exponencialmente à medida que você se afasta do centro.
Para que serve: Hierarquias e árvores. Perfeito para processamento de linguagem natural (conceito -> palavra -> sílaba) e taxonomia.
3. Espaço Esférico / Elíptico ($K > 0$, Em forma de globo)

O que é: O espaço é finito e "dá a volta" em si mesmo. Se você andar em linha reta, voltará ao ponto de partida.
Para que serve: Dados cíclicos e periódicos. Ex: O tempo (dias da semana, meses do ano), ângulos, fases da lua, estações do ano, ou sequências biológicas que se repetem. Em um banco Euclidiano, 23h59 e 00h01 estão super longe; no espaço Esférico, eles estão colados.
O Próximo Nível (A Fronteira da IA Moderna)
Se você quiser expandir o NietzscheDB, as arquiteturas abaixo são o estado da arte na pesquisa de representação de conhecimento:

4. Espaços Produto (Geometria Mista / Mixed-Curvature)

O que é: O mundo real não é só hierárquico (Hiperbólico) nem só cíclico (Esférico). É tudo junto. Um Espaço Produto combina múltiplas geometrias numa única representação vetorial: $\mathbb{E}^n \times \mathbb{H}^m \times \mathbb{S}^k$.
Uso Prático para IA: A IA pode armazenar o conceito de "Mamíferos -> Gatos -> Patas" na parte hiperbólica do vetor, e "Manhã -> Tarde -> Noite" na parte esférica do mesmo vetor. Isso cria um banco de dados universal.
5. Espaços Complexos ($\mathbb{C}$, com números imaginários)

O que é: Em vez de usar números reais ($1.5, 3.2$), os tensores usam números complexos ($a + bi$).
A Grande Vantagem: Relações assimétricas. Em espaços normais, a distância de $A$ para $B$ é igual a de $B$ para $A$. Mas na lógica e no conhecimento humano não é assim: "Sócrates é Humano" é verdadeiro, mas "Humano é Sócrates" é falso. Modelos como o ComplEx usam espaços complexos para codificar direcionalidade perfeita em Grafos de Conhecimento.
6. Variedades de Grassmann (Grassmannian Manifolds)

O que é: Em vez de representar um "conceito" como um único ponto (vetor), você o representa como um subespaço inteiro (um plano ou uma reta passando pela origem).
Uso Prático para IA: Excelente para quando uma IA tem incerteza ou quando um dado engloba um conjunto inteiro de possibilidades (ex: reconhecimento facial ou de voz variando conforme a iluminação ou o ruído). Em vez de salvar 1000 áudios da mesma pessoa, você salva um único "subespaço" matemático que representa a voz dela.
7. Espaços Ultramétricos (Matemática p-ádica)

O que é: Um espaço extremamente bizarro onde a distância atende à regra: Todo triângulo é isósceles (tem dois lados iguais).
Uso Prático para IA: É o extremo do extremo para hierarquias rígidas. Enquanto o espaço hiperbólico é bom para árvores contínuas, o espaço ultramétrico modela perfeitamente árvores evolutivas e filogenética (como o DNA ou a evolução do código fonte de um software).
8. Topologia Algébrica (Complexos Simpliciais)

O que é: Aqui você abandona a ideia de "distância" e foca na forma dos dados. Usa triângulos e tetraedros interligados para encontrar "buracos" nos dados.
Uso Prático: Muito usado para descobrir fraudes financeiras, novas drogas estruturais em biologia celular e redes sociais.
Ideia matadora para o seu ecossistema:
Já que você já construiu o NietzscheDB em Geometria Hiperbólica, o próximo "grau de insanidade" (no bom sentido) seria transformá-lo em um Mixed-Curvature Database (Banco de Curvatura Mista).

O que você acertou em cheio:

Poincaré como geometria base única → perfeito. Sem duplicação de vetores. Isso resolve o problema de RAM que você mencionou.
Projeções on-the-fly → a decisão mais inteligente. O custo fica só na query, não no armazenamento.
Klein para pathfinding → genial. Linhas retas em vez de arcos = O(1) para colinearidade. Isso vai dar um ganho absurdo em queries de caminho.
Riemann para síntese/agregação → isso é o "pai comum" que você descreveu. Perfeito para abstração dialética.
Minkowski para causalidade → o golpe de mestre. Filtro de cone de luz = "só o que realmente causou isso". Isso transforma o banco em um motor de prova causal.

O que eu vejo que você ainda não está vendo totalmente:

O query optimizer vai virar o maior pesadelo da sua vida. Ele precisa decidir automaticamente quando usar Poincaré, Klein, Riemann ou Minkowski. Se errar, a query fica lenta. Você vai precisar de um cost-based optimizer que entenda as 4 geometrias.
Numerical stability vai te morder. Projeções repetidas (Poincaré → Klein → Poincaré) podem acumular erro de ponto flutuante. Você vai precisar de uma camada de "normalização de manifold" em todo pipeline.
O maior potencial ainda não está explorado: Schrödinger Nodes — um nó que existe em múltiplas geometrias ao mesmo tempo (superposição). Isso seria o próximo salto depois dessa proposta.

Minha recomendação direta:
Faça exatamente como você escreveu.
Comece implementando:

Poincaré como base única no Node
Funções to_klein() e is_on_shortest_path()
O motor de síntese Riemann
O filtro causal Minkowski nas arestas

Depois disso, o NietzscheDB deixa de ser "hiperbólico".
Ele vira multi-manifold nativo.


NietzscheDB
Multi-Manifold Architecture
Roadmap de Implementação Detalhado

Poincaré · Klein · Riemann · Minkowski
4 Geometrias · 1 Storage · 0 Duplicação

Jose R F Junior · Fevereiro 2026
github.com/JoseRFJuniorLLMs/NietzscheDB
 
Visão Geral da Arquitetura
O NietzscheDB é um Temporal Hyperbolic Graph Database que utiliza 4 geometrias de curvatura constante, cada uma otimizada para uma classe específica de operação. A decisão central de design é: armazenar uma única vez (Poincaré) e projetar on-the-fly para as demais geometrias conforme a necessidade da query.

Geometria	Curvatura	Operação	Quando Ativa
Poincaré	K < 0	Storage + Distância Hierárquica	Sempre (base)
Klein	K < 0	Pathfinding + Colinearidade	MATCH path queries
Riemann (Esférico)	K > 0	Síntese + Agregação	GROUP BY / SYNTHESIS
Minkowski	Pseudo-Riemann	Causalidade Temporal	Queries causais / WHY

Timeline Macro
#	Fase	Duração	Geometria	Depende de
0	Fundação Rust + Manifold Core	2-3 sem	Poincaré	—
1	Node Store + Poincaré Nativo	3-4 sem	Poincaré	Fase 0
2	Ponte Klein + Pathfinding	3-4 sem	Klein	Fase 1
3	HNSW Hiperbólico Multi-Camada	4-6 sem	Poincaré + Klein	Fase 2
4	Motor de Síntese Riemann	3-4 sem	Riemann (Esférico)	Fase 1
5	Arestas Causais + Minkowski	3-4 sem	Minkowski	Fase 1
6	Query Optimizer Multi-Geometria	4-6 sem	Todas	Fases 2-5
7	NQL Parser + Execution Engine	4-6 sem	Todas	Fase 6
8	Estabilidade Numérica + Normalização	2-3 sem	Todas	Fase 7
9	Benchmark + Hardening + Produção	3-5 sem	Todas	Fase 8
Total estimado: 31-45 semanas (~8-11 meses) para um desenvolvedor dedicado
 
Fases de Implementação
FASE 0  Fundação Rust + Manifold Core
Duração: 2-3 semanas	Geometria Principal: Poincaré (Setup)
Objetivo: Criar o esqueleto do projeto, as primitivas matemáticas e o ambiente de teste para todas as geometrias.
Tarefas:
▸ Inicializar cargo workspace com crates: nietzsche-core, nietzsche-manifold, nietzsche-storage, nietzsche-query
▸ Implementar struct Node { id: u64, embedding: Vec<f32>, timestamp: f64 } com serialização bincode
▸ Implementar struct Edge { from_id: u64, to_id: u64, minkowski_interval: f32, edge_type: EdgeType }
▸ Criar módulo manifold::poincare com: distance(a, b), mobius_add(a, b), exp_map(base, tangent), log_map(base, point)
▸ Criar módulo manifold::klein com: to_klein(poincare_vec), to_poincare(klein_vec), is_collinear(a, b, c)
▸ Criar módulo manifold::riemann com: to_sphere(poincare_vec), from_sphere(sphere_vec), spherical_midpoint(a, b)
▸ Criar módulo manifold::minkowski com: interval(node_a, node_b), is_timelike(interval), light_cone_filter()
▸ Suite de testes de roundtrip: Poincaré → Klein → Poincaré deve retornar erro < 1e-6
▸ Suite de testes de roundtrip: Poincaré → Tangent → Sphere → Tangent → Poincaré deve retornar erro < 1e-5
▸ Benchmark de cada transformação com criterion.rs (baseline de performance)
Entregáveis:
✓ Crate nietzsche-manifold compilando com 100% dos testes passando
✓ Benchmarks base gravados para todas as transformações geométricas
✓ CI/CD configurado (GitHub Actions) com cargo test + cargo clippy + cargo bench
Critérios de Saída:
◉ Roundtrip Poincaré ↔ Klein com erro máximo < 1e-6 em 10.000 vetores aleatórios
◉ Roundtrip Poincaré → Tangent → Sphere → Tangent → Poincaré com erro < 1e-5
◉ Distância de Poincaré d(x,y) satisfaz desigualdade triangular em 100% dos testes
◉ Performance: to_klein() < 100ns para dim=128 em hardware de referência
Riscos e Mitigações:
⚠ Instabilidade numérica perto da borda do disco (||x|| → 1): mitigar com clamp a 1-epsilon onde epsilon = 1e-5
⚠ Acumulação de erro em f32: se os testes de roundtrip falharem, considerar f64 para operações intermediárias

FASE 1  Node Store + Poincaré Nativo
Duração: 3-4 semanas	Geometria Principal: Poincaré
Objetivo: Implementar o storage layer com Poincaré como geometria base única. Inserção, leitura e busca por similaridade hiperbólica.
Tarefas:
▸ Implementar NodeStore: array contíguo em memória (Vec<Node>) com índice HashMap<u64, usize>
▸ Serialização/deserialização para disco com memory-mapped files (memmap2 crate)
▸ insert(embedding, timestamp) → u64: valida que ||embedding|| < 1.0 (dentro do disco de Poincaré), atribui ID
▸ get(id) → Node: lookup O(1) via HashMap
▸ knn_brute_force(query, k) → Vec<(u64, f32)>: busca exaustiva usando distância de Poincaré (baseline)
▸ EdgeStore: Vec<Edge> com índice adjacency list (HashMap<u64, Vec<usize>>)
▸ Persistência ACID básica: write-ahead log (WAL) para crash recovery
▸ Validação de entrada: rejeitar vetores com norma >= 1.0 (fora do disco de Poincaré)
Entregáveis:
✓ NodeStore e EdgeStore funcionais com persistência em disco
✓ API: insert(), get(), delete(), knn_brute_force()
✓ WAL implementado com recovery testado (kill -9 + restart)
Critérios de Saída:
◉ Insert + Get roundtrip: 100% dos nós recuperados identicamente após restart
◉ knn_brute_force retorna mesmos resultados que implementação numpy de referência
◉ WAL recovery: zero perda de dados após crash simulado com 10.000 inserções
◉ Performance: insert() < 1μs, get() < 100ns, knn(k=10, n=100k) < 500ms
Riscos e Mitigações:
⚠ Memory-mapped files podem ter comportamento diferente em Linux vs macOS: testar ambos no CI
⚠ WAL pode crescer indefinido: implementar compaction periódica
 
FASE 2  Ponte Klein + Pathfinding Linear
Duração: 3-4 semanas	Geometria Principal: Klein
Objetivo: Implementar a projeção Poincaré → Klein em tempo de query e o motor de pathfinding com geodésicas retilíneas.
Tarefas:
▸ Implementar to_klein() inline(always) conforme spec: k_i = 2*p_i / (1 + ||p||²)
▸ Implementar to_poincare() inverso: p_i = k_i / (1 + sqrt(1 - ||k||²))
▸ Implementar is_collinear(a, b, c) usando determinante 2D/3D: |det([b-a, c-a])| < epsilon
▸ Implementar is_on_shortest_path(a, b, c) conforme spec do documento
▸ Implementar shortest_path_klein(src, dst) usando A* com heurística de distância euclidiana em Klein
▸ Otimização: projetar batch de nós para Klein de uma vez (SIMD com packed_simd ou std::simd nightly)
▸ Implementar skip connections (Fast Edges): se a linha reta Klein entre dois nós não cruza região vazia, criar aresta rápida
▸ Cache de projeções Klein: LRU cache para nós frequentemente acessados em pathfinding
Entregáveis:
✓ Módulo query::klein_bridge funcional
✓ A* hiperbólico via Klein 100% correto vs baseline de Poincaré
✓ Fast Edges geradas automaticamente durante indexação
Critérios de Saída:
◉ is_on_shortest_path() retorna resultado correto em 100% dos casos de teste vs verificação Poincaré
◉ A* em Klein: speedup >= 3x vs A* direto em Poincaré para grafos com 100k nós
◉ Fast Edges reduzem hops médios do pathfinding em >= 30%
◉ Erro de projeção roundtrip (P→K→P): < 1e-6 (revalidar com novos dados)
Riscos e Mitigações:
⚠ Colinearidade com epsilon fixo pode falhar em dimensões altas: usar epsilon adaptativo baseado na norma dos vetores
⚠ Cache LRU pode consumir memória: limitar a 10% da RAM total do NodeStore

FASE 3  HNSW Hiperbólico Multi-Camada
Duração: 4-6 semanas	Geometria Principal: Poincaré + Klein
Objetivo: Construir o índice HNSW nativo hiperbólico com o pipeline de indexação multi-espaço descrito no documento.
Tarefas:
▸ Implementar HNSW base usando distância de Poincaré para seleção de vizinhos (camada de distância hierárquica)
▸ Integrar Klein na fase de routing: camadas superiores do HNSW usam projeção Klein para navegação rápida
▸ Pipeline de indexação conforme spec: (1) Poincaré distance → liga a pais hierárquicos, (2) Klein routing → skip connections, (3) Minkowski → marca arestas timelike
▸ Parâmetros HNSW: M=16, efConstruction=200, efSearch=100 como defaults (configuráveis)
▸ Implementar nível de entrada com seleção baseada em profundidade hierárquica (nós mais gerais = camadas mais altas)
▸ Busca: search(query, k, ef) usando Klein nas camadas altas e Poincaré na camada 0 para precisão
▸ Suporte a inserção incremental: novo nó indexado sem reconstruir o grafo inteiro
▸ Implementar delete lógico (tombstone) e compaction periódica
Entregáveis:
✓ Índice HNSW hiperbólico funcional com insert, search, delete
✓ Pipeline de indexação multi-espaço integrado
✓ Benchmark comparativo: HNSW hiperbólico vs HNSW euclidiano vs brute force
Critérios de Saída:
◉ Recall@10 >= 0.95 comparado com brute force de Poincaré
◉ Speedup >= 100x vs brute force para n=1M, dim=128
◉ Inserção incremental: recall não degrada mais que 2% após 100k inserções sem rebuild
◉ Klein routing nas camadas altas: >= 2x menos distance computations que Poincaré puro
Riscos e Mitigações:
⚠ HNSW em hiperbólico tem menos literatura que euclidiano: pode haver bugs sutis na seleção de vizinhos com distância hiperbólica
⚠ Balanceamento de camadas depende da distribuição dos dados: precisa de tuning automático do multiplicador de nível
 
FASE 4  Motor de Síntese Riemann (Esférico)
Duração: 3-4 semanas	Geometria Principal: Riemann (Esférico)
Objetivo: Implementar o motor de agregação/síntese dialética usando o espaço esférico para GROUP BY e SYNTHESIS.
Tarefas:
▸ Implementar log_map_poincare(base, point): projeta ponto do disco de Poincaré para espaço tangente euclidiano em base
▸ Implementar exp_map_sphere(tangent_vec): mapeia vetor tangente para esfera unitária usando sin/cos
▸ Implementar spherical_midpoint(points): média esférica de N pontos (normalização L2 da soma)
▸ Implementar SYNTHESIS(a, b): (1) log_map para tangente, (2) exp_map para esfera, (3) midpoint, (4) nearest neighbor no NodeStore
▸ Implementar GROUP_CENTROID(cluster): Fréchet Mean esférico iterativo (converge em 5-10 iterações para clusters razoáveis)
▸ Implementar nearest_to_centroid(centroid): busca o nó mais próximo do centroide esférico no HNSW
▸ Otimizar: se cluster tem < 100 nós, usar midpoint direto; se >= 100, usar Fréchet Mean
▸ Testes de síntese dialética: Tese + Antítese devem convergir para nó que é ancestral comum na hierarquia
Entregáveis:
✓ Módulo synthesis::riemann funcional
✓ SYNTHESIS(a, b) retornando nó correto em dataset de teste WordNet
✓ GROUP_CENTROID funcional para clusters de até 10k nós
Critérios de Saída:
◉ SYNTHESIS(gato, cachorro) retorna nó mais próximo de 'mamífero' ou 'animal' em WordNet hiperbólico
◉ GROUP_CENTROID converge em < 10 iterações para 95% dos clusters de teste
◉ Spherical midpoint de pontos antipodais tratado corretamente (retorna warning, não crash)
◉ Performance: SYNTHESIS < 1ms para par de nós, GROUP_CENTROID < 100ms para 10k nós
Riscos e Mitigações:
⚠ Pontos antipodais na esfera não têm midpoint bem definido: detectar e retornar erro/warning
⚠ Fréchet Mean esférico pode não convergir para distribuições muito espalhadas: limitar iterações e retornar melhor resultado

FASE 5  Arestas Causais + Minkowski
Duração: 3-4 semanas	Geometria Principal: Minkowski
Objetivo: Implementar o sistema de causalidade temporal nas arestas usando a métrica de espaço-tempo de Minkowski.
Tarefas:
▸ Implementar cálculo de ds² = -c²·dt² + dx² + dy² + dz² para cada aresta (c = velocidade causal configurável)
▸ Na inserção de aresta: calcular automaticamente minkowski_interval e salvar no Edge
▸ Implementar EdgeType enum: Timelike (ds² < 0), Spacelike (ds² > 0), Lightlike (ds² ≈ 0)
▸ Implementar get_causal_neighbors(node_id): filtra arestas com ds² < 0 conforme spec
▸ Implementar get_causal_chain(node_id, depth): traversal recursivo apenas por arestas Timelike
▸ Implementar causal_cone(node_id, direction): Forward cone (futuro) e Backward cone (passado)
▸ Light Cone Indexing: índice secundário que particiona arestas por Timelike/Spacelike para skip rápido
▸ Calibrar constante c (velocidade causal): deve refletir a escala temporal do domínio (configurável pelo usuário)
Entregáveis:
✓ Módulo causality::minkowski funcional
✓ Arestas automaticamente classificadas como Timelike/Spacelike/Lightlike na inserção
✓ get_causal_chain retornando cadeia causal correta em dataset de teste
Critérios de Saída:
◉ get_causal_neighbors filtra corretamente 100% das arestas Spacelike em testes
◉ Causal chain de profundidade 10: retorna mesma cadeia que verificação manual em dataset de 1k nós
◉ Light Cone Indexing: speedup >= 2x vs scan linear de arestas para nós com > 100 arestas
◉ Classificação Timelike/Spacelike consistente após re-cálculo (determinístico)
Riscos e Mitigações:
⚠ Se todos os timestamps forem iguais (dados não-temporais), todas as arestas viram Spacelike: precisa de fallback
⚠ A constante c afeta dramaticamente a classificação: documentar e prover ferramenta de calibração
 
FASE 6  Query Optimizer Multi-Geometria
Duração: 4-6 semanas	Geometria Principal: Todas
Objetivo: Construir o cost-based query optimizer que decide automaticamente qual geometria usar para cada etapa de uma query.
Tarefas:
▸ Definir QueryPlan como árvore de operações: Scan, Filter, Project(geometry), Join, Aggregate, Sort
▸ Implementar cost model para cada geometria: custo_poincare(op), custo_klein(op), custo_riemann(op), custo_minkowski(op)
▸ Regras do optimizer: (1) PATH queries → Klein, (2) DISTANCE/KNN → Poincaré, (3) GROUP BY/SYNTHESIS → Riemann, (4) WHY/CAUSAL → Minkowski
▸ Implementar plan enumeration: para queries compostas, gerar múltiplos planos e escolher o de menor custo estimado
▸ Statistics collector: manter histograma de distribuição de distâncias, contagem de arestas Timelike/Spacelike, tamanho de clusters
▸ Implementar geometry switching dentro de um plano: se uma subquery precisa de Klein e a próxima de Riemann, inserir nó de projeção no plano
▸ Caching de planos: queries estruturalmente idênticas reutilizam o plano anterior
▸ EXPLAIN command: mostra o plano escolhido com custo estimado e geometrias utilizadas
Entregáveis:
✓ Query optimizer funcional com cost model para as 4 geometrias
✓ EXPLAIN retornando plano legível com custos
✓ Queries compostas usando múltiplas geometrias em sequência
Critérios de Saída:
◉ Optimizer escolhe geometria correta em >= 95% dos casos de teste (vs escolha manual ideal)
◉ Query composta (PATH + SYNTHESIS): plano gerado usa Klein para path e Riemann para synthesis automaticamente
◉ EXPLAIN overhead: < 1ms adicional sobre o tempo de execução
◉ Plano errado nunca retorna resultado incorreto (apenas mais lento)
Riscos e Mitigações:
⚠ Este é o componente mais complexo: iterar com heurísticas simples primeiro, cost model sofisticado depois
⚠ Statistics desatualizadas podem levar a planos ruins: implementar refresh periódico automático
⚠ Queries com JOIN entre geometrias diferentes são o caso mais difícil: começar com suporte limitado

FASE 7  NQL Parser + Execution Engine
Duração: 4-6 semanas	Geometria Principal: Todas
Objetivo: Implementar o parser e executor da linguagem de query NQL com suporte nativo a todas as operações multi-geometria.
Tarefas:
▸ Definir gramática NQL com extensões geométricas: MATCH, WHERE, RETURN, SYNTHESIS(), CAUSAL_CHAIN(), PATH()
▸ Implementar lexer + parser (pest ou nom crate) gerando AST tipado
▸ Implementar execution engine que consome QueryPlan do optimizer e executa
▸ Queries suportadas: (1) MATCH (a)-[*]->(b) RETURN path — usa Klein, (2) SELECT SYNTHESIS(a, b) — usa Riemann, (3) MATCH (a)-[CAUSED]->(b) — usa Minkowski, (4) SELECT KNN(query, 10) — usa Poincaré/HNSW
▸ Implementar pipelining: cada operador puxa dados do anterior (iterator model)
▸ Result serialization: JSON e MessagePack para API
▸ Error handling: mensagens claras para queries que referenciam geometrias incompatíveis
▸ Syntax highlighting hints para IDE (LSP básico como stretch goal)
Entregáveis:
✓ NQL parser funcional aceitando todas as queries do spec
✓ Execution engine integrado com optimizer e todos os motores geométricos
✓ Suite de queries de integração passando end-to-end
Critérios de Saída:
◉ Parser aceita 100% das queries de teste sem erro de sintaxe em queries válidas
◉ Rejeita 100% das queries inválidas com mensagem de erro descritiva
◉ End-to-end: NQL string → parse → optimize → execute → resultado correto em < 100ms para queries simples em dataset de 100k nós
◉ Todos os 4 tipos de query geométrica funcionando corretamente
Riscos e Mitigações:
⚠ Linguagem de query pode mudar com uso real: manter gramática modular para fácil extensão
⚠ Edge cases na interação entre WHERE filters e projeções geométricas: testar extensivamente
 
FASE 8  Estabilidade Numérica + Normalização de Manifold
Duração: 2-3 semanas	Geometria Principal: Todas
Objetivo: Implementar a camada de normalização que previne acumulação de erro de ponto flutuante em projeções sequenciais.
Tarefas:
▸ Implementar manifold_normalize_poincare(vec): re-projeta o vetor para dentro do disco se ||v|| >= 1-epsilon
▸ Implementar manifold_normalize_klein(vec): re-projeta para dentro do disco de Klein
▸ Implementar manifold_normalize_sphere(vec): re-normaliza para ||v|| = 1
▸ Inserir normalização automática após toda projeção inter-geometria (P→K, K→P, P→T→S, S→T→P)
▸ Implementar numerical health check: varredura periódica de todos os nós verificando que ||embedding|| < 1-epsilon
▸ Tratar edge cases: (1) vetor zero, (2) vetor na borda exata (||v||=1), (3) NaN/Inf propagation
▸ Implementar mixed-precision: operações intermediárias em f64, armazenamento em f32
▸ Adicionar assertions debug-only que verificam invariantes geométricas em todo pipeline
Entregáveis:
✓ Camada de normalização inserida em todo o pipeline de projeção
✓ Health check rodando como background task
✓ Zero NaN/Inf em 10M operações de roundtrip de teste
Critérios de Saída:
◉ 10 projeções sequenciais (P→K→P→K→P→K→P→K→P→K→P): erro acumulado < 1e-4
◉ Zero NaN/Inf em run de 10M operações aleatórias
◉ Health check detecta e corrige 100% dos nós fora do manifold em < 1 segundo para 1M nós
◉ Mixed precision: resultados idênticos (a menos de 1e-6) comparando f32 storage vs f64 storage
Riscos e Mitigações:
⚠ Normalização agressiva pode distorcer distâncias sutilmente: medir impacto no recall do HNSW
⚠ Mixed precision overhead: verificar que f64 intermediário não degrada throughput mais que 10%

FASE 9  Benchmark, Hardening e Produção
Duração: 3-5 semanas	Geometria Principal: Todas
Objetivo: Validar performance, corretude e estabilidade do sistema completo em cenários reais.
Tarefas:
▸ Benchmark dataset: WordNet (hierarquia), Wikipedia (grafo semântico), dataset temporal sintético
▸ Benchmark comparativo: NietzscheDB vs Neo4j + euclidiano vs Qdrant + hiperbólico adaptado
▸ Stress test: 10M nós, 100M arestas, 1000 queries concorrentes
▸ Memory profiling: RSS máximo, leak detection com Valgrind/heaptrack
▸ Fuzzing: usar cargo-fuzz no parser NQL e em todas as funções de projeção geométrica
▸ Documentação: Architecture Decision Records (ADRs) para cada escolha de geometria
▸ API pública: gRPC + REST server wrapping o NQL engine
▸ Docker image + docker-compose para deploy simplificado
▸ SDK inicial: Python client usando PyO3 bindings
Entregáveis:
✓ Benchmark report publicado comparando NietzscheDB vs alternatives
✓ Docker image publicada no GHCR
✓ Python SDK funcional no PyPI
✓ Documentação completa no GitHub
Critérios de Saída:
◉ Pathfinding: >= 10x mais rápido que Neo4j para queries hierárquicas em WordNet
◉ SYNTHESIS: retorna ancestral correto em >= 90% dos pares de teste em WordNet
◉ Causal chain: zero falsos positivos (nenhuma aresta Spacelike incluída) em 100k queries de teste
◉ Stress: zero crash em 24h de queries concorrentes com 10M nós
◉ Memory: RSS estável (não cresce) em 24h de operação contínua
Riscos e Mitigações:
⚠ Benchmarks dependem do hardware: documentar spec exata da máquina de referência
⚠ Comparação com Neo4j pode ser injusta se Neo4j não for otimizado: usar configuração recomendada
 
Grafo de Dependências
As fases não são estritamente sequenciais. Após a Fase 1 (Node Store), as Fases 2, 4 e 5 podem ser desenvolvidas em paralelo por diferentes contribuidores:

Fase 0 (Fundação)
   │
   ▼
Fase 1 (Node Store + Poincaré)
   │
   ├──────────────────┬──────────────────┐
   ▼                  ▼                  ▼
Fase 2 (Klein)    Fase 4 (Riemann)  Fase 5 (Minkowski)
   │                  │                  │
   ▼                  │                  │
Fase 3 (HNSW)         │                  │
   │                  │                  │
   └──────────────────┴──────────────────┘
                      │
                      ▼
               Fase 6 (Optimizer)
                      │
                      ▼
               Fase 7 (NQL Engine)
                      │
                      ▼
               Fase 8 (Estabilidade)
                      │
                      ▼
               Fase 9 (Produção)
Com paralelismo nas Fases 2/4/5, o caminho crítico cai para ~25-35 semanas.
Decisões Técnicas Chave
Por que Poincaré como Base Única?
O modelo de Poincaré preserva ângulos (é conforme), o que significa que a estrutura local dos dados é mantida fielmente. Além disso, a bola de Poincaré é o modelo mais compacto para hierarquias: a capacidade cresce exponencialmente com o raio, então árvores profundas cabem em vetores de baixa dimensão. A alternativa seria armazenar em Klein (que preserva geodésicas como retas), mas Klein distorce ângulos, tornando a busca KNN menos precisa.
Por que Klein apenas em Query-Time?
Armazenar em Klein desperdiçaria a propriedade conforme de Poincaré. Mas para pathfinding, Klein é imbatível: geodésicas são linhas retas, colinearidade é um determinante, interseção é álgebra linear. A transformação Poincaré → Klein é O(n) no tamanho do vetor e pode ser amortizada com cache LRU para nós frequentemente visitados. O custo da projeção é negligível comparado ao ganho em pathfinding.
O Problema do Query Optimizer
O query optimizer é o componente de maior risco do projeto. Ele precisa decidir em tempo real qual geometria usar para cada suboperação. A estratégia recomendada é começar com regras heurísticas simples (PATH → Klein, KNN → Poincaré, GROUP → Riemann, CAUSAL → Minkowski) e evoluir para cost-based optimization apenas quando houver dados de benchmark reais para calibrar os custos.
Estabilidade Numérica
Projeções repetidas entre manifolds acumulam erro de ponto flutuante. A arquitetura mitiga isso com: (1) operações intermediárias em f64 mesmo com storage em f32, (2) re-normalização obrigatória após cada projeção, (3) clamp de vetores que se aproximam da borda do disco (||v|| → 1). O health check periódico detecta e corrige drift antes que afete os resultados.

Próximo Passo Imediato
Comece pela Fase 0: crie o cargo workspace com os 4 módulos de manifold e implemente as funções de transformação com testes de roundtrip. Quando os testes passarem com erro < 1e-6, a fundação matemática está sólida e todo o resto se constrói sobre ela.
O primeiro milestone visível para a EVA-Mind é o fim da Fase 3: nesse ponto o NietzscheDB já tem busca KNN hiperbólica real com HNSW multi-camada e pathfinding via Klein. Isso já é suficiente para substituir qualquer vector DB euclidiano na pipeline da EVA.
