<p align="center">
  <img src="img/logo.jpg" alt="NietzscheDB" width="100%"/>
</p>

<h1 align="center">NietzscheDB</h1>

<p align="center">
  <strong>The Multi-Manifold Graph Database for AGI</strong>
</p>

<p align="center">
  <em>Euclidean geometry failed. The world isn't flat, and neither is intelligence.</em>
</p>

<p align="center">
  <a href="https://github.com/JoseRFJuniorLLMs/NietzscheDB/blob/main/LICENSE_AGPLv3.md"><img src="https://badge.fury.io/js/perspektive.svg" alt="perspektive.js"></a>
  <a href="https://www.npmjs.com/package/perspektive"><img src="https://img.shields.io/npm/v/perspektive?color=00d8ff&style=flat-square" alt="NPM Version"></a>
  <a href="https://www.rust-lang.org/"><img src="https://img.shields.io/badge/built%20with-Rust%20nightly-orange.svg" alt="Rust"></a>
  <img src="https://img.shields.io/badge/geometry-Poincar%C3%A9%20%C2%B7%20Klein%20%C2%B7%20Riemann%20%C2%B7%20Minkowski-purple.svg" alt="Multi-Manifold">
  <img src="https://img.shields.io/badge/GPU-cuVS%20CAGRA-76b900.svg" alt="GPU">
  <img src="https://img.shields.io/badge/TPU-PJRT%20Ironwood-4285F4.svg" alt="TPU">
</p>

---

## ğŸ§  The Manifesto: Why Nietzsche?

> *"There are no facts, only interpretations."*  
> â€” Friedrich Nietzsche, **Notebooks**, 1886

Standard databases store data as "static facts" in flat, Euclidean spaces. This is a geometric lie. In high-dimensional intelligence, a concept is defined solely by its relationship to others, and its position is relative to the observer's depth of abstraction.

NietzscheDB implements **Perspektivismus** (Perspectivism) as a database primitive. It abandons the "God's-eye view" of a single flat table for a **Multi-Manifold Architecture**, where the same piece of knowledge can be viewed through different geometric lenses depending on the cognitive need.

---

NietzscheDB is powered by **[perspektive.js](https://github.com/JoseRFJuniorLLMs/perspektive.js)**, the world's most advanced multi-manifold graph renderer. It serves as the AGI's "retina," allowing you to audit, debug, and explore the internal manifolds of the database at 60fps.

<p align="center">
  <img src="https://raw.githubusercontent.com/JoseRFJuniorLLMs/perspektive.js/main/img/logo.gif" alt="Visual Cortex" width="600px"/>
</p>

### Advanced Auditing Tools:
- â³ **Causal Scrubber (Minkowski Time Machine)**: Scrub through the database history. Watch nodes dissolve and reform as you rewind the chain of causal reasoning.
- ğŸ”€ **Counterfactual UI**: Drag-and-drop nodes to create "What-If" hypotheses. Generate ephemeral edges to simulate new realities without mutating the core graph.
- ğŸŒŒ **Fractal Viewport**: Infinite zoom into the PoincarÃ© boundary. As the brain grows, the renderer streams new subgraphs dynamically (Google Maps for Memory).
- âš›ï¸ **Probability Clouds**: Volumetric GLSL raymarching visualize quantum fidelity and semantic arousal on the Bloch Sphere.

---

## ğŸŒ The 4 Geometric Perspectives

NietzscheDB doesn't just store data; it projects it across four distinct manifolds to solve specific AGI problems:

| Lens | Geometry | Manifold | AGI Role |
|---|---|---|---|
| ğŸŒŒ **Hierarchy** | PoincarÃ© Ball | Hyperbolic (K < 0) | **Abstraction Level**: Depth = Generality. Center = Foundation, Border = Detail. |
| ğŸ§­ **Logic** | Klein Model | Hyperbolic (K < 0) | **Reasoning**: Semantic paths are straight lines. O(1) collinearity checks. |
| â³ **Causality** | Minkowski | Lorentzian (Flat) | **Auditability**: Light cone filters ensure effect never precedes cause. |
| âš›ï¸ **Synthesis** | Riemann Sphere | Spherical (K > 0) | **Dialectics**: Where thesis and antithesis merge into a shallower, more abstract point. |

---

## ğŸš€ Key Features

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚           MULTI-MANIFOLD GRAPH DATABASE                â”‚
â”‚    PoincarÃ© Â· Klein Â· Riemann Â· Minkowski              â”‚
â”‚                                                         â”‚
â”‚   Â· Perspektive.js 0.1.3 native visual cortex          â”‚
â”‚   Â· Causal Scrubber (Minkowski Time Machine)           â”‚
â”‚   Â· Counterfactual UI (Speculative Reasoning)          â”‚
â”‚   Â· Autonomous fractal growth via L-System rules        â”‚
â”‚   Â· Multi-scale search via hyperbolic heat diffusion    â”‚
â”‚   Â· Active memory reconsolidation during sleep cycles   â”‚
â”‚   Â· GPU (cuVS) / TPU (PJRT) accelerated vector search   â”‚
â”‚   Â· Hegelian Dialectic Engine (automated synthesis)     â”‚
â”‚   Â· Code-as-Data: NQL queries as activatable nodes      â”‚
â”‚   Â· SchrÃ¶dinger Edges (probabilistic context collapse)  â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**NietzscheDB closes the interpretability gap.** It allows you to see the abyss â€” and ensures that when you look into the database, the database (geometrically) looks back at you.

---

## ğŸ§  Neuro-Symbolic Intelligence: Beyond Vectors

NietzscheDB is a **Neuro-Symbolic** engine. It bridges the gap between neural perception (embeddings/GNNs) and symbolic reasoning (graph topology/Manifolds).

### Integrated ML Models:
- ğŸ•¸ï¸ **Neural Foundation (GNN)**: A native Graph Neural Network that learns node representations directly on the hyperbolic manifold, optimized for high-dimensional hierarchical relationships.
- ğŸ¯ **Value Network**: A predictive model that estimates the "Energy" and "Will to Power" of nodes, identifying elite concepts and guiding the autonomous pruning process.
- ğŸ§ª **Zero-Data Pipeline**: Built-in orchestration to generate synthetic clinical data, distill it through classical algorithms, and train the neural core without external data dependencies.
- ğŸŒ«ï¸ **Diffusion Engine**: Real-time Pregel-like heat kernel propagation that simulates neural activation across the graph, modulated by emotional valence and arousal.

---

- Abstract concepts naturally live near the center of the PoincarÃ© ball
- Specific memories live near the boundary
- Hierarchical distance is intrinsic â€” not encoded, but *geometric*
- The knowledge graph grows and prunes itself like a fractal organism
- The system "sleeps" and reconsolidates its own memory topology
- An autonomous evolution cycle (Zaratustra) propagates energy, captures temporal echoes, and identifies elite nodes
- Causal relationships are identified via Minkowski intervals (dsÂ² < 0 = timelike = causal)

It is a fork of **[YARlabs/hyperspace-db](https://github.com/YARlabs/hyperspace-db)** â€” extended from a hyperbolic HNSW vector database into the world's first **multi-manifold graph database** with a full graph engine, query language, L-System growth, 4 non-Euclidean geometries, GPU/TPU acceleration, graph algorithms, cluster support, and an autonomous sleep/reconsolidation cycle.

---

## Why EVA Needs This

| Problem | Standard Vector DB | NietzscheDB |
|---|---|---|
| **Hierarchy** | Flat â€” same depth for all | Geometric â€” depth = abstraction level (PoincarÃ©) |
| **Logic/Reasoning** | Cosine similarity only | Multi-manifold (Klein Model) + straight-line semantic paths |
| **Causal Auditability** | None | Minkowski light cone filters (WHY / What-If) |
| **Observability** | JSON Logs / Dashboards | **Perspektive.js Visual Cortex** (60fps multi-manifold auditing) |
| **Hypothetical Reasoning**| Manual data cloning | **Counterfactual UI** (ShadowGraph overlays) |
| **Temporal Scrubbing** | Time filtering | **Causal Scrubber** (Minkowski Time Machine) |
| **Knowledge Growth** | Static inserts | L-System self-organizing fractal growth |
| **Memory Pruning** | Manual/TTL deletion | Hausdorff dimension self-pruning |
| **Consolidation** | No concept | Sleep Cycles (Riemannian reconsolidation) |
| **Conflict Resolution** | Last-write-wins | Hegelian Dialectic Engine (automated synthesis) |
| **Query Language** | k-NN / SQL / GraphQL | NQL (Multi-manifold, Diffusion, Speculative Dream) |
| **Hardware** | Generic CPU/GPU | cuVS (GPU) + PJRT Ironwood (TPU) backends |
| **Integration** | REST API | MCP (Model Context Protocol) + gRPC + REST |


---

## Architecture

NietzscheDB is built as a **Rust nightly workspace** with 38 crates in two layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         NietzscheDB Layer (29 crates)                        â”‚
â”‚                                                                              â”‚
â”‚  Engine:     nietzsche-graph    nietzsche-query     nietzsche-hyp-ops        â”‚
â”‚  Growth:     nietzsche-lsystem  nietzsche-pregel    nietzsche-sleep          â”‚
â”‚  Evolution:  nietzsche-zaratustra                                            â”‚
â”‚  Analytics:  nietzsche-algo     nietzsche-sensory                            â”‚
â”‚  Visionary:  nietzsche-dream    nietzsche-narrative  nietzsche-agency        â”‚
â”‚  Wiederkehr: nietzsche-wiederkehr                                            â”‚
â”‚  Infra:      nietzsche-api      nietzsche-server    nietzsche-cluster        â”‚
â”‚  SDKs:       nietzsche-sdk      nietzsche-mcp                                â”‚
â”‚  Accel:      nietzsche-hnsw-gpu nietzsche-tpu       nietzsche-cugraph        â”‚
â”‚  Search:     nietzsche-filtered-knn  nietzsche-named-vectors  nietzsche-pq   â”‚
â”‚  Index:      nietzsche-secondary-idx                                         â”‚
â”‚  Observe:    nietzsche-metrics                                               â”‚
â”‚  Storage:    nietzsche-table    nietzsche-media      nietzsche-kafka          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     HyperspaceDB Layer (9 crates â€” fork base)                â”‚
â”‚                                                                              â”‚
â”‚  hyperspace-core   hyperspace-index   hyperspace-store                       â”‚
â”‚  hyperspace-server hyperspace-proto   hyperspace-cli                         â”‚
â”‚  hyperspace-embed  hyperspace-wasm    hyperspace-sdk                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### HyperspaceDB Foundation (fork base)

The storage and indexing foundation, inheriting all of HyperspaceDB v2.0:

- **Poincare Ball HNSW** â€” native multi-manifold nearest-neighbor index. Not re-ranking, not post-processing: the graph itself navigates in non-Euclidean geometry (PoincarÃ© ball with Klein/Riemann/Minkowski projections at query time).
- **mmap Vector Store** â€” memory-mapped, append-only segments (`chunk_N.hyp`) with 1-bit to 8-bit quantization (up to 64x compression).
- **Write-Ahead Log v3** â€” binary `[Magic][Len][CRC32][Op][Data]` format with configurable durability and automatic crash recovery.
- **gRPC API** â€” async Command-Query Separation with background indexing. Client gets `OK` as soon as the WAL is written.
- **Leader-Follower Replication** â€” async anti-entropy via logical clocks and Merkle tree bucket sync (256 buckets).
- **SIMD Acceleration** â€” Portable SIMD (`std::simd`) for 4-8x distance computation speedup on AVX2/Neon.
- **Multi-tenancy** â€” namespace isolation per `user_id`, per-user quota and billing accounting.
- **9,087 QPS** insert performance verified under stress test (90x above original target).
- **WASM** â€” browser-compatible build via `hyperspace-wasm` with IndexedDB storage.
- **Universal Embedder** â€” `hyperspace-embed` with local ONNX (`ort`) + remote API support.

### NietzscheDB Extensions

Twenty-nine new crates built on top of the foundation:

#### `nietzsche-graph` â€” Multi-Manifold Graph Engine
- `Node` = `NodeMeta` (~108 bytes: id, depth, energy, node_type, hausdorff_local, valence, arousal, content) + `PoincareVector` (embedding, stored separately for 10-25x traversal speedup)
- `PoincareVector` with `Vec<f32>` coords (distance kernel promotes to f64 internally for numerical stability near the Poincare boundary)
- `SparseVector` for SPLADE/sparse embeddings: sorted indices + values with O(nnz) dot product, cosine similarity, and L2 norm
- `Edge` typed as `Association`, `LSystemGenerated`, `Hierarchical`, or `Pruned`
- `AdjacencyIndex` using `DashMap` for lock-free concurrent access
- `GraphStorage` over RocksDB with 10 column families: `nodes`, `embeddings`, `edges`, `adj_out`, `adj_in`, `meta`, `sensory`, `energy_idx`, `meta_idx`, `lists`
- Own WAL for graph operations, separate from the vector WAL
- `NietzscheDB` dual-write: every insert goes to both RocksDB (graph) and HyperspaceDB (embedding)
- **Traversal engine** (`traversal.rs`): energy-gated BFS (reads only NodeMeta â€” ~100 bytes per hop), Poincare-distance Dijkstra, shortest-path reconstruction, energy-biased `DiffusionWalk` with seeded RNG
- **EmbeddedVectorStore** abstraction: CPU (HnswIndex) / GPU (GpuVectorStore) / TPU (TpuVectorStore) / Mock â€” selected at runtime via `NIETZSCHE_VECTOR_BACKEND`. Default is Embedded (real HNSW); Mock requires explicit opt-in
- **Multi-Metric HNSW**: Cosine, Euclidean, Poincare, and DotProduct distance metrics per collection. Factory routing ensures correct metric type at the HNSW graph topology level
- **KNN metadata filter push-down**: `MetadataFilter` (Eq, In, Range, And) pushed through VectorStore â†’ DynHnsw â†’ HnswIndex with RoaringBitmap pre-filtering for efficient filtered vector search
- **MERGE upsert semantics**: `merge_node` (find-or-create by content), `merge_edge` (find-or-create by from/to/type) with ON CREATE SET / ON MATCH SET
- **Atomic edge metadata increment**: `increment_edge_metadata(edge_id, field, delta)` for counter patterns (e.g. `r.count = r.count + 1`)
- **Persistent secondary indexes**: `create_index(field)` / `drop_index(field)` / `list_indexes()` with automatic backfill and startup recovery from CF_META registry. NQL executor auto-detects indexed fields for O(log N) scans instead of full table scans
- **Encryption at-rest** (`encryption.rs`): AES-256-CTR with HKDF-SHA256 per-CF key derivation from master key (`NIETZSCHE_ENCRYPTION_KEY`)
- **Schema validation** (`schema.rs`): per-NodeType constraints (required fields, field types), persisted in CF_META, enforced on `insert_node`
- **Metadata secondary indexes** (`CF_META_IDX`): arbitrary field indexing with FNV-1a + sortable value encoding for range scans
- **ListStore** (`CF_LISTS`): per-node ordered lists with RPUSH/LRANGE/LLEN semantics, atomic sequence counters
- **TTL / expires_at** enforcement: background reaper scans expired nodes and phantomizes them (topology-preserving). CREATE with `ttl` property auto-computes `expires_at`
- **Redis-compatible cache layer**: `CacheSet`/`CacheGet`/`CacheDel` RPCs using CF_META with "cache:" prefix, TTL as 8-byte expiry timestamp, lazy-delete on expired reads
- **Per-collection `tokio::sync::RwLock` concurrency**: `CollectionManager` with `DashMap` + `Arc<RwLock<NietzscheDB>>` per collection. Reads proceed concurrently; writes block only the affected collection
- **Full-text search + hybrid** (`fulltext.rs`): inverted index with BM25 scoring, plus RRF fusion with KNN vector search
- **SchrÃ¶dinger Edges** (`schrodinger.rs`): probabilistic edges with Markov transition probabilities â€” edges are "superpositions" that collapse at MATCH time. Context-dependent probability boost, per-tick decay, reinforcement learning. Batch collapse/decay operations
- **Valence/Arousal** (`valence.rs`): emotional dimensions on NodeMeta â€” valence âˆˆ [-1, 1] (pleasure/displeasure) and arousal âˆˆ [0, 1] (intensity). Arousal amplifies `energy_bias` in `diffusion_walk()` (heat travels faster through emotional memories). Valence modulates Laplacian edge weights in spectral diffusion (matching-polarity edges boost heat conductivity). Includes `emotional_gravity()`, `decay_arousal()`, `reinforce_emotion()`

#### `nietzsche-hyp-ops` â€” Multi-Manifold Geometry Engine
Four non-Euclidean geometry modules sharing a single PoincarÃ© storage layer:

| Module | Geometry | Key Operations |
|---|---|---|
| `poincare` (core) | PoincarÃ© ball (K < 0) | Mobius addition, exp/log maps, geodesic distance, parallel transport |
| `klein` | Klein disk (K < 0) | `to_klein`/`to_poincare`, colinearity check O(1), straight-line pathfinding |
| `riemann` | Unit sphere (K > 0) | Spherical midpoint, FrÃ©chet mean, dialectical `synthesis`/`synthesis_multi` |
| `minkowski` | Minkowski spacetime | `dsÂ² = -cÂ²Î”tÂ² + â€–Î”xâ€–Â²`, causal classification (Timelike/Spacelike/Lightlike), light cone filter |
| `manifold` | Normalization layer | `normalize_poincare`/`klein`/`sphere`, health checks, safe roundtrip projections |

Invariants enforced: PoincarÃ© â€–xâ€– < 1.0, Klein â€–xâ€– < 1.0, Sphere â€–xâ€– = 1.0. Cascaded roundtrip error < 1e-4 after 10 projections. Includes criterion benchmarks.

#### `nietzsche-query` â€” NQL Query Language
Nietzsche Query Language â€” a declarative query language with first-class multi-manifold primitives. Parser built with `pest` (PEG grammar). Supports arithmetic SET expressions (`n.count = n.count + 1`), edge alias property access (`-[r:TYPE]->` with `r.weight` in WHERE/ORDER BY), CREATE with TTL, DETACH DELETE, and eval_field fallback to `node.content`/`node.metadata` for dynamic properties. 113+ unit + integration tests.

**[Full NQL Reference: docs/NQL.md](docs/NQL.md)**

Query types:

| Type | Description |
|---|---|
| `MATCH` | Pattern matching on nodes/paths with geometric conditions |
| `CREATE` | Insert new nodes with labels, properties, and optional TTL |
| `MATCH â€¦ SET` | Update matched nodes' properties (supports arithmetic: `n.count = n.count + 1`) |
| `MATCH â€¦ DELETE` | Delete matched nodes |
| `MATCH â€¦ DETACH DELETE` | Delete matched nodes and all incident edges |
| `MERGE` | Upsert nodes/edges (ON CREATE SET / ON MATCH SET) |
| `DIFFUSE` | Multi-scale heat-kernel activation propagation |
| `RECONSTRUCT` | Decode sensory data from latent vector |
| `EXPLAIN` | Return execution plan with cost estimates |
| `DREAM FROM` | Speculative graph exploration via heat-kernel diffusion with noise |
| `APPLY/REJECT DREAM` | Accept or discard dream simulation results |
| `TRANSLATE` | Cross-modal projection (Synesthesia) via Poincare ball log/exp map |
| `MATCH ... AS OF CYCLE` | Time-travel query on named snapshots (Eternal Return) |
| `COUNTERFACTUAL` | What-if query with ephemeral property overlays |
| `CREATE/DROP/SHOW DAEMON` | Autonomous daemon agents (Wiederkehr) |
| `SHOW ARCHETYPES` | List shared cross-collection archetypes |
| `SHARE ARCHETYPE` | Publish elite node for cross-collection discovery |
| `NARRATE` | Generate human-readable narrative from graph evolution |
| `PSYCHOANALYZE` | Return evolutionary lineage of a node (creation, connections, energy) |

```sql
-- Hyperbolic nearest-neighbor search with depth filter
MATCH (m:Memory)
WHERE HYPERBOLIC_DIST(m.embedding, $q) < 0.5
  AND m.depth > 0.6
  AND NOT m.node_type = "Pruned"
RETURN m
ORDER BY HYPERBOLIC_DIST(m.embedding, $q) ASC
LIMIT 10

-- Graph traversal: hierarchical expansion
MATCH (c:Concept)-[:Hierarchical]->(child)
WHERE c.energy > 0.7
RETURN child ORDER BY child.depth DESC LIMIT 20

-- IN / BETWEEN / string operators
MATCH (n)
WHERE n.node_type IN ("Semantic", "Episodic")
  AND n.energy BETWEEN 0.3 AND 0.9
  AND n.node_type STARTS_WITH "S"
RETURN n LIMIT 50

-- Aggregation with GROUP BY
MATCH (n)
RETURN n.node_type, COUNT(*) AS total, AVG(n.energy) AS avg_e
GROUP BY n.node_type
ORDER BY total DESC

-- Mathematician-named geometric functions
MATCH (n)
WHERE RIEMANN_CURVATURE(n) > 0.3
  AND HAUSDORFF_DIM(n) BETWEEN 1.2 AND 1.8
  AND DIRICHLET_ENERGY(n) < 0.1
RETURN n ORDER BY RIEMANN_CURVATURE(n) DESC LIMIT 10

-- Multi-hop path traversal (BFS 2..4 hops)
MATCH (a)-[:Association*2..4]->(b)
WHERE a.energy > 0.5
RETURN a, b LIMIT 50

-- Create a new node
CREATE (n:Episodic {title: "first meeting", source: "manual"})
RETURN n

-- Create with TTL (auto-expires after 3600 seconds)
CREATE (n:EvaSession {id: "sess_1", turn_count: 0, ttl: 3600})
RETURN n

-- Arithmetic SET (per-node evaluation)
MATCH (n:EvaSession {id: "sess_1"})
SET n.turn_count = n.turn_count + 1, n.status = "active"
RETURN n

-- Edge alias: access edge properties in WHERE/ORDER BY
MATCH (a:Person)-[r:MENTIONED]->(b:Topic)
WHERE r.weight > 0.5
RETURN a, b ORDER BY r.weight DESC LIMIT 10

-- Update matched nodes
MATCH (n:Semantic) WHERE n.energy < 0.1 SET n.energy = 0.5 RETURN n

-- DETACH DELETE (node + all incident edges)
MATCH (n:EvaSession) WHERE n.status = "expired" DETACH DELETE n

-- Delete expired nodes
MATCH (n) WHERE n.energy = 0.0 DELETE n

-- Time-based queries with NOW() and INTERVAL()
MATCH (n) WHERE n.created_at > NOW() - INTERVAL("7d") RETURN n LIMIT 50

-- EXPLAIN with cost estimates
EXPLAIN MATCH (n:Memory) WHERE n.energy > 0.3 RETURN n
-- â†’ NodeScan(label=Memory) -> Filter(conditions=1) | rows=~250, scan=EnergyIndexScan, index=CF_ENERGY_IDX, cost=~500Âµs

-- Multi-scale heat-kernel diffusion
DIFFUSE FROM $seed
  WITH t = [0.1, 1.0, 10.0]
  MAX_HOPS 6
RETURN path

-- Dream Queries â€” speculative exploration
DREAM FROM $seed DEPTH 5 NOISE 0.05
SHOW DREAMS
APPLY DREAM "dream_xxx"

-- Daemon Agents â€” autonomous graph patrols
CREATE DAEMON guardian ON (n:Memory)
  WHEN n.energy > 0.8
  THEN DIFFUSE FROM n WITH t=[0.1, 1.0] MAX_HOPS 5
  EVERY INTERVAL("1h")
  ENERGY 0.8
SHOW DAEMONS

-- Time-travel via named snapshots
MATCH (n:Memory) AS OF CYCLE 3
WHERE n.energy > 0.5
RETURN n

-- Narrative Engine
NARRATE IN "memories" WINDOW 24 FORMAT json

-- Evolutionary lineage of a node
PSYCHOANALYZE $node_id

-- Emotional memory search (high arousal, positive valence)
MATCH (n:Episodic)
WHERE n.arousal > 0.7 AND n.valence > 0.3
RETURN n ORDER BY n.arousal DESC LIMIT 10

-- Set emotional state on a memory
MATCH (n) WHERE n.id = $id
SET n.valence = 0.8, n.arousal = 0.9
RETURN n
```

**Built-in geometric functions:**

| Function | Named after | Computes |
|---|---|---|
| `HYPERBOLIC_DIST(n.e, $q)` | â€” | Poincare ball geodesic distance |
| `POINCARE_DIST(n, $q)` | Henri Poincare | Same â€” explicit model name |
| `KLEIN_DIST(n, $q)` | Felix Klein | Beltrami-Klein distance |
| `RIEMANN_CURVATURE(n)` | Bernhard Riemann | Ollivier-Ricci curvature |
| `HAUSDORFF_DIM(n)` | Felix Hausdorff | Local fractal dimension |
| `GAUSS_KERNEL(n, t)` | Carl Friedrich Gauss | Heat kernel `exp(-d^2/4t)` |
| `CHEBYSHEV_COEFF(n, k)` | Pafnuty Chebyshev | Chebyshev polynomial T_k |
| `DIRICHLET_ENERGY(n)` | P.G.L. Dirichlet | Local Dirichlet energy |
| `EULER_CHAR(n)` | Leonhard Euler | V - E characteristic |
| `LAPLACIAN_SCORE(n)` | P.-S. Laplace | Graph Laplacian diagonal |
| `LOBACHEVSKY_ANGLE(n, $p)` | N. Lobachevsky | Angle of parallelism |
| `MINKOWSKI_NORM(n)` | H. Minkowski | Conformal factor |
| `RAMANUJAN_EXPANSION(n)` | S. Ramanujan | Spectral expansion ratio |
| `FOURIER_COEFF(n, k)` | J. Fourier | Graph Fourier coefficient |
| `NOW()` | â€” | Current Unix timestamp (seconds, f64) |
| `EPOCH_MS()` | â€” | Current Unix epoch (milliseconds, f64) |
| `INTERVAL("1h")` | â€” | Duration to seconds (s/m/h/d/w units) |

#### `nietzsche-lsystem` â€” Fractal Growth Engine
The knowledge graph is not static â€” it grows by **L-System production rules**:
- `ProductionRule` fires when `EnergyAbove(t)`, `DepthBelow(t)`, `HausdorffAbove(t)`, or custom conditions (`And`, `Or`, `Not`, `Always`)
- `SpawnChild` places the child node deeper in the Poincare ball (more specific, closer to boundary) via **Mobius addition** `u + v`
- `SpawnSibling` creates lateral associations at a given hyperbolic angle
- `Prune` archives low-complexity regions (not deleted â€” tagged as `Pruned`)
- **Hausdorff dimension** computed via box-counting on hyperbolic coordinates at scales `[4, 8, 16, 32, 64]`
- Nodes with D < 0.5 or D > 1.9 are pruned automatically; target fractal regime: **1.2 < D < 1.8**
- `LSystemEngine::tick` protocol: Scan -> Hausdorff update -> Rule matching -> Apply mutations -> Report
- **EnergyCircuitBreaker**: cross-system anti-tumor protection â€” depth-aware energy caps, BFS tumor detection, energy dampening, rate limiting. Prevents runaway energy cascades from creating pathological node clusters
- 41+ unit tests across all modules

#### `nietzsche-pregel` â€” Hyperbolic Heat Kernel Diffusion
Multi-scale activation propagation across the hyperbolic graph:
- **Chebyshev polynomial approximation** of the heat kernel `e^(-tL)` â€” O(K x |E|) complexity
- **Hyperbolic graph Laplacian** â€” edge weights derived from Poincare distances
- **Modified Bessel functions** `I_k(t)` for computing Chebyshev coefficients analytically
- Multiple diffusion scales: `t=0.1` activates direct neighbors (focused recall), `t=10.0` activates structurally connected but semantically distant nodes (free association)
- **Valence-modulated Laplacian**: edge weights incorporate emotional valence â€” edges between nodes of matching emotional polarity (both positive or both negative) propagate heat faster (emotional clustering effect)
- `HyperbolicLaplacian` + `apply_heat_kernel` + `chebyshev_coefficients` as stable public API

#### `nietzsche-wiederkehr` â€” DAEMON Agents
Autonomous agents that live inside the database, patrolling the graph and executing actions when conditions are met:
- **DaemonDef** with configurable WHEN conditions, THEN actions, EVERY interval, and ENERGY budget
- **DaemonEngine** tick loop: evaluate conditions, collect intents, decay energy, reap dead daemons
- **Will to Power** priority scheduler: BinaryHeap-based scheduling with energy Ã— urgency weighting
- NQL: `CREATE DAEMON`, `DROP DAEMON`, `SHOW DAEMONS`
- 18 unit tests (store, evaluator, engine, priority)

#### `nietzsche-dream` â€” Dream Queries
Speculative graph exploration via hyperbolic diffusion with stochastic noise:
- **DreamEngine**: BFS exploration from seed node with noise-perturbed energy detection
- Energy spike and curvature anomaly event detection
- Pending/Applied/Rejected dream lifecycle with persistent sessions
- NQL: `DREAM FROM`, `APPLY DREAM`, `REJECT DREAM`, `SHOW DREAMS`
- 8 unit tests (store, engine)

#### `nietzsche-narrative` â€” Narrative Engine
Story arc detection and generation from graph evolution:
- **NarrativeEngine**: scans nodes, computes energy statistics, detects elite emergence and decay events
- Configurable time window, elite/decay thresholds
- JSON and text output formats with auto-generated summaries
- NQL: `NARRATE IN "collection" WINDOW hours FORMAT json|text`
- 4 unit tests

#### Synesthesia (in `nietzsche-sensory`)
Cross-modal projection via hyperbolic parallel transport:
- `translate_modality()`: log_map â†’ modal rotation â†’ exp_map on the Poincare ball
- Preserves hierarchical depth (radius) while changing modality direction
- Quality loss estimation per modality pair
- NQL: `TRANSLATE $node FROM text TO audio`

#### Eternal Return (in `nietzsche-query`)
Temporal queries and counterfactual reasoning:
- `AS OF CYCLE N`: time-travel queries on named snapshots
- `COUNTERFACTUAL SET ... MATCH ...`: what-if queries with ephemeral overlays

#### Collective Unconscious (in `nietzsche-cluster`)
Cross-collection archetype sharing via gossip protocol:
- `ArchetypeRegistry`: DashMap-based registry with merge_peer_archetypes for gossip
- NQL: `SHOW ARCHETYPES`, `SHARE ARCHETYPE $node TO "collection"`
- 4 unit tests

#### `nietzsche-agency` â€” Autonomous Agency Engine
Graph-level autonomous intelligence with counterfactual reasoning:
- **AgencyEngine** tick loop: runs 3 built-in daemons (Entropy, Gap, Coherence) + MetaObserver
- **EntropyDaemon**: detects Hausdorff variance spikes across angular regions
- **GapDaemon**: identifies knowledge gaps in depthÃ—angle sectors
- **CoherenceDaemon**: measures multi-scale diffusion overlap (Chebyshev heat kernel)
- **MetaObserver**: produces HealthReports with energy percentiles, fractal status, wake-up triggers
- **CounterfactualEngine**: what-if simulations via ShadowGraph (remove/add nodes without mutating real graph)
- **AgencyEventBus**: tokio broadcast channel for cross-system event propagation
- **Hegelian Dialectic Engine** (`dialectic.rs`): AGI-2 module â€” detects contradictions between nodes with opposing polarity, creates Tension nodes at embedding midpoints, synthesizes resolutions during sleep by pulling toward center and creating Semantic synthesis nodes. Full detect â†’ tension â†’ synthesize pipeline
- **Code-as-Data** (`code_as_data.rs`): AGI-4 module â€” NQL queries stored as activatable graph nodes. When a node's energy exceeds its `activation_threshold` (via heat diffusion / Will-to-Power), the stored query is extracted and can be executed. Includes cooldown, max firings, and exhaustion tracking. Transforms the database into a Turing-complete reactive rule engine
- 30+ unit tests (event_bus, engine, observer, daemons, shadow, simulator, dialectic, code_as_data)

#### `nietzsche-sleep` â€” Reconsolidation Sleep Cycle
EVA sleeps. During sleep:
1. Sample high-curvature subgraph via random walk
2. Snapshot current embeddings (rollback point)
3. Perturb embeddings in the tangent space (the "dream")
4. Optimize via **RiemannianAdam** on the Poincare manifold
5. Measure Hausdorff dimension before and after
6. **Commit** if `delta(Hausdorff) < threshold` â€” identity preserved, reconsolidation accepted
7. **Rollback** if identity was destroyed â€” dream discarded

This prevents catastrophic forgetting while allowing genuine memory reorganization.

**Time-travel / Versioning:** Named snapshots (`SnapshotRegistry`) allow creating labeled checkpoints of the entire embedding state, listing all snapshots with timestamps, and restoring any previous state â€” enabling temporal queries and safe experimentation.

#### `nietzsche-zaratustra` â€” Autonomous Evolution Engine
Three-phase autonomous cycle inspired by Nietzsche's philosophy:
1. **Will to Power** â€” energy propagation: each node absorbs `alpha x mean(neighbour_energy)`, amplifying high-energy clusters
2. **Eternal Recurrence** â€” temporal echo snapshots: captures periodic state for pattern detection
3. **Ubermensch** â€” elite tier identification: nodes in the top energy fraction are promoted to elite status

Configurable via `ZARATUSTRA_INTERVAL_SECS` (default 600s). Invocable via gRPC `InvokeZaratustra` or automatic background scheduler.

#### `nietzsche-algo` â€” Graph Algorithm Library
Eleven built-in graph algorithms, all available via gRPC and HTTP:

| Algorithm | Type | RPC |
|---|---|---|
| PageRank | Centrality | `RunPageRank` |
| Louvain | Community | `RunLouvain` |
| Label Propagation | Community | `RunLabelProp` |
| Betweenness Centrality | Centrality | `RunBetweenness` |
| Closeness Centrality | Centrality | `RunCloseness` |
| Degree Centrality | Centrality | `RunDegreeCentrality` |
| WCC (Weakly Connected) | Component | `RunWCC` |
| SCC (Strongly Connected) | Component | `RunSCC` |
| A* Pathfinding | Pathfinding | `RunAStar` |
| Triangle Count | Structure | `RunTriangleCount` |
| Jaccard Similarity | Similarity | `RunJaccardSimilarity` |

#### `nietzsche-sensory` â€” Sensory Compression Layer
Multi-modal latent vector storage with progressive degradation:
- Stores latent representations for: **text, audio, image, fused** modalities
- Progressive degradation: `f32 -> f16 -> int8 -> PQ -> gone`
- Original shape metadata preserved for reconstruction
- Encoder version tracking for backward compatibility
- Persisted in RocksDB via graph storage

#### `nietzsche-cluster` â€” Distributed Foundation
Gossip-based cluster discovery and shard routing:
- `ClusterNode` â€” identity, role (primary/replica/coordinator), health
- `ClusterRegistry` â€” gossip-updated peer view
- `ClusterRouter` â€” shard selection
- Eventual consistency via gossip (no Raft in current phase)
- **Semantic CRDTs** (`crdt.rs`): conflict-free replicated data types for graph merge â€” add-wins node/edge sets, max-energy wins for concurrent updates, phantom-add-wins (irreversible), Lamport timestamp ordering. `GraphDelta` struct for gossip transmission with `apply_delta()` merge
- Configurable via `NIETZSCHE_CLUSTER_ENABLED`, `NIETZSCHE_CLUSTER_ROLE`, `NIETZSCHE_CLUSTER_SEEDS`

#### `nietzsche-hnsw-gpu` â€” GPU Vector Backend
NVIDIA cuVS CAGRA acceleration for vector search. See [GPU Acceleration](#gpu-acceleration) section.

#### `nietzsche-tpu` â€” TPU Vector Backend
Google TPU acceleration via PJRT C API. See [TPU Acceleration](#tpu-acceleration) section.

#### `nietzsche-cugraph` â€” GPU Graph Traversal
GPU-accelerated graph algorithms via NVIDIA cuGraph:
- cuGraph BFS/Dijkstra/PageRank on GPU
- Poincare GPU k-NN with custom CUDA kernel
- Dynamic FFI loader for `libcugraph.so` at runtime
- cudarc + NVRTC for Poincare kernel compilation
- Feature flag: `--features cuda`

#### `nietzsche-mcp` â€” Model Context Protocol Server
JSON-RPC 2.0 server for AI assistant integration (Claude, GPT, etc.):
- **19 tools**: graph CRUD, NQL query, KNN search, traversal, graph algorithms, diffusion, stats
- Stdin/stdout transport (standard MCP protocol)
- Parameter validation with typed `ParamValue` (String, Float, Int, Bool, Vector)
- 19 unit tests

#### `nietzsche-metrics` â€” Prometheus/OpenTelemetry Metrics
Observability export layer:
- **NODES_INSERTED**, **EDGES_INSERTED**, **QUERIES_EXECUTED** (CounterVec by collection)
- **QUERY_DURATION_SECONDS**, **KNN_DURATION_SECONDS**, **DIFFUSION_DURATION_SECONDS** (Histogram)
- **NODE_COUNT**, **EDGE_COUNT**, **DAEMON_COUNT**, **DAEMON_ENERGY_TOTAL** (Gauge)
- Singleton `MetricsRegistry` with Prometheus text format export (`/metrics`)
- 6 unit tests

#### `nietzsche-filtered-knn` â€” Filtered KNN with Roaring Bitmaps
Pre-filtered nearest-neighbor search using Roaring Bitmaps:
- **NodeFilter** enum: EnergyRange, NodeType, ContentField, ContentFieldExists, And, Or
- Energy range filter leverages `CF_ENERGY_IDX` for efficient range scans
- JSON dot-path navigation for content field filtering
- Poincare distance computation for multi-manifold KNN
- 15 integration tests

#### `nietzsche-named-vectors` â€” Multi-Vector per Node
Multiple named vector embeddings per node:
- `NamedVector { node_id, name, coordinates, metric }` with VectorMetric (Poincare, Cosine, Euclidean)
- Persisted in CF_META with key `nvec:{node_id}:{name}` (bincode serialization)
- `NamedVectorStore` with put/get/list/delete/delete_all operations
- 8 unit tests

#### `nietzsche-pq` â€” Product Quantization
Magnitude-preserving vector compression (NOT binary quantization â€” preserves hyperbolic depth):
- **Codebook** training via k-means clustering per sub-vector partition
- **PQEncoder** with encode/decode: M sub-vectors Ã— K=256 centroids
- **Asymmetric Distance Computation (ADC)** via precomputed DistanceTable
- KEY: `test_magnitude_preservation` proves PQ preserves `â€–xâ€–` = depth in Poincare ball
- Configurable: `PQConfig { m: 8, k: 256, max_iterations: 25 }`
- 12 unit tests

#### `nietzsche-secondary-idx` â€” Secondary Indexes
Arbitrary JSON field indexing for fast lookups:
- `IndexDef { name, field_path, index_type: String|Float|Int }`
- Persisted in CF_META: definitions at `idx_def:{name}`, entries at `sidx:{name}:{sortable_value}:{node_id}`
- Float encoding: IEEE 754 sign-magnitude to lexicographic order (16 hex chars)
- `SecondaryIndexBuilder` with create_index, drop_index, insert_entry, lookup, range_lookup
- 13 unit tests

#### `nietzsche-kafka` â€” Kafka Connect Sink
Change data capture sink for streaming mutations:
- `GraphMutation` enum: InsertNode, DeleteNode, InsertEdge, DeleteEdge, SetEnergy, SetContent
- `KafkaSink` with process_message/process_batch (BatchResult with succeeded/failed/errors)
- SetContent merges JSON fields into existing node content
- 9 unit tests

#### `nietzsche-table` â€” Relational Table Store (SQLite)
Bridging graph and relational paradigms:
- `TableSchema` with `ColumnDef { name, col_type, nullable, default }`
- Column types: Text, Integer, Float, Bool, Uuid, Json, **NodeRef** (FK to graph nodes)
- `TableStore` wrapping rusqlite::Connection with create/drop/insert/query/delete/list/schema
- Schema metadata persisted in `_nietzsche_table_meta` internal table
- File-backed or in-memory operation modes
- 15 unit tests

#### `nietzsche-media` â€” Media/Blob Store (OpenDAL)
Backend-agnostic media storage for files associated with graph nodes:
- Powered by **Apache OpenDAL** â€” supports local filesystem, S3, GCS, Azure, and more
- `MediaMeta { id, node_id, filename, media_type, content_type, size_bytes, created_at }`
- Media types: Image, Audio, Video, Document, Binary
- `MediaStore` with put/get/get_meta/delete/list_for_node/exists
- Flat key structure: `{node_id}/{media_id}` and `{node_id}/{media_id}.meta`
- 8 unit tests

#### `nietzsche-api` â€” Unified gRPC API
Single endpoint for all NietzscheDB capabilities â€” **71+ RPCs** over a single `NietzscheDB` service, including 6 multi-manifold geometry RPCs (Synthesis, CausalNeighbors, CausalChain, KleinPath, IsOnShortestPath). Every data-plane RPC accepts a `collection` field; empty -> `"default"`.

```protobuf
service NietzscheDB {
  // â”€â”€ Collection management â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc CreateCollection(CreateCollectionRequest)   returns (CreateCollectionResponse);
  rpc DropCollection(DropCollectionRequest)       returns (StatusResponse);
  rpc ListCollections(Empty)                      returns (ListCollectionsResponse);

  // â”€â”€ Graph CRUD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc InsertNode(InsertNodeRequest)     returns (NodeResponse);
  rpc GetNode(NodeIdRequest)            returns (NodeResponse);
  rpc DeleteNode(NodeIdRequest)         returns (StatusResponse);
  rpc UpdateEnergy(UpdateEnergyRequest) returns (StatusResponse);
  rpc InsertEdge(InsertEdgeRequest)     returns (EdgeResponse);
  rpc DeleteEdge(EdgeIdRequest)         returns (StatusResponse);
  rpc MergeNode(MergeNodeRequest)       returns (MergeNodeResponse);
  rpc MergeEdge(MergeEdgeRequest)       returns (MergeEdgeResponse);
  rpc IncrementEdgeMeta(IncrementEdgeMetaRequest) returns (IncrementEdgeMetaResponse);

  // â”€â”€ Batch Operations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc BatchInsertNodes(BatchInsertNodesRequest)   returns (BatchInsertNodesResponse);
  rpc BatchInsertEdges(BatchInsertEdgesRequest)   returns (BatchInsertEdgesResponse);

  // â”€â”€ Query & Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc Query(QueryRequest)               returns (QueryResponse);
  rpc KnnSearch(KnnRequest)             returns (KnnResponse);   // supports metadata filters
  rpc FullTextSearch(FullTextSearchRequest) returns (FullTextSearchResponse);
  rpc HybridSearch(HybridSearchRequest) returns (KnnResponse);

  // â”€â”€ Traversal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc Bfs(TraversalRequest)             returns (TraversalResponse);
  rpc Dijkstra(TraversalRequest)        returns (TraversalResponse);
  rpc Diffuse(DiffusionRequest)         returns (DiffusionResponse);

  // â”€â”€ Graph Algorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc RunPageRank(PageRankRequest)             returns (AlgorithmScoreResponse);
  rpc RunLouvain(LouvainRequest)               returns (AlgorithmCommunityResponse);
  rpc RunLabelProp(LabelPropRequest)           returns (AlgorithmCommunityResponse);
  rpc RunBetweenness(BetweennessRequest)       returns (AlgorithmScoreResponse);
  rpc RunCloseness(ClosenessRequest)           returns (AlgorithmScoreResponse);
  rpc RunDegreeCentrality(DegreeCentralityRequest) returns (AlgorithmScoreResponse);
  rpc RunWCC(WccRequest)                       returns (AlgorithmCommunityResponse);
  rpc RunSCC(SccRequest)                       returns (AlgorithmCommunityResponse);
  rpc RunAStar(AStarRequest)                   returns (AStarResponse);
  rpc RunTriangleCount(TriangleCountRequest)   returns (TriangleCountResponse);
  rpc RunJaccardSimilarity(JaccardRequest)     returns (SimilarityResponse);

  // â”€â”€ Lifecycle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc TriggerSleep(SleepRequest)        returns (SleepResponse);
  rpc InvokeZaratustra(ZaratustraRequest) returns (ZaratustraResponse);

  // â”€â”€ Sensory Compression â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc InsertSensory(InsertSensoryRequest) returns (StatusResponse);
  rpc GetSensory(NodeIdRequest)           returns (SensoryResponse);
  rpc Reconstruct(ReconstructRequest)     returns (ReconstructResponse);
  rpc DegradeSensory(NodeIdRequest)       returns (StatusResponse);

  // â”€â”€ Backup / Restore â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc CreateBackup(CreateBackupRequest)   returns (BackupResponse);
  rpc ListBackups(Empty)                  returns (ListBackupsResponse);
  rpc RestoreBackup(RestoreBackupRequest) returns (StatusResponse);

  // â”€â”€ ListStore â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc ListRPush(ListPushRequest)          returns (ListPushResponse);
  rpc ListLRange(ListRangeRequest)        returns (ListRangeResponse);
  rpc ListLen(ListLenRequest)             returns (ListLenResponse);

  // â”€â”€ Cache (Redis-compatible) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc CacheSet(CacheSetRequest)           returns (StatusResponse);
  rpc CacheGet(CacheGetRequest)           returns (CacheGetResponse);
  rpc CacheDel(CacheDelRequest)           returns (StatusResponse);
  rpc ReapExpired(ReapExpiredRequest)      returns (ReapExpiredResponse);

  // â”€â”€ Change Data Capture â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc SubscribeCDC(CdcRequest)            returns (stream CdcEvent);

  // â”€â”€ Multi-Manifold Geometry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc Synthesis(SynthesisRequest)                   returns (SynthesisResponse);
  rpc SynthesisMulti(SynthesisMultiRequest)         returns (SynthesisResponse);
  rpc CausalNeighbors(CausalNeighborsRequest)       returns (CausalNeighborsResponse);
  rpc CausalChain(CausalChainRequest)               returns (CausalChainResponse);
  rpc KleinPath(KleinPathRequest)                   returns (KleinPathResponse);
  rpc IsOnShortestPath(ShortestPathCheckRequest)     returns (ShortestPathCheckResponse);

  // â”€â”€ Cluster â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc ExchangeGossip(GossipRequest)       returns (GossipResponse);

  // â”€â”€ Schema Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc SetSchema(SetSchemaRequest)         returns (StatusResponse);
  rpc GetSchema(GetSchemaRequest)         returns (GetSchemaResponse);
  rpc ListSchemas(Empty)                  returns (ListSchemasResponse);

  // â”€â”€ Secondary Indexes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc CreateIndex(CreateIndexRequest)     returns (StatusResponse);
  rpc DropIndex(DropIndexRequest)         returns (StatusResponse);
  rpc ListIndexes(ListIndexesRequest)     returns (ListIndexesResponse);

  // â”€â”€ Admin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc GetStats(Empty)                     returns (StatsResponse);
  rpc HealthCheck(Empty)                  returns (StatusResponse);
}
```

#### `nietzsche-sdk` â€” Rust Client SDK
Async gRPC client with seed examples (`seed_100.rs`, `seed_1gb.rs`).

#### `nietzsche-server` â€” Production Binary
Standalone server binary with env-var-based configuration, background sleep and Zaratustra schedulers, TTL reaper, scheduled backup with auto-pruning, RBAC (Admin/Writer/Reader), cluster gossip, embedded HTTP dashboard, and graceful shutdown.

```bash
NIETZSCHE_DATA_DIR=/data/nietzsche \
NIETZSCHE_PORT=50051 \
NIETZSCHE_DASHBOARD_PORT=8080 \
NIETZSCHE_LOG_LEVEL=info \
NIETZSCHE_SLEEP_INTERVAL_SECS=3600 \
ZARATUSTRA_INTERVAL_SECS=600 \
nietzsche-server
```

---

## HTTP Dashboard & REST API

NietzscheDB ships with an embedded **React + Cosmograph 2.1** dashboard, compiled into the binary as a single HTML file. No external web server needed.

### Dashboard Tech Stack

| Component | Version |
|---|---|
| React | 19.2 |
| TypeScript | 5.9 |
| Cosmograph | 2.1 (GPU graph visualization) |
| Vite | 7.2 + vite-plugin-singlefile |
| Tailwind CSS | 4.1 |
| TanStack React Query | 5.90 |
| Radix UI | Component primitives |
| Recharts | 3.7 |

### Dashboard Pages

| Page | Features |
|---|---|
| Overview | Node/edge counts, uptime, version, system config |
| Collections | List, create, inspect collections with dimension/metric |
| Nodes | Browse, insert, delete nodes |
| Graph Explorer | Full Cosmograph 2.1 visualization with timeline, histograms (energy/depth/hausdorff), categorical bars (node_type/edge_type), search, color legend, selection tools |
| Data Explorer | NQL query editor, CRUD forms |
| Settings | Server configuration |

### REST API Endpoints

**Core:**
| Method | Endpoint | Description |
|---|---|---|
| GET | `/api/health` | `{status: "ok"}` |
| GET | `/api/stats` | Node/edge counts, version, uptime |
| GET | `/api/collections` | List all collections |
| GET | `/metrics` | Prometheus metrics |

**Data (CRUD):**
| Method | Endpoint | Description |
|---|---|---|
| GET | `/api/graph?collection=NAME&limit=N` | Nodes + edges for visualization |
| GET | `/api/node/:id` | Get single node |
| POST | `/api/node` | Insert node |
| DELETE | `/api/node/:id` | Delete node |
| POST | `/api/edge` | Insert edge |
| DELETE | `/api/edge/:id` | Delete edge |
| POST | `/api/batch/nodes` | Batch insert nodes |
| POST | `/api/batch/edges` | Batch insert edges |

**Query & Traversal:**
| Method | Endpoint | Description |
|---|---|---|
| POST | `/api/query` | Execute NQL query |
| POST | `/api/sleep` | Trigger sleep cycle |
| GET | `/api/search` | Full-text search |

**Graph Algorithms:**
| Method | Endpoint | Description |
|---|---|---|
| GET | `/api/algo/pagerank` | PageRank centrality |
| GET | `/api/algo/louvain` | Louvain community detection |
| GET | `/api/algo/labelprop` | Label propagation |
| GET | `/api/algo/betweenness` | Betweenness centrality |
| GET | `/api/algo/closeness` | Closeness centrality |
| GET | `/api/algo/degree` | Degree centrality |
| GET | `/api/algo/wcc` | Weakly connected components |
| GET | `/api/algo/scc` | Strongly connected components |
| GET | `/api/algo/triangles` | Triangle count |
| GET | `/api/algo/jaccard` | Jaccard similarity |

**Data Management:**
| Method | Endpoint | Description |
|---|---|---|
| POST | `/api/backup` | Create backup |
| GET | `/api/backup` | List backups |
| GET | `/api/export/nodes` | Export all nodes |
| GET | `/api/export/edges` | Export all edges |

---

## SDKs

### Python
```python
from nietzsche_db import NietzscheClient

db = NietzscheClient("localhost:50051")

# Insert a memory into hyperbolic space (||x|| < 1.0 required)
node_id = db.insert_node(embedding=[0.1, 0.2, 0.3], metadata={"text": "Nietzsche on memory"})

# KNN search
results = db.knn_search(embedding=[0.1, 0.2, 0.3], k=10)

# Run NQL query
results = db.query("MATCH (m:Memory) WHERE m.depth > 0.7 RETURN m LIMIT 5")

# Trigger sleep and reconsolidate
report = db.trigger_sleep(noise=0.02, adam_lr=0.005)
print(f"delta_hausdorff={report.hausdorff_delta:.3f}, committed={report.committed}")
```

### Go (sdk-papa-caolho)
```go
import nietzsche "sdk-papa-caolho"

client, _ := nietzsche.ConnectInsecure("localhost:50052")
defer client.Close()

// Insert node with Poincare embedding
node, _ := client.InsertNode(ctx, nietzsche.InsertNodeOpts{
    Coords:   []float64{0.1, 0.2, 0.3},
    Content:  map[string]string{"text": "first memory"},
    NodeType: "Semantic",
})

// KNN search
results, _ := client.KnnSearch(ctx, []float64{0.1, 0.2, 0.3}, 10, "")

// Graph algorithms
scores, _ := client.RunPageRank(ctx, nietzsche.PageRankOpts{Iterations: 20})

// Trigger sleep
sleep, _ := client.TriggerSleep(ctx, nietzsche.SleepOpts{Noise: 0.02})
fmt.Printf("deltaH=%.3f committed=%v\n", sleep.HausdorffDelta, sleep.Committed)
```

Go SDK covers all 71+ RPCs: collections, nodes, edges, batch operations, query, search, traversal, algorithms, backup, CDC, merge, sensory, indexes, lifecycle, and multi-manifold operations (Synthesis, CausalNeighbors, CausalChain, KleinPath, IsOnShortestPath).

### TypeScript & C++
Located in `sdks/ts/` and `sdks/cpp/`.

---

## Development Roadmap

```
PHASE 0   Foundation & environment          âœ… COMPLETE
PHASE 1   Node and edge model               âœ… COMPLETE
PHASE 2   Graph storage engine              âœ… COMPLETE
PHASE 3   Traversal engine                  âœ… COMPLETE
PHASE 4   NQL query language                âœ… COMPLETE
PHASE 5   L-System engine                   âœ… COMPLETE
PHASE 6   Fractal diffusion / Pregel        âœ… COMPLETE
PHASE 7   ACID transactions on graph        âœ… COMPLETE
PHASE 8   Reconsolidation (sleep cycle)     âœ… COMPLETE
PHASE 9   Public API + SDKs                 âœ… COMPLETE
PHASE 10  Benchmarks, hardening, production âœ… COMPLETE
PHASE 11  Sensory compression layer         âœ… COMPLETE
PHASE Z   Zaratustra evolution engine       âœ… COMPLETE
PHASE A+B Unified gRPC API (71+ RPCs)       âœ… COMPLETE
PHASE D   Merge semantics (upsert)          âœ… COMPLETE
PHASE G   Cluster foundation (gossip)       âœ… COMPLETE
PHASE GPU GPU acceleration (cuVS CAGRA)     âœ… COMPLETE
PHASE TPU TPU acceleration (PJRT)           âœ… COMPLETE

â”€â”€ Production Hardening Roadmap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
P0.1  TTL Reaper (background expiry)       âœ… COMPLETE
P0.2  RBAC (Admin/Writer/Reader roles)     âœ… COMPLETE
P0.3  Backup Hardening (scheduled+prune)   âœ… COMPLETE
P1.4  NQL CREATE / SET / DELETE            âœ… COMPLETE
P1.5  Metadata Secondary Indexes           âœ… COMPLETE
P1.6  Cluster Gossip Wiring                âœ… COMPLETE
P2.7  Encryption at-rest (AES-256-CTR)     âœ… COMPLETE
P2.8  Multi-hop Path NQL (BoundedBFS)      âœ… COMPLETE
P2.9  ListStore (RPUSH/LRANGE/LLEN)        âœ… COMPLETE
P3.10 Query Cost Estimator (EXPLAIN)       âœ… COMPLETE
P3.11 Hybrid BM25+ANN (RRF fusion)         âœ… COMPLETE
P3.12 Schema Validation (per-NodeType)     âœ… COMPLETE

â”€â”€ Consolidation Sprint (2026-02-21) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
C0.1  Bug fixes (5 real bugs)              âœ… COMPLETE
C0.2  Test coverage (+389 new tests)       âœ… COMPLETE
       Sprint 1: +166 (algo, zaratustra, gpu, graph, query, sparse, autotuner, snapshot)
       Sprint 2: +127 (tpu: 28, cugraph: 41, sdk: 28, wasm: 30)
       Sprint 3: +96  (embed: 49, cli: 47) â€” 100% module coverage
C1.1  NQL Time Functions (NOW/INTERVAL)    âœ… COMPLETE
C1.2  ListStore list_del method            âœ… COMPLETE
C2.1  SparseVector type                    âœ… COMPLETE
C2.2  HNSW Auto-tuner (ef_search)          âœ… COMPLETE
C2.3  Named Snapshots (time-travel)        âœ… COMPLETE

â”€â”€ Expansion Sprint (2026-02-21) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
E0.1  MCP Server (AI assistant tools)      âœ… COMPLETE  (19 tools, 19 tests)
E0.2  Prometheus/OTel metrics export       âœ… COMPLETE  (12 metrics, 6 tests)
E0.3  Filtered KNN + Roaring Bitmaps       âœ… COMPLETE  (5 filter types, 15 tests)
E0.4  Named Vectors (multi-vector/node)    âœ… COMPLETE  (3 metrics, 8 tests)
E0.5  Product Quantization (PQ)            âœ… COMPLETE  (magnitude-preserving, 12 tests)
E0.6  Secondary Indexes (arbitrary field)  âœ… COMPLETE  (3 index types, 13 tests)
E0.7  Kafka Connect Sink (CDC)             âœ… COMPLETE  (6 mutation types, 9 tests)
E0.8  Table Store (SQLite)                 âœ… COMPLETE  (7 column types, 15 tests)
E0.9  Media/Blob Store (OpenDAL)           âœ… COMPLETE  (5 media types, 8 tests)
E1.0  Go SDK batch RPCs                    âœ… COMPLETE  (42/42 RPCs)

â”€â”€ EVA Compatibility Sprint (2026-02-21) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
A.1   Multi-Metric HNSW fix + DotProduct   âœ… COMPLETE  (Euclidean bug fixed, DotProduct added)
A.2   EmbeddedVectorStore as default       âœ… COMPLETE  (Mock â†’ Embedded, real HNSW by default)
B.2   KNN metadata filter push-down        âœ… COMPLETE  (MetadataFilter â†’ RoaringBitmap pre-filter)
D.1   MergeEdge ON MATCH + edge metadata   âœ… COMPLETE  (update_edge_metadata + WAL entries)
D.2   IncrementEdgeMeta RPC               âœ… COMPLETE  (atomic counter increment on edges)
E.1   Persistent secondary index registry  âœ… COMPLETE  (create/drop/list + backfill + startup load)
E.2   NQL executor index integration       âœ… COMPLETE  (auto O(log N) scan for indexed WHERE)
E.3   Index management gRPC RPCs           âœ… COMPLETE  (CreateIndex/DropIndex/ListIndexes)

â”€â”€ NQL & EVA Compatibility (2026-02-21) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NQL-1 MERGE statement (ON CREATE/ON MATCH)  âœ… COMPLETE  (node + edge MERGE with upsert)
NQL-2 Multi-hop typed path (*1..4)          âœ… COMPLETE  (BFS with depth + label filter)
NQL-3 SET with arithmetic expressions       âœ… COMPLETE  (n.count = n.count + 1, per-node eval)
NQL-4 CREATE with TTL support               âœ… COMPLETE  (ttl property â†’ expires_at auto-compute)
NQL-5 DETACH DELETE                         âœ… COMPLETE  (node + all incident edges)
NQL-6 Edge property access in WHERE/RETURN  âœ… COMPLETE  (edge alias -[r:TYPE]-> with r.field)
NQL-7 ORDER BY on edge properties           âœ… COMPLETE  (r.weight, r.created_at, etc.)
Ph.C  Redis-compatible cache RPCs           âœ… COMPLETE  (CacheSet/Get/Del + ReapExpired)
Ph.F  Sensory RPCs (fully connected)        âœ… COMPLETE  (insert/get/reconstruct/degrade)
Ph.G  Per-collection RwLock concurrency     âœ… COMPLETE  (DashMap + tokio::sync::RwLock)

â”€â”€ AGI & Advanced Features Sprint (2026-02-22) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AGI-1 EnergyCircuitBreaker (anti-tumor)    âœ… COMPLETE  (depth caps, BFS tumor detection, dampening)
AGI-2 Hegelian Dialectic Engine            âœ… COMPLETE  (contradictionâ†’tensionâ†’synthesis pipeline)
AGI-3 Semantic CRDTs (cluster merge)       âœ… COMPLETE  (add-wins, max-energy, phantom-add-wins)
AGI-4 Code-as-Data (NQL-as-node)           âœ… COMPLETE  (activatable queries, cooldown, exhaustion)
AGI-5 SchrÃ¶dinger Edges                    âœ… COMPLETE  (probabilistic collapse, decay, reinforce)
AGI-6 Valence/Arousal (emotional vectors)  âœ… COMPLETE  (diffusion modulation, Laplacian weighting)

â”€â”€ Multi-Manifold Sprint (2026-02-22) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MM-1  Klein model (pathfinding)            âœ… COMPLETE  (to_klein, to_poincare, colinearity O(1), 10 tests)
MM-2  Riemann sphere (synthesis)           âœ… COMPLETE  (synthesis, synthesis_multi, FrÃ©chet mean, 10 tests)
MM-3  Minkowski spacetime (causality)      âœ… COMPLETE  (dsÂ², classify, light_cone_filter, 8 tests)
MM-4  Manifold normalization layer         âœ… COMPLETE  (health checks, safe roundtrips, 10x error < 1e-4)
MM-5  Edge causality metadata              âœ… COMPLETE  (CausalType enum, minkowski_interval on Edge)
MM-6  6 new gRPC RPCs                      âœ… COMPLETE  (Synthesis, SynthesisMulti, CausalNeighbors, CausalChain, KleinPath, IsOnShortestPath)
MM-7  Go SDK manifold methods              âœ… COMPLETE  (6 methods + types + proto sync)
```

---

## Benchmarks

Run all benchmarks:
```bash
cargo bench --workspace
```

Individual suites:

| Suite | Command |
|---|---|
| Graph engine | `cargo bench -p nietzsche-graph` |
| Riemannian ops | `cargo bench -p nietzsche-sleep` |
| Chebyshev / diffusion | `cargo bench -p nietzsche-pregel` |
| Hyperbolic math | `cargo bench -p nietzsche-hyp-ops` |
| Distance metrics | `cargo bench -p hyperspace-core` |

### Representative results (ring graph, Apple M2)

| Benchmark | N | Time |
|---|---|---|
| `graph/insert_node` | 1 | ~18 us |
| `graph/insert_node_batch` | 100 | ~1.4 ms |
| `graph/scan_nodes` | 500 | ~3.8 ms |
| `graph/bfs` | chain-50 | ~52 us |
| `graph/dijkstra` | chain-50 | ~81 us |
| `riemannian/exp_map` | dim=256 | ~420 ns |
| `riemannian/adam_10_steps` | dim=64 | ~6.2 us |
| `chebyshev/apply_heat_kernel` | ring-40 | ~210 us |
| `chebyshev/laplacian_build` | ring-50 | ~390 us |

---

## Production Deployment

### Docker Compose (recommended)

```yaml
# docker-compose.yaml
services:
  nietzsche:
    build: .
    ports:
      - "50052:50051"   # gRPC
      - "8080:8080"     # HTTP dashboard
    environment:
      NIETZSCHE_DATA_DIR:            /data/nietzsche
      NIETZSCHE_PORT:                "50051"
      NIETZSCHE_DASHBOARD_PORT:      "8080"
      NIETZSCHE_SLEEP_INTERVAL_SECS: "300"
      ZARATUSTRA_INTERVAL_SECS:      "600"
    volumes:
      - nietzsche_data:/data/nietzsche

  hyperspace:
    build:
      context: .
      dockerfile: deploy/docker/Dockerfile
    ports:
      - "50051:50051"
      - "50050:50050"
    environment:
      NIETZSCHE_ADDR: http://nietzsche:50052
    depends_on:
      - nietzsche
    volumes:
      - hyperspace_data:/data/hyperspace

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
```

### Docker (standalone)

```bash
# Build
docker build -t nietzsche-db:latest .

# Run
docker run -d \
  -p 50051:50051 \
  -p 8080:8080 \
  -v /data/nietzsche:/data/nietzsche \
  -e NIETZSCHE_LOG_LEVEL=info \
  -e NIETZSCHE_SLEEP_INTERVAL_SECS=300 \
  -e NIETZSCHE_DASHBOARD_PORT=8080 \
  --name nietzsche-db \
  nietzsche-db:latest
```

### Environment Variables

| Variable | Default | Description |
|---|---|---|
| `NIETZSCHE_DATA_DIR` | `/data/nietzsche` | RocksDB + WAL + collections root |
| `NIETZSCHE_PORT` | `50051` | gRPC listen port |
| `NIETZSCHE_DASHBOARD_PORT` | `8080` | HTTP dashboard port (0 = disabled) |
| `NIETZSCHE_LOG_LEVEL` | `info` | Tracing filter (`trace`, `debug`, `info`, `warn`, `error`) |
| `NIETZSCHE_SLEEP_INTERVAL_SECS` | `0` | Sleep cycle interval in seconds (0 = disabled) |
| `NIETZSCHE_SLEEP_NOISE` | `0.02` | Tangent-space perturbation magnitude |
| `NIETZSCHE_SLEEP_ADAM_STEPS` | `10` | RiemannianAdam steps per sleep cycle |
| `NIETZSCHE_HAUSDORFF_THRESHOLD` | `0.15` | Max delta-hausdorff before rollback |
| `NIETZSCHE_MAX_CONNECTIONS` | `1024` | Maximum concurrent gRPC connections |
| `NIETZSCHE_VECTOR_BACKEND` | `embedded` | `embedded` (HNSW), `gpu`, `tpu`, or empty (mock) |
| `NIETZSCHE_API_KEY` | â€” | Admin auth token for gRPC (backward compat) |
| `NIETZSCHE_API_KEY_ADMIN` | â€” | Admin role API key |
| `NIETZSCHE_API_KEY_WRITER` | â€” | Writer role API key (read + mutate) |
| `NIETZSCHE_API_KEY_READER` | â€” | Reader role API key (read only) |
| `NIETZSCHE_ENCRYPTION_KEY` | â€” | Base64-encoded 32-byte AES master key (empty = disabled) |
| `NIETZSCHE_TTL_REAPER_INTERVAL_SECS` | `60` | TTL reaper scan interval (0 = disabled) |
| `NIETZSCHE_BACKUP_INTERVAL_SECS` | `0` | Automatic backup interval (0 = disabled) |
| `NIETZSCHE_BACKUP_RETENTION_COUNT` | `5` | Max backups to keep (older ones pruned) |
| `NIETZSCHE_INDEXED_FIELDS` | â€” | CSV of metadata fields to index (e.g. `created_at,category`) |
| `ZARATUSTRA_INTERVAL_SECS` | `600` | Zaratustra cycle interval (0 = disabled) |
| `NIETZSCHE_CLUSTER_ENABLED` | `false` | Enable cluster mode |
| `NIETZSCHE_CLUSTER_NODE_NAME` | `nietzsche-0` | Human-readable node name |
| `NIETZSCHE_CLUSTER_ROLE` | `primary` | `primary`, `replica`, or `coordinator` |
| `NIETZSCHE_CLUSTER_SEEDS` | â€” | Comma-separated seed peer addresses |
| `PJRT_PLUGIN_PATH` | â€” | Path to `libtpu.so` for TPU backend |

### Health Check

```bash
# gRPC health (requires grpcurl)
grpcurl -plaintext localhost:50051 nietzsche.NietzscheDB/HealthCheck

# HTTP dashboard health
curl http://localhost:8080/api/health

# List all collections
curl http://localhost:8080/api/collections

# Graph data for visualization
curl "http://localhost:8080/api/graph?collection=eva_core&limit=500"
```

### CI / CD

**`.github/workflows/ci.yml`** â€” runs on every PR:

| Job | What it does |
|---|---|
| `lint` | `cargo fmt --check` + `cargo clippy -D warnings` |
| `test` | `cargo test --workspace --all-features` (requires `protoc` + `libclang`) |
| `bench-dry-run` | `cargo bench --no-run --workspace` (compile check) |
| `docker` | `docker build` (validates Dockerfile; no push on PRs) |

**`.github/workflows/deploy-gcp.yml`** â€” runs on push to `main`:

| Job | What it does |
|---|---|
| `build-and-push` | Builds Docker image, pushes to GCP Artifact Registry via WIF |
| `deploy` | SSH into GCP VM via OS Login, runs `docker compose up -d` |
| Health check | Verifies `GET /api/health` returns 200 |

---

## GPU Acceleration

NietzscheDB supports GPU-accelerated vector search via **NVIDIA cuVS CAGRA** and GPU graph traversal via **NVIDIA cuGraph**.

### Vector Search â€” `nietzsche-hnsw-gpu`

```
Insert â†’ CPU staging buffer (Vec<f32>)
               â”‚
               â”œâ”€â”€ n < 1,000 vectors  â†’ CPU linear scan
               â””â”€â”€ n >= 1,000 vectors â†’ CAGRA build on GPU (lazy, on first knn)
                                         â””â”€â”€ GPU search â†’ results back to CPU
```

- Lazy CAGRA index build: only constructs GPU index when first k-NN query arrives
- Dirty ratio rebuild: reconstructs when >= 10% of index modified
- Automatic fallback to CPU if GPU fails

### Graph Traversal â€” `nietzsche-cugraph`

- GPU-accelerated BFS, Dijkstra, PageRank via cuGraph FFI
- Custom CUDA kernel for Poincare distance computation (compiled via NVRTC)
- Dynamic `libcugraph.so` loading at runtime

### Build (GCP / Linux)

```bash
# 1. CUDA Toolkit 12.x + cuVS 24.6
apt-get install -y clang libclang-dev

# 2. Build with GPU support
cargo build --release --features gpu

# 3. Run with GPU backend
NIETZSCHE_VECTOR_BACKEND=gpu ./target/release/nietzsche-server
```

### Docker (GPU)

```dockerfile
# Dockerfile.gpu
FROM nvidia/cuda:12.4-devel-ubuntu22.04 AS builder
RUN apt-get update && apt-get install -y clang libclang-dev curl
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --default-toolchain nightly
COPY . .
RUN cargo build --release --features gpu

FROM nvidia/cuda:12.4-runtime-ubuntu22.04
COPY --from=builder /target/release/nietzsche-server /usr/local/bin/
EXPOSE 50051 8080
CMD ["nietzsche-server"]
```

```yaml
# docker-compose.gpu.yml
services:
  nietzsche-server:
    image: nietzsche-server:gpu
    runtime: nvidia
    environment:
      NIETZSCHE_VECTOR_BACKEND: gpu
      NIETZSCHE_DATA_DIR: /data/nietzsche
    ports:
      - "50051:50051"
      - "8080:8080"
    volumes:
      - nietzsche_data:/data/nietzsche
```

### GCP GPU Instance Recommendation

| Instance | GPU | VRAM | Best for |
|---|---|---|---|
| `g2-standard-4` | L4 | 24 GB | Production â€” best price/perf |
| `n1-standard-4` + T4 | T4 | 16 GB | Budget option |
| `a2-highgpu-1g` | A100 | 40 GB | Large-scale datasets |

### Feature Flags

```toml
# nietzsche-server/Cargo.toml
[features]
gpu = ["dep:nietzsche-hnsw-gpu"]   # enables GPU injection in main.rs

# nietzsche-hnsw-gpu/Cargo.toml
[features]
cuda = ["dep:cuvs", "dep:ndarray"] # enables actual CUDA calls
```

---

## TPU Acceleration

NietzscheDB supports Google **TPU**-accelerated vector search via the **PJRT C API**, targeting Cloud TPU VMs (v5e, v6e Trillium, v7 Ironwood).

### Architecture

```
Insert â†’ CPU staging buffer (Vec<f32>)
               â”‚
               â”œâ”€â”€ n < 1,000 vectors  â†’ CPU linear scan
               â””â”€â”€ n >= 1,000 vectors â†’ lazy MHLO compile (once)
                                         â”œâ”€â”€ upload %query  â†’ TPU
                                         â”œâ”€â”€ upload %matrix â†’ TPU
                                         â”œâ”€â”€ execute MHLO kernel
                                         â””â”€â”€ CPU: L2 norm correction
```

### Hardware Targets

| TPU | Generation | HBM |
|---|---|---|
| v5e | 5th gen | 16 GB/chip |
| v6e | Trillium | 32 GB/chip |
| v7 | **Ironwood** | **192 GB/chip** |

### Build (Cloud TPU VM)

```bash
PJRT_PLUGIN_PATH=/lib/libtpu.so \
cargo build --release --features tpu

PJRT_PLUGIN_PATH=/lib/libtpu.so \
NIETZSCHE_VECTOR_BACKEND=tpu \
./target/release/nietzsche-server
```

### Feature Flags

```toml
# nietzsche-server/Cargo.toml
[features]
tpu = ["dep:nietzsche-tpu", "nietzsche-tpu/tpu"]

# nietzsche-tpu/Cargo.toml
[features]
tpu = ["dep:pjrt"]
```

### GPU vs TPU

| Feature | GPU (cuVS CAGRA) | TPU (PJRT MHLO) |
|---|---|---|
| Index type | ANN graph (HNSW-like) | Exact dot-product batch |
| Best for | Ultra-low latency, single query | High throughput, large batch |
| Memory | GPU VRAM (CUDA managed) | TPU HBM (192 GB on Ironwood) |
| Cloud | GCP GPU instances | GCP Cloud TPU VMs |
| Feature flag | `--features gpu` | `--features tpu` |
| Env var | `NIETZSCHE_VECTOR_BACKEND=gpu` | `NIETZSCHE_VECTOR_BACKEND=tpu` |

CPU-only build (default) compiles and runs correctly â€” GPU/TPU paths simply not activated.

---

## Codebase Structure

```
NietzscheDB/
â”œâ”€â”€ Cargo.toml                â† unified Rust workspace (38 crates)
â”œâ”€â”€ rust-toolchain.toml       â† nightly channel
â”œâ”€â”€ Dockerfile                â† multi-stage production image
â”œâ”€â”€ docker-compose.yaml       â† nietzsche + hyperspace + prometheus + grafana
â”œâ”€â”€ .github/workflows/        â† CI + deploy pipelines
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ hyperspace-core/      â† Poincare HNSW, distance metrics, SIMD
â”‚   â”œâ”€â”€ hyperspace-store/     â† mmap segments, WAL v3
â”‚   â”œâ”€â”€ hyperspace-index/     â† HNSW graph, ArcSwap lock-free updates
â”‚   â”œâ”€â”€ hyperspace-server/    â† gRPC server, multi-tenancy, replication
â”‚   â”œâ”€â”€ hyperspace-proto/     â† protobuf definitions
â”‚   â”œâ”€â”€ hyperspace-cli/       â† CLI tools (ratatui TUI)
â”‚   â”œâ”€â”€ hyperspace-embed/     â† ONNX + remote embedding
â”‚   â”œâ”€â”€ hyperspace-wasm/      â† WASM / browser / IndexedDB
â”‚   â”œâ”€â”€ hyperspace-sdk/       â† HyperspaceDB Rust client
â”‚   â”œâ”€â”€ nietzsche-graph/      â† multi-manifold graph engine     [Phases 1-3]
â”‚   â”œâ”€â”€ nietzsche-hyp-ops/    â† multi-manifold geometry (PoincarÃ©Â·KleinÂ·RiemannÂ·Minkowski)
â”‚   â”œâ”€â”€ nietzsche-query/      â† NQL parser + executor           [Phase 4]
â”‚   â”œâ”€â”€ nietzsche-lsystem/    â† L-System + Hausdorff pruning    [Phase 5]
â”‚   â”œâ”€â”€ nietzsche-pregel/     â† heat kernel diffusion           [Phase 6]
â”‚   â”œâ”€â”€ nietzsche-sleep/      â† sleep/reconsolidation cycle     [Phase 8]
â”‚   â”œâ”€â”€ nietzsche-zaratustra/ â† autonomous evolution engine     [Phase Z]
â”‚   â”œâ”€â”€ nietzsche-algo/       â† 11 graph algorithms
â”‚   â”œâ”€â”€ nietzsche-sensory/    â† sensory compression layer       [Phase 11]
â”‚   â”œâ”€â”€ nietzsche-cluster/    â† gossip cluster foundation       [Phase G]
â”‚   â”œâ”€â”€ nietzsche-wiederkehr/ â† DAEMON agents + Will to Power scheduler
â”‚   â”œâ”€â”€ nietzsche-dream/      â† dream queries (speculative exploration)
â”‚   â”œâ”€â”€ nietzsche-narrative/  â† narrative engine (story arc detection)
â”‚   â”œâ”€â”€ nietzsche-agency/     â† autonomous agency + counterfactual engine
â”‚   â”œâ”€â”€ nietzsche-mcp/        â† MCP server for AI assistants (19 tools)
â”‚   â”œâ”€â”€ nietzsche-metrics/    â† Prometheus/OpenTelemetry metrics export
â”‚   â”œâ”€â”€ nietzsche-filtered-knn/ â† filtered KNN with Roaring Bitmaps
â”‚   â”œâ”€â”€ nietzsche-named-vectors/ â† multi-vector per node
â”‚   â”œâ”€â”€ nietzsche-pq/         â† Product Quantization (magnitude-preserving)
â”‚   â”œâ”€â”€ nietzsche-secondary-idx/ â† secondary indexes by arbitrary field
â”‚   â”œâ”€â”€ nietzsche-kafka/      â† Kafka Connect sink (CDC streaming)
â”‚   â”œâ”€â”€ nietzsche-table/      â† relational table store (SQLite)
â”‚   â”œâ”€â”€ nietzsche-media/      â† media/blob store (OpenDAL: S3, GCS, local)
â”‚   â”œâ”€â”€ nietzsche-api/        â† unified gRPC API (71+ RPCs)
â”‚   â”œâ”€â”€ nietzsche-sdk/        â† Rust client SDK
â”‚   â”œâ”€â”€ nietzsche-server/     â† production binary + dashboard
â”‚   â”œâ”€â”€ nietzsche-hnsw-gpu/   â† GPU vector search (cuVS CAGRA)
â”‚   â”œâ”€â”€ nietzsche-tpu/        â† TPU vector search (PJRT)
â”‚   â””â”€â”€ nietzsche-cugraph/    â† GPU graph traversal (cuGraph)
â”œâ”€â”€ dashboard/                â† React 19 + Cosmograph 2.1 + Tailwind 4
â”‚   â”œâ”€â”€ src/pages/            â† Overview, Collections, Nodes, Graph, Data, Settings
â”‚   â””â”€â”€ dist/                 â† single-file HTML (embedded in binary)
â”œâ”€â”€ sdks/
â”‚   â”œâ”€â”€ go/                   â† sdk-papa-caolho (71+ RPCs, full coverage)
â”‚   â”œâ”€â”€ python/               â† gRPC client + proto generation
â”‚   â”œâ”€â”€ ts/                   â† TypeScript SDK
â”‚   â””â”€â”€ cpp/                  â† C++ SDK
â”œâ”€â”€ scripts/                  â† benchmark, build-dashboard, build-wasm, verify
â”œâ”€â”€ benchmarks/               â† reproducible benchmark suite
â”œâ”€â”€ integrations/             â† LangChain Python + JS, LlamaIndex
â”œâ”€â”€ deploy/                   â† Docker, Kubernetes, WIF setup
â”œâ”€â”€ docs/                     â† NQL reference, architecture
â””â”€â”€ examples/                 â† HiveMind Tauri app, Python, TypeScript
```

---

## Build Profiles

```toml
# Release (production)
[profile.release]
lto = true
codegen-units = 1
strip = true
panic = "abort"
opt-level = 3

# Bench-fast (CI benchmarks)
[profile.bench-fast]
inherits = "release"
lto = "thin"
codegen-units = 4

# Perf (maximum native CPU optimization)
[profile.perf]
inherits = "release"
# RUSTFLAGS="-C target-cpu=native"
```

---

## Research Context: The Non-Euclidean Revolution

NietzscheDB closes gaps that no existing database fills. It is built on the realization that **Intelligence is not flat**.

- **Multi-Manifold Native**: While every other vector database (Qdrant, Milvus, Pinecone) uses Euclidean or Cosine distance as a flat metric, NietzscheDB operates across 4 non-Euclidean geometries: PoincarÃ© (Hierarchy), Klein (Straight-line Logic), Riemann (Synthesis), and Minkowski (Causality).
- **The Visual Audit Gap**: Traditional databases are black boxes. NietzscheDB integrates **Perspektive.js** as its Visual Cortex, allowing humans to physically see the database manifolds and audit decision-making via the Causal Scrubber.
- **Autonomous Metabolism**: NietzscheDB implements a formal **Sleep/Reconsolidation Cycle**. It doesn't just store data; it organizes it during downtime using Riemannian optimization and Hausdorff identity verification.
- **Dialectical Reasoning**: The built-in **Hegelian Dialectic Engine** allows the database to resolve contradictions by synthesizing opposites into abstract "synthesis" nodes.
- **Emotional Physics**: Valence and arousal fields on nodes alter heat diffusion propagation. Knowledge that "matters" (high arousal) spreads faster through the memory, mirroring biological cognitive priority.

### Key References & Inspiration
- **Hyperbolic Geometry of Complex Networks** (Krioukov et al., 2010)
- **Hyperbolic Neural Networks** (Ganea et al., NeurIPS 2018)
- **Riemannian Adaptive Optimization** (Becigneul & Ganea, ICLR 2019)
- **Beyond Euclidean Embeddings** â€” The foundation of Nietzsche's *Perspectivism* as a computational paradigm.

---

## Git Remotes

```bash
origin    https://github.com/JoseRFJuniorLLMs/NietzscheDB.git   # NietzscheDB Manifesto repo
upstream  https://github.com/YARlabs/hyperspace-db.git          # Upstream HNSW foundation
```

---

## License

NietzscheDB is licensed under the **AGPL-3.0**.  
Developed as the memory core for the **EVA AGI System**.

---

<p align="center">
  <img src="img/logo.jpg" alt="NietzscheDB" width="120px" /><br>
  <em>"He who has a why to live can bear almost any how."</em><br>
  â€” <strong>Friedrich Nietzsche</strong>
</p>

<p align="center">
  <strong>Retina of the AGI</strong> Â· Powered by <strong>Rust nightly</strong> Â· <strong>Perspektive.js 0.1.3</strong> Â· <strong>4 Manifolds</strong> Â· <strong>MCP + gRPC</strong> Â· <strong>GPU/TPU</strong> Â· <strong>Hegelian Engine</strong>
</p>
