<p align="center">
  <img src="img/logo.jpg" alt="NietzscheDB" width="100%"/>
</p>

<p align="center">
  <img src="img/nietzschedb.gif" alt="NietzscheDB Demo" width="480"/>
</p>

<h1 align="center">NietzscheDB</h1>

<p align="center">
  <strong>The Multi-Manifold Graph Database for AGI</strong>
</p>

<p align="center">
  <em>Euclidean geometry failed. The world isn't flat, and neither is intelligence.</em>
</p>

<p align="center">
  <a href="https://github.com/JoseRFJuniorLLMs/NietzscheDB/blob/main/LICENSE_AGPLv3.md"><img src="https://badge.fury.io/js/perspektive.svg" alt="perspektive.js"></a>
  <a href="https://www.npmjs.com/package/perspektive"><img src="https://img.shields.io/npm/v/perspektive?color=00d8ff&style=flat-square" alt="NPM Version"></a>
  <a href="https://www.rust-lang.org/"><img src="https://img.shields.io/badge/built%20with-Rust%20nightly-orange.svg" alt="Rust"></a>
  <img src="https://img.shields.io/badge/geometry-Poincar%C3%A9%20%C2%B7%20Klein%20%C2%B7%20Riemann%20%C2%B7%20Minkowski-purple.svg" alt="Multi-Manifold">
  <img src="https://img.shields.io/badge/GPU-cuVS%20CAGRA-76b900.svg" alt="GPU">
  <img src="https://img.shields.io/badge/TPU-PJRT%20Ironwood-4285F4.svg" alt="TPU">
</p>

---

## ğŸ§  The Manifesto: Why Nietzsche?

> *"There are no facts, only interpretations."*  
> â€” Friedrich Nietzsche, **Notebooks**, 1886

> *"If Zarathustra descended from the mountain to announce the Ãœbermensch, NietzscheDB descended from GitHub to announce Non-Euclidean AGI."*  
> â€” **Jose R F Junior**

> *"Are you trying to make AGI with boring tables and vectors? I'm going to do it with dynamite and curved geometry."*  
> â€” **Jose R F Junior**

Standard databases store data as "static facts" in flat, Euclidean spaces. This is a geometric lie. In high-dimensional intelligence, a concept is defined solely by its relationship to others, and its position is relative to the observer's depth of abstraction.

NietzscheDB implements **Perspektivismus** (Perspectivism) as a database primitive. It abandons the "God's-eye view" of a single flat table for a **Multi-Manifold Architecture**, where the same piece of knowledge can be viewed through different geometric lenses depending on the cognitive need.

---

NietzscheDB is powered by **[perspektive.js](https://github.com/JoseRFJuniorLLMs/perspektive.js)**, the world's most advanced multi-manifold graph renderer. It serves as the AGI's "retina," allowing you to audit, debug, and explore the internal manifolds of the database at 60fps.

<p align="center">
  <img src="https://raw.githubusercontent.com/JoseRFJuniorLLMs/perspektive.js/main/img/logo.gif" alt="Visual Cortex" width="600px"/>
</p>

### Advanced Auditing Tools:
- â³ **Causal Scrubber (Minkowski Time Machine)**: Scrub through the database history. Watch nodes dissolve and reform as you rewind the chain of causal reasoning.
- ğŸ”€ **Counterfactual UI**: Drag-and-drop nodes to create "What-If" hypotheses. Generate ephemeral edges to simulate new realities without mutating the core graph.
- ğŸŒŒ **Fractal Viewport**: Infinite zoom into the PoincarÃ© boundary. As the brain grows, the renderer streams new subgraphs dynamically (Google Maps for Memory).
- âš›ï¸ **Probability Clouds**: Volumetric GLSL raymarching visualize quantum fidelity and semantic arousal on the Bloch Sphere.

---

## ğŸŒ The 4 Geometric Perspectives

NietzscheDB doesn't just store data; it projects it across four distinct manifolds to solve specific AGI problems:

| Lens | Geometry | Manifold | AGI Role |
|---|---|---|---|
| ğŸŒŒ **Hierarchy** | PoincarÃ© Ball | Hyperbolic (K < 0) | **Abstraction Level**: Depth = Generality. Center = Foundation, Border = Detail. |
| ğŸ§­ **Logic** | Klein Model | Hyperbolic (K < 0) | **Reasoning**: Semantic paths are straight lines. O(1) collinearity checks. |
| â³ **Causality** | Minkowski | Lorentzian (Flat) | **Auditability**: Light cone filters ensure effect never precedes cause. |
| âš›ï¸ **Synthesis** | Riemann Sphere | Spherical (K > 0) | **Dialectics**: Where thesis and antithesis merge into a shallower, more abstract point. |

---

## ğŸš€ Key Features

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚           MULTI-MANIFOLD GRAPH DATABASE                â”‚
â”‚    PoincarÃ© Â· Klein Â· Riemann Â· Minkowski              â”‚
â”‚                                                         â”‚
â”‚   Â· Perspektive.js 0.1.3 native visual cortex          â”‚
â”‚   Â· Causal Scrubber (Minkowski Time Machine)           â”‚
â”‚   Â· Counterfactual UI (Speculative Reasoning)          â”‚
â”‚   Â· Autonomous fractal growth via L-System rules        â”‚
â”‚   Â· Multi-scale search via hyperbolic heat diffusion    â”‚
â”‚   Â· Active memory reconsolidation during sleep cycles   â”‚
â”‚   Â· GPU (cuVS) / TPU (PJRT) accelerated vector search   â”‚
â”‚   Â· Hegelian Dialectic Engine (automated synthesis)     â”‚
â”‚   Â· Code-as-Data: NQL queries as activatable nodes      â”‚
â”‚   Â· SchrÃ¶dinger Edges (probabilistic context collapse)  â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**NietzscheDB closes the interpretability gap.** It allows you to see the abyss â€” and ensures that when you look into the database, the database (geometrically) looks back at you.

---

## ğŸ§  Neuro-Symbolic Intelligence: Beyond Vectors

NietzscheDB is a **Neuro-Symbolic** engine. It bridges the gap between neural perception (embeddings/GNNs) and symbolic reasoning (graph topology/Manifolds).

### Integrated ML Models:
- ğŸ•¸ï¸ **Neural Foundation (GNN)**: A native Graph Neural Network that learns node representations directly on the hyperbolic manifold, optimized for high-dimensional hierarchical relationships.
- ğŸ¯ **Value Network**: A predictive model that estimates the "Energy" and "Will to Power" of nodes, identifying elite concepts and guiding the autonomous pruning process.
- ğŸ§ª **Zero-Data Pipeline**: Built-in orchestration to generate synthetic clinical data, distill it through classical algorithms, and train the neural core without external data dependencies.
- ğŸŒ«ï¸ **Diffusion Engine**: Real-time Pregel-like heat kernel propagation that simulates neural activation across the graph, modulated by emotional valence and arousal.

---

- Abstract concepts naturally live near the center of the PoincarÃ© ball
- Specific memories live near the boundary
- Hierarchical distance is intrinsic â€” not encoded, but *geometric*
- The knowledge graph grows and prunes itself like a fractal organism
- The system "sleeps" and reconsolidates its own memory topology
- An autonomous evolution cycle (Zaratustra) propagates energy, captures temporal echoes, and identifies elite nodes
- Causal relationships are identified via Minkowski intervals (dsÂ² < 0 = timelike = causal)

It is a fork of **[YARlabs/nietzsche-db](https://github.com/YARlabs/nietzsche-db)** â€” extended from a hyperbolic HNSW vector database into the world's first **multi-manifold graph database** with a full graph engine, query language, L-System growth, 4 non-Euclidean geometries, GPU/TPU acceleration, graph algorithms, cluster support, and an autonomous sleep/reconsolidation cycle.

---

## Why EVA Needs This

| Problem | Standard Vector DB | NietzscheDB |
|---|---|---|
| **Hierarchy** | Flat â€” same depth for all | Geometric â€” depth = abstraction level (PoincarÃ©) |
| **Logic/Reasoning** | Cosine similarity only | Multi-manifold (Klein Model) + straight-line semantic paths |
| **Causal Auditability** | None | Minkowski light cone filters (WHY / What-If) |
| **Observability** | JSON Logs / Dashboards | **Perspektive.js Visual Cortex** (60fps multi-manifold auditing) |
| **Hypothetical Reasoning**| Manual data cloning | **Counterfactual UI** (ShadowGraph overlays) |
| **Temporal Scrubbing** | Time filtering | **Causal Scrubber** (Minkowski Time Machine) |
| **Knowledge Growth** | Static inserts | L-System self-organizing fractal growth |
| **Memory Pruning** | Manual/TTL deletion | Hausdorff dimension self-pruning |
| **Consolidation** | No concept | Sleep Cycles (Riemannian reconsolidation) |
| **Conflict Resolution** | Last-write-wins | Hegelian Dialectic Engine (automated synthesis) |
| **Query Language** | k-NN / SQL / GraphQL | NQL (Multi-manifold, Diffusion, Speculative Dream) |
| **Hardware** | Generic CPU/GPU | cuVS (GPU) + PJRT Ironwood (TPU) backends |
| **Integration** | REST API | MCP (Model Context Protocol) + gRPC + REST |


---

## Architecture

NietzscheDB is built as a **Rust nightly workspace** with 41 crates in two layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         NietzscheDB Layer (32 crates)                        â”‚
â”‚                                                                              â”‚
â”‚  Engine:     nietzsche-graph    nietzsche-query     nietzsche-hyp-ops        â”‚
â”‚  Growth:     nietzsche-lsystem  nietzsche-pregel    nietzsche-sleep          â”‚
â”‚  Evolution:  nietzsche-zaratustra                                            â”‚
â”‚  Analytics:  nietzsche-algo     nietzsche-sensory                            â”‚
â”‚  Visionary:  nietzsche-dream    nietzsche-narrative  nietzsche-agency        â”‚
â”‚  Neural:     nietzsche-rl       nietzsche-neural    nietzsche-gnn            â”‚
â”‚  Wiederkehr: nietzsche-wiederkehr                                            â”‚
â”‚  Infra:      nietzsche-api      nietzsche-server    nietzsche-cluster        â”‚
â”‚  SDKs:       nietzsche-sdk      nietzsche-mcp                                â”‚
â”‚  Accel:      nietzsche-hnsw-gpu nietzsche-tpu       nietzsche-cugraph        â”‚
â”‚  Search:     nietzsche-filtered-knn  nietzsche-named-vectors  nietzsche-pq   â”‚
â”‚  Index:      nietzsche-secondary-idx                                         â”‚
â”‚  Observe:    nietzsche-metrics                                               â”‚
â”‚  Storage:    nietzsche-table    nietzsche-media      nietzsche-kafka          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     NietzscheDB Layer (9 crates â€” fork base)                â”‚
â”‚                                                                              â”‚
â”‚  nietzsche-core   nietzsche-hnsw   nietzsche-vecstore                       â”‚
â”‚  nietzsche-baseserver nietzsche-proto   nietzsche-cli                         â”‚
â”‚  nietzsche-embed  nietzsche-wasm    nietzsche-rsdk                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### NietzscheDB Foundation (fork base)

The storage and indexing foundation, inheriting all of NietzscheDB v2.0:

- **Poincare Ball HNSW** â€” native multi-manifold nearest-neighbor index. Not re-ranking, not post-processing: the graph itself navigates in non-Euclidean geometry (PoincarÃ© ball with Klein/Riemann/Minkowski projections at query time).
- **mmap Vector Store** â€” memory-mapped, append-only segments (`chunk_N.hyp`) with 1-bit to 8-bit quantization (up to 64x compression).
- **Write-Ahead Log v3** â€” binary `[Magic][Len][CRC32][Op][Data]` format with configurable durability and automatic crash recovery.
- **gRPC API** â€” async Command-Query Separation with background indexing. Client gets `OK` as soon as the WAL is written.
- **Leader-Follower Replication** â€” async anti-entropy via logical clocks and Merkle tree bucket sync (256 buckets).
- **SIMD Acceleration** â€” Portable SIMD (`std::simd`) for 4-8x distance computation speedup on AVX2/Neon.
- **Multi-tenancy** â€” namespace isolation per `user_id`, per-user quota and billing accounting.
- **9,087 QPS** insert performance verified under stress test (90x above original target).
- **WASM** â€” browser-compatible build via `nietzsche-wasm` with IndexedDB storage.
- **Universal Embedder** â€” `nietzsche-embed` with local ONNX (`ort`) + remote API support.

### NietzscheDB Extensions

Thirty-two new crates built on top of the foundation:

#### `nietzsche-graph` â€” Multi-Manifold Graph Engine
- `Node` = `NodeMeta` (~108 bytes: id, depth, energy, node_type, hausdorff_local, valence, arousal, content) + `PoincareVector` (embedding, stored separately for 10-25x traversal speedup)
- `PoincareVector` with `Vec<f32>` coords (distance kernel promotes to f64 internally for numerical stability near the Poincare boundary)
- `SparseVector` for SPLADE/sparse embeddings: sorted indices + values with O(nnz) dot product, cosine similarity, and L2 norm
- `Edge` typed as `Association`, `LSystemGenerated`, `Hierarchical`, or `Pruned`
- `AdjacencyIndex` using `DashMap` for lock-free concurrent access
- `GraphStorage` over RocksDB with **15 column families**: `nodes`, `embeddings`, `edges`, `adj_out`, `adj_in`, `meta`, `sensory`, `energy_idx`, `meta_idx`, `lists`, `sql_schema`, `sql_data`, `cooldowns`, `dsi_id`, `dsi_semantic`
- Own WAL for graph operations, separate from the vector WAL
- `NietzscheDB` dual-write: every insert goes to both RocksDB (graph) and NietzscheDB (embedding)
- **Traversal engine** (`traversal.rs`): energy-gated BFS (reads only NodeMeta â€” ~100 bytes per hop), Poincare-distance Dijkstra, shortest-path reconstruction, energy-biased `DiffusionWalk` with seeded RNG
- **EmbeddedVectorStore** abstraction: CPU (HnswIndex) / GPU (GpuVectorStore) / TPU (TpuVectorStore) / Mock â€” selected at runtime via `NIETZSCHE_VECTOR_BACKEND`. Default is Embedded (real HNSW); Mock requires explicit opt-in
- **Multi-Metric HNSW**: Cosine, Euclidean, Poincare, and DotProduct distance metrics per collection. Factory routing ensures correct metric type at the HNSW graph topology level
- **KNN metadata filter push-down**: `MetadataFilter` (Eq, In, Range, And) pushed through VectorStore â†’ DynHnsw â†’ HnswIndex with RoaringBitmap pre-filtering for efficient filtered vector search
- **MERGE upsert semantics**: `merge_node` (find-or-create by content), `merge_edge` (find-or-create by from/to/type) with ON CREATE SET / ON MATCH SET
- **Atomic edge metadata increment**: `increment_edge_metadata(edge_id, field, delta)` for counter patterns (e.g. `r.count = r.count + 1`)
- **Persistent secondary indexes**: `create_index(field)` / `drop_index(field)` / `list_indexes()` with automatic backfill and startup recovery from CF_META registry. NQL executor auto-detects indexed fields for O(log N) scans instead of full table scans
- **Encryption at-rest** (`encryption.rs`): AES-256-CTR with HKDF-SHA256 per-CF key derivation from master key (`NIETZSCHE_ENCRYPTION_KEY`)
- **Schema validation** (`schema.rs`): per-NodeType constraints (required fields, field types), persisted in CF_META, enforced on `insert_node`
- **Metadata secondary indexes** (`CF_META_IDX`): arbitrary field indexing with FNV-1a + sortable value encoding for range scans
- **ListStore** (`CF_LISTS`): per-node ordered lists with RPUSH/LRANGE/LLEN semantics, atomic sequence counters
- **TTL / expires_at** enforcement: background reaper scans expired nodes and phantomizes them (topology-preserving). CREATE with `ttl` property auto-computes `expires_at`
- **NietzscheDB-compatible cache layer**: `CacheSet`/`CacheGet`/`CacheDel` RPCs using CF_META with "cache:" prefix, TTL as 8-byte expiry timestamp, lazy-delete on expired reads
- **Per-collection `tokio::sync::RwLock` concurrency**: `CollectionManager` with `DashMap` + `Arc<RwLock<NietzscheDB>>` per collection. Reads proceed concurrently; writes block only the affected collection
- **Full-text search + hybrid** (`fulltext.rs`): inverted index with BM25 scoring, plus RRF fusion with KNN vector search
- **SchrÃ¶dinger Edges** (`schrodinger.rs`): probabilistic edges with Markov transition probabilities â€” edges are "superpositions" that collapse at MATCH time. Context-dependent probability boost, per-tick decay, reinforcement learning. Batch collapse/decay operations
- **Valence/Arousal** (`valence.rs`): emotional dimensions on NodeMeta â€” valence âˆˆ [-1, 1] (pleasure/displeasure) and arousal âˆˆ [0, 1] (intensity). Arousal amplifies `energy_bias` in `diffusion_walk()` (heat travels faster through emotional memories). Valence modulates Laplacian edge weights in spectral diffusion (matching-polarity edges boost heat conductivity). Includes `emotional_gravity()`, `decay_arousal()`, `reinforce_emotion()`
- **Query Stability & Gas Limits**: NQL query execution is protected by a `GasTracker` to prevent infinite recursion and resource exhaustion. Each node scan, edge traversal, and condition evaluation consumes a portion of the `DEFAULT_GAS_LIMIT` (50,000 units).

#### `nietzsche-hyp-ops` â€” Multi-Manifold Geometry Engine
Four non-Euclidean geometry modules sharing a single PoincarÃ© storage layer:

| Module | Geometry | Key Operations |
|---|---|---|
| `poincare` (core) | PoincarÃ© ball (K < 0) | Mobius addition, exp/log maps, geodesic distance, parallel transport |
| `klein` | Klein disk (K < 0) | `to_klein`/`to_poincare`, colinearity check O(1), straight-line pathfinding |
| `riemann` | Unit sphere (K > 0) | Spherical midpoint, FrÃ©chet mean, dialectical `synthesis`/`synthesis_multi` |
| `minkowski` | Minkowski spacetime | `dsÂ² = -cÂ²Î”tÂ² + â€–Î”xâ€–Â²`, causal classification (Timelike/Spacelike/Lightlike), light cone filter |
| `manifold` | Normalization layer | `normalize_poincare`/`klein`/`sphere`, health checks, safe roundtrip projections |

Invariants enforced: PoincarÃ© â€–xâ€– < 1.0, Klein â€–xâ€– < 1.0, Sphere â€–xâ€– = 1.0. Cascaded roundtrip error < 1e-4 after 10 projections. Includes criterion benchmarks.

#### `nietzsche-query` â€” NQL Query Language
Nietzsche Query Language â€” a declarative query language with first-class multi-manifold primitives. Parser built with `pest` (PEG grammar). **NQL 3.0** brings OPTIONAL MATCH, UNION, CASE WHEN, IS NULL/IS NOT NULL, regex matching, EXISTS subqueries, UNWIND, SHORTEST_PATH, COLLECT, 30+ string/math/cast/null built-in functions, and 5 new physicist-named cognitive functions â€” closing the gap with Cypher/GQL while preserving NQL's unique hyperbolic geometry primitives. Supports arithmetic SET expressions (`n.count = n.count + 1`), edge alias property access (`-[r:TYPE]->` with `r.weight` in WHERE/ORDER BY), CREATE with TTL, DETACH DELETE, and eval_field fallback to `node.content`/`node.metadata` for dynamic properties. 113+ unit + integration tests.

**[Full NQL Reference: docs/NQL.md](docs/NQL.md)**

Query types:

| Type | Description |
|---|---|
| `MATCH` | Pattern matching on nodes/paths with geometric conditions |
| `OPTIONAL MATCH` | Left-outer-join style pattern â€” returns NULL for non-matching bindings |
| `CREATE` | Insert new nodes with labels, properties, and optional TTL |
| `MATCH â€¦ SET` | Update matched nodes' properties (supports arithmetic: `n.count = n.count + 1`) |
| `MATCH â€¦ DELETE` | Delete matched nodes |
| `MATCH â€¦ DETACH DELETE` | Delete matched nodes and all incident edges |
| `MERGE` | Upsert nodes/edges (ON CREATE SET / ON MATCH SET) |
| `DIFFUSE` | Multi-scale heat-kernel activation propagation |
| `RECONSTRUCT` | Decode sensory data from latent vector |
| `EXPLAIN` | Return execution plan with cost estimates |
| `UNION / UNION ALL` | Combine results from multiple queries (with/without dedup) |
| `UNWIND` | Expand a list expression into individual rows |
| `SHORTEST_PATH` | Find shortest path between two node patterns |
| `MATCH ELITES` | Return top-energy elite nodes from the graph |
| `MEASURE TENSION` | Compute hyperbolic tension between two node patterns |
| `MEASURE TGC` | Compute Topological Generative Capacity of the graph |
| `FIND NEAREST` | K-NN search in hyperbolic space with optional namespace |
| `DREAM FROM` | Speculative graph exploration via heat-kernel diffusion with noise |
| `APPLY/REJECT DREAM` | Accept or discard dream simulation results |
| `TRANSLATE` | Cross-modal projection (Synesthesia) via Poincare ball log/exp map |
| `MATCH ... AS OF CYCLE` | Time-travel query on named snapshots (Eternal Return) |
| `COUNTERFACTUAL` | What-if query with ephemeral property overlays |
| `CREATE/DROP/SHOW DAEMON` | Autonomous daemon agents (Wiederkehr) |
| `SHOW ARCHETYPES` | List shared cross-collection archetypes |
| `SHARE ARCHETYPE` | Publish elite node for cross-collection discovery |
| `NARRATE` | Generate human-readable narrative from graph evolution |
| `PSYCHOANALYZE` | Return evolutionary lineage of a node (creation, connections, energy) |

```sql
-- Hyperbolic nearest-neighbor search with depth filter
MATCH (m:Memory)
WHERE HYPERBOLIC_DIST(m.embedding, $q) < 0.5
  AND m.depth > 0.6
  AND NOT m.node_type = "Pruned"
RETURN m
ORDER BY HYPERBOLIC_DIST(m.embedding, $q) ASC
LIMIT 10

-- Graph traversal: hierarchical expansion
MATCH (c:Concept)-[:Hierarchical]->(child)
WHERE c.energy > 0.7
RETURN child ORDER BY child.depth DESC LIMIT 20

-- IN / BETWEEN / string operators
MATCH (n)
WHERE n.node_type IN ("Semantic", "Episodic")
  AND n.energy BETWEEN 0.3 AND 0.9
  AND n.node_type STARTS_WITH "S"
RETURN n LIMIT 50

-- Aggregation with GROUP BY
MATCH (n)
RETURN n.node_type, COUNT(*) AS total, AVG(n.energy) AS avg_e
GROUP BY n.node_type
ORDER BY total DESC

-- Mathematician-named geometric functions
MATCH (n)
WHERE RIEMANN_CURVATURE(n) > 0.3
  AND HAUSDORFF_DIM(n) BETWEEN 1.2 AND 1.8
  AND DIRICHLET_ENERGY(n) < 0.1
RETURN n ORDER BY RIEMANN_CURVATURE(n) DESC LIMIT 10

-- Multi-hop path traversal (BFS 2..4 hops)
MATCH (a)-[:Association*2..4]->(b)
WHERE a.energy > 0.5
RETURN a, b LIMIT 50

-- Create a new node
CREATE (n:Episodic {title: "first meeting", source: "manual"})
RETURN n

-- Create with TTL (auto-expires after 3600 seconds)
CREATE (n:EvaSession {id: "sess_1", turn_count: 0, ttl: 3600})
RETURN n

-- Arithmetic SET (per-node evaluation)
MATCH (n:EvaSession {id: "sess_1"})
SET n.turn_count = n.turn_count + 1, n.status = "active"
RETURN n

-- Edge alias: access edge properties in WHERE/ORDER BY
MATCH (a:Person)-[r:MENTIONED]->(b:Topic)
WHERE r.weight > 0.5
RETURN a, b ORDER BY r.weight DESC LIMIT 10

-- Update matched nodes
MATCH (n:Semantic) WHERE n.energy < 0.1 SET n.energy = 0.5 RETURN n

-- DETACH DELETE (node + all incident edges)
MATCH (n:EvaSession) WHERE n.status = "expired" DETACH DELETE n

-- Delete expired nodes
MATCH (n) WHERE n.energy = 0.0 DELETE n

-- Time-based queries with NOW() and INTERVAL()
MATCH (n) WHERE n.created_at > NOW() - INTERVAL("7d") RETURN n LIMIT 50

-- EXPLAIN with cost estimates
EXPLAIN MATCH (n:Memory) WHERE n.energy > 0.3 RETURN n
-- â†’ NodeScan(label=Memory) -> Filter(conditions=1) | rows=~250, scan=EnergyIndexScan, index=CF_ENERGY_IDX, cost=~500Âµs

-- Multi-scale heat-kernel diffusion
DIFFUSE FROM $seed
  WITH t = [0.1, 1.0, 10.0]
  MAX_HOPS 6
RETURN path

-- Dream Queries â€” speculative exploration
DREAM FROM $seed DEPTH 5 NOISE 0.05
SHOW DREAMS
APPLY DREAM "dream_xxx"

-- Daemon Agents â€” autonomous graph patrols
CREATE DAEMON guardian ON (n:Memory)
  WHEN n.energy > 0.8
  THEN DIFFUSE FROM n WITH t=[0.1, 1.0] MAX_HOPS 5
  EVERY INTERVAL("1h")
  ENERGY 0.8
SHOW DAEMONS

-- Time-travel via named snapshots
MATCH (n:Memory) AS OF CYCLE 3
WHERE n.energy > 0.5
RETURN n

-- Narrative Engine
NARRATE IN "memories" WINDOW 24 FORMAT json

-- Evolutionary lineage of a node
PSYCHOANALYZE $node_id

-- Emotional memory search (high arousal, positive valence)
MATCH (n:Episodic)
WHERE n.arousal > 0.7 AND n.valence > 0.3
RETURN n ORDER BY n.arousal DESC LIMIT 10

-- Set emotional state on a memory
MATCH (n) WHERE n.id = $id
SET n.valence = 0.8, n.arousal = 0.9
RETURN n

-- â”€â”€ NQL 3.0 Features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

-- OPTIONAL MATCH (left-outer-join)
MATCH (a:Person)
OPTIONAL MATCH (a)-[:KNOWS]->(b)
RETURN a, b

-- UNION â€” combine two queries
MATCH (n:Semantic) WHERE n.energy > 0.8 RETURN n LIMIT 5
UNION
MATCH (n:Episodic) WHERE n.energy > 0.9 RETURN n LIMIT 5

-- IS NULL / IS NOT NULL
MATCH (n) WHERE n.title IS NOT NULL RETURN n LIMIT 20
MATCH (n) WHERE n.expires_at IS NULL RETURN n LIMIT 10

-- Regex matching
MATCH (n) WHERE n.title =~ "^neuro.*" RETURN n LIMIT 10

-- EXISTS subquery
MATCH (n) WHERE EXISTS { (n)-[:Association]->(m) } RETURN n

-- CASE WHEN expression
MATCH (n) RETURN n,
  CASE WHEN n.energy > 0.8 THEN "elite"
       WHEN n.energy > 0.5 THEN "active"
       ELSE "decay" END AS status
LIMIT 20

-- COLLECT aggregation (returns JSON array)
MATCH (n) RETURN n.node_type, COLLECT(n.energy) AS energies
GROUP BY n.node_type

-- UNWIND list into rows
UNWIND [1, 2, 3] AS x RETURN x

-- SHORTEST_PATH between two nodes
SHORTEST_PATH (a:Concept)-[*..5]->(b:Memory) LIMIT 1

-- MATCH ELITES â€” top-energy nodes
MATCH ELITES LIMIT 10

-- MEASURE TENSION between node types
MEASURE TENSION (a:Concept), (b:Memory)

-- MEASURE TGC â€” Topological Generative Capacity
MEASURE TGC

-- FIND NEAREST â€” hyperbolic k-NN
FIND NEAREST "concept" TARGET $query_vec LIMIT 5

-- String functions
MATCH (n) WHERE UPPER(n.title) = "NIETZSCHE" RETURN n
MATCH (n) RETURN n.title, LENGTH(n.title) AS len, REVERSE(n.title) AS rev LIMIT 10

-- Math functions
MATCH (n) RETURN n, ABS(n.energy - 0.5) AS dist, ROUND(n.depth, 2) AS rounded
MATCH (n) WHERE SQRT(n.energy) > 0.7 RETURN n

-- Cast functions
MATCH (n) RETURN TO_STRING(n.energy) AS e_str, TO_INT(n.depth * 100) AS d_pct

-- COALESCE (first non-null)
MATCH (n) RETURN COALESCE(n.title, n.name, "untitled") AS label

-- Physicist-named cognitive functions
MATCH (n) WHERE BOLTZMANN_SURVIVAL(n) > 0.5 RETURN n
MATCH (n) WHERE HELMHOLTZ_GRADIENT(n) > 0.1 RETURN n
MATCH (a), (b) WHERE LYAPUNOV_DELTA(a, b) < 0.3 RETURN a, b
MATCH (n) WHERE PRIGOGINE_BASIN(n) > 0.5 RETURN n
MATCH (a), (b) RETURN ERDOS_EDGE_PROB(a, b) AS prob
```

**Built-in geometric functions:**

| Function | Named after | Computes |
|---|---|---|
| `HYPERBOLIC_DIST(n.e, $q)` | â€” | Poincare ball geodesic distance |
| `POINCARE_DIST(n, $q)` | Henri Poincare | Same â€” explicit model name |
| `KLEIN_DIST(n, $q)` | Felix Klein | Beltrami-Klein distance |
| `RIEMANN_CURVATURE(n)` | Bernhard Riemann | Ollivier-Ricci curvature |
| `HAUSDORFF_DIM(n)` | Felix Hausdorff | Local fractal dimension |
| `GAUSS_KERNEL(n, t)` | Carl Friedrich Gauss | Heat kernel `exp(-d^2/4t)` |
| `CHEBYSHEV_COEFF(n, k)` | Pafnuty Chebyshev | Chebyshev polynomial T_k |
| `DIRICHLET_ENERGY(n)` | P.G.L. Dirichlet | Local Dirichlet energy |
| `EULER_CHAR(n)` | Leonhard Euler | V - E characteristic |
| `LAPLACIAN_SCORE(n)` | P.-S. Laplace | Graph Laplacian diagonal |
| `LOBACHEVSKY_ANGLE(n, $p)` | N. Lobachevsky | Angle of parallelism |
| `MINKOWSKI_NORM(n)` | H. Minkowski | Conformal factor |
| `RAMANUJAN_EXPANSION(n)` | S. Ramanujan | Spectral expansion ratio |
| `FOURIER_COEFF(n, k)` | J. Fourier | Graph Fourier coefficient |
| `NOW()` | â€” | Current Unix timestamp (seconds, f64) |
| `EPOCH_MS()` | â€” | Current Unix epoch (milliseconds, f64) |
| `INTERVAL("1h")` | â€” | Duration to seconds (s/m/h/d/w units) |
| `BOLTZMANN_SURVIVAL(n)` | Ludwig Boltzmann | Survival probability via energy statistics |
| `HELMHOLTZ_GRADIENT(n)` | Hermann von Helmholtz | Free-energy gradient magnitude |
| `LYAPUNOV_DELTA(a, b)` | Aleksandr Lyapunov | Stability divergence between two nodes |
| `PRIGOGINE_BASIN(n)` | Ilya Prigogine | Dissipative structure basin depth |
| `ERDOS_EDGE_PROB(a, b)` | Paul ErdÅ‘s | Edge formation probability (ErdÅ‘sâ€“RÃ©nyi) |
| `COALESCE(a, b, ...)` | â€” | First non-null value |
| `UPPER/LOWER/TRIM(s)` | â€” | String case/whitespace functions |
| `LENGTH/SUBSTRING/REPLACE` | â€” | String manipulation |
| `CONCAT/REVERSE/SPLIT` | â€” | String composition |
| `ABS/CEIL/FLOOR/ROUND` | â€” | Numeric rounding |
| `SQRT/LOG/LOG10/POW` | â€” | Mathematical functions |
| `SIGN/MOD` | â€” | Sign and modulus |
| `TO_INT/TO_FLOAT/TO_STRING/TO_BOOL` | â€” | Type casting |
| `CASE WHEN ... THEN ... END` | â€” | Conditional expression |
| `COLLECT(expr)` | â€” | Aggregate into JSON array |

#### `nietzsche-lsystem` â€” Fractal Growth Engine
The knowledge graph is not static â€” it grows by **L-System production rules**:
- `ProductionRule` fires when `EnergyAbove(t)`, `DepthBelow(t)`, `HausdorffAbove(t)`, or custom conditions (`And`, `Or`, `Not`, `Always`)
- `SpawnChild` places the child node deeper in the Poincare ball (more specific, closer to boundary) via **Mobius addition** `u + v`
- `SpawnSibling` creates lateral associations at a given hyperbolic angle
- `Prune` archives low-complexity regions (not deleted â€” tagged as `Pruned`)
- **Hausdorff dimension** computed via box-counting on hyperbolic coordinates at scales `[4, 8, 16, 32, 64]`
- Nodes with D < 0.5 or D > 1.9 are pruned automatically; target fractal regime: **1.2 < D < 1.8**
- `LSystemEngine::tick` protocol: Scan -> Hausdorff update -> Rule matching -> Apply mutations -> Report
- **EnergyCircuitBreaker**: cross-system anti-tumor protection â€” depth-aware energy caps, BFS tumor detection, energy dampening, rate limiting. Prevents runaway energy cascades from creating pathological node clusters
- 41+ unit tests across all modules

#### `nietzsche-pregel` â€” Hyperbolic Heat Kernel Diffusion
Multi-scale activation propagation across the hyperbolic graph:
- **Chebyshev polynomial approximation** of the heat kernel `e^(-tL)` â€” O(K x |E|) complexity
- **Hyperbolic graph Laplacian** â€” edge weights derived from Poincare distances
- **Modified Bessel functions** `I_k(t)` for computing Chebyshev coefficients analytically
- Multiple diffusion scales: `t=0.1` activates direct neighbors (focused recall), `t=10.0` activates structurally connected but semantically distant nodes (free association)
- **Valence-modulated Laplacian**: edge weights incorporate emotional valence â€” edges between nodes of matching emotional polarity (both positive or both negative) propagate heat faster (emotional clustering effect)
- `HyperbolicLaplacian` + `apply_heat_kernel` + `chebyshev_coefficients` as stable public API

#### `nietzsche-wiederkehr` â€” DAEMON Agents
Autonomous agents that live inside the database, patrolling the graph and executing actions when conditions are met:
- **DaemonDef** with configurable WHEN conditions, THEN actions, EVERY interval, and ENERGY budget
- **DaemonEngine** tick loop: evaluate conditions, collect intents, decay energy, reap dead daemons
- **Will to Power** priority scheduler: BinaryHeap-based scheduling with energy Ã— urgency weighting
- NQL: `CREATE DAEMON`, `DROP DAEMON`, `SHOW DAEMONS`
- 18 unit tests (store, evaluator, engine, priority)

#### `nietzsche-dream` â€” Dream Queries
Speculative graph exploration via hyperbolic diffusion with stochastic noise:
- **DreamEngine**: BFS exploration from seed node with noise-perturbed energy detection
- Energy spike and curvature anomaly event detection
- Pending/Applied/Rejected dream lifecycle with persistent sessions
- NQL: `DREAM FROM`, `APPLY DREAM`, `REJECT DREAM`, `SHOW DREAMS`
- 8 unit tests (store, engine)

#### `nietzsche-narrative` â€” Narrative Engine
Story arc detection and generation from graph evolution:
- **NarrativeEngine**: scans nodes, computes energy statistics, detects elite emergence and decay events
- Configurable time window, elite/decay thresholds
- JSON and text output formats with auto-generated summaries
- NQL: `NARRATE IN "collection" WINDOW hours FORMAT json|text`
- 4 unit tests

#### Synesthesia (in `nietzsche-sensory`)
Cross-modal projection via hyperbolic parallel transport:
- `translate_modality()`: log_map â†’ modal rotation â†’ exp_map on the Poincare ball
- Preserves hierarchical depth (radius) while changing modality direction
- Quality loss estimation per modality pair
- NQL: `TRANSLATE $node FROM text TO audio`

#### Eternal Return (in `nietzsche-query`)
Temporal queries and counterfactual reasoning:
- `AS OF CYCLE N`: time-travel queries on named snapshots
- `COUNTERFACTUAL SET ... MATCH ...`: what-if queries with ephemeral overlays

#### Collective Unconscious (in `nietzsche-cluster`)
Cross-collection archetype sharing via gossip protocol:
- `ArchetypeRegistry`: DashMap-based registry with merge_peer_archetypes for gossip
- NQL: `SHOW ARCHETYPES`, `SHARE ARCHETYPE $node TO "collection"`
- 4 unit tests

#### `nietzsche-agency` â€” Autonomous Agency Engine
Graph-level autonomous intelligence with counterfactual reasoning and active forgetting:
- **AgencyEngine** tick loop: runs 8 built-in daemons (Entropy, Gap, Coherence, Ltd, Nezhmetdinov + more) + MetaObserver
- **EntropyDaemon**: detects Hausdorff variance spikes across angular regions
- **GapDaemon**: identifies knowledge gaps in depth x angle sectors
- **CoherenceDaemon**: measures multi-scale diffusion overlap (Chebyshev heat kernel)
- **NezhmetdinovDaemon**: Active Forgetting Engine â€” evaluates node vitality V(n) via sigmoid function, applies Triple Condition (vitality + energy + causal), Ricci curvature veto, and emits ForgettingCondemned events for hard deletion
- **Forgetting Module** (15 submodules, 4 Camadas): vitality function, judgment/verdict system, Merkle Tree deletion ledger, Poincare void tracker, TGC calculator, elite drift tracker, anti-gaming monitor, stability monitor, causal immunity, vitality variance health, friction scoring, Zaratustra cycle orchestrator, telemetry writer
- **MetaObserver**: produces HealthReports with energy percentiles, fractal status, wake-up triggers
- **CounterfactualEngine**: what-if simulations via ShadowGraph (remove/add nodes without mutating real graph)
- **AgencyEventBus**: tokio broadcast channel for cross-system event propagation
- **Hegelian Dialectic Engine** (`dialectic.rs`): AGI-2 module â€” detects contradictions between nodes with opposing polarity, creates Tension nodes at embedding midpoints, synthesizes resolutions during sleep by pulling toward center and creating Semantic synthesis nodes. Full detect -> tension -> synthesize pipeline
- **Code-as-Data** (`code_as_data.rs`): AGI-4 module â€” NQL queries stored as activatable graph nodes. When a node's energy exceeds its `activation_threshold` (via heat diffusion / Will-to-Power), the stored query is extracted and can be executed. Includes cooldown, max firings, and exhaustion tracking. Transforms the database into a Turing-complete reactive rule engine
- **Simulate Forgetting** binary: 5000-node x 500-cycle standalone simulation with CSV telemetry
- **Motor de Desejo** (`desire.rs`): Transforms knowledge gaps into structured missions. `DesireSignal` with sector, depth_range, priority, and suggested_query. Priority = 0.4Ã—depth_weight + 0.6Ã—density_weight. Desires above `desire_dream_threshold=0.6` auto-trigger `TriggerDream` intents, creating a closed Desireâ†’Dreamâ†’Generation loop
- **Quantum Fidelity** (`quantum.rs`): Bloch sphere state representation for epistemic confidence. Three thresholds: default (0.85), strict (0.90, safety-critical), relaxed (0.65, exploratory). `BlochState::fidelity()` for quantum state similarity, `trace_distance()` for confidence bounds
- 155 unit tests (event_bus, engine, observer, daemons, shadow, simulator, dialectic, code_as_data, forgetting: 72 tests across all 15 submodules)

#### `nietzsche-agency` â€” TGC: Topological Generative Capacity

The **master health metric** for autonomous cognition. Formally implemented in `forgetting/tgc.rs` with complete mathematical specification:

```
TGC(t) = intensity Ã— mean_quality Ã— (1 + Î±Â·Î”H_s) Ã— (1 + Î²Â·Î”E_g)

Where:
  intensity      = nodes_created / active_nodes
  mean_quality   = mean vitality of generated nodes âˆˆ [0, 1]
  Î”H_s           = structural_entropy(t) - structural_entropy(t-1)   (Shannon degree distribution)
  Î”E_g           = global_efficiency(t) - global_efficiency(t-1)     (Latora-Marchiori, BFS-sampled)
  Î±              = 2.0  (entropy amplifier)
  Î²              = 3.0  (efficiency amplifier, Î²/Î± = 1.5)
```

| Metric | Formula | File |
|---|---|---|
| Structural Entropy (H_s) | `-Î£ p(k)Â·ln(p(k))` | `forgetting/structural_metrics.rs` |
| Global Efficiency (E_g) | `(1/\|S\|Â·(N-1)) Î£ 1/d(s,t)` | `forgetting/structural_metrics.rs` |
| Phase Rupture | `TGC > 1.5` triggers regime alert | `forgetting/tgc.rs` |
| EMA Smoothing | `Î³=0.2, Ï„â‰ˆ4.48 cycles` | `forgetting/tgc.rs` |
| Anti-Gaming | 5 Goodhart violations with 50% penalty | `forgetting/anti_gaming.rs` |
| 3 Pathological Attractors | Elitist / Minimalist / Stationary | `forgetting/stability.rs` |
| Telemetry | 17-field CSV per cycle | `forgetting/telemetry.rs` |

**4-Camada Forgetting Architecture** (Nezhmetdinov Engine):
1. **Camada 1** â€” Local Judgment: `V(n) = Ïƒ(wâ‚e + wâ‚‚H âˆ’ wâ‚ƒÎ¾ + wâ‚„Ï€ + wâ‚…Îº âˆ’ wâ‚†Ï„)` with Triple Condition + Ricci veto + Causal immunity
2. **Camada 2** â€” Deletion Ledger: Merkle Tree cryptographic receipts with inclusion proofs
3. **Camada 3** â€” Generative Metabolism: Void Tracker captures PoincarÃ© coordinates as dream seeds
4. **Camada 4** â€” Global Health: TGC + Var(V) + Elite Drift + Anti-Gaming (4 vital signs)

Full mathematical specification: `docs/articles/NietzscheDB-Topological-Generative-Capacity.md` (8 parts, 7 canonical equations).

#### `nietzsche-rl` â€” Reinforcement Learning Engine
PPO (Proximal Policy Optimization) for autonomous growth strategy selection:
- **PpoEngine**: ONNX-based neural policy inference at runtime
- **4 growth strategies**: `Balanced`, `FavorGrowth`, `FavorPruning`, `Consolidate`
- **State representation** (`GrowthState`): derived from graph health metrics (energy, Hausdorff, gaps, entropy)
- **Reward function**: +1.0 if Hausdorff preserved AND query-speed improves, -1.0 if Hausdorff degrades
- Training: `scripts/models/train_ppo.py` (Actor-Critic architecture with LayerNorm + GELU)
- Export: ONNX model `ppo_growth_v1` for runtime inference

#### `nietzsche-neural` â€” Neural Model Registry
ONNX model lifecycle management for all neural components:
- `ModelRegistry` with `load_model()` / `get_session()` for inference
- Manages PPO, GNN, and Value Network ONNX sessions
- Thread-safe model loading with `Arc<Mutex>`

#### `nietzsche-gnn` â€” Graph Neural Network Engine
GNN inference for topology-aware node evaluation:
- `GnnEngine::predict()`: feeds node features + adjacency to ONNX session
- **Zero-data learning**: Classical heat kernel (Chebyshev) distills knowledge to GNN
- Dual loss: MSE (embeddings) + BCE (node importance classification)
- Integrates with `NeuralThresholdDaemon`: GNN score > 0.7 triggers node protection
- Training: `scripts/models/train_gnn.py`

#### `nietzsche-sleep` â€” Reconsolidation Sleep Cycle
EVA sleeps. During sleep:
1. Sample high-curvature subgraph via random walk
2. Snapshot current embeddings (rollback point)
3. Perturb embeddings in the tangent space (the "dream")
4. Optimize via **RiemannianAdam** on the Poincare manifold
5. Measure Hausdorff dimension before and after
6. **Commit** if `delta(Hausdorff) < threshold` â€” identity preserved, reconsolidation accepted
7. **Rollback** if identity was destroyed â€” dream discarded

This prevents catastrophic forgetting while allowing genuine memory reorganization.

**Time-travel / Versioning:** Named snapshots (`SnapshotRegistry`) allow creating labeled checkpoints of the entire embedding state, listing all snapshots with timestamps, and restoring any previous state â€” enabling temporal queries and safe experimentation.

#### `nietzsche-zaratustra` â€” Autonomous Evolution Engine
Three-phase autonomous cycle inspired by Nietzsche's philosophy:
1. **Will to Power** â€” energy propagation: each node absorbs `alpha x mean(neighbour_energy)`, amplifying high-energy clusters
2. **Eternal Recurrence** â€” temporal echo snapshots: captures periodic state for pattern detection
3. **Ubermensch** â€” elite tier identification: nodes in the top energy fraction are promoted to elite status

Configurable via `ZARATUSTRA_INTERVAL_SECS` (default 600s). Invocable via gRPC `InvokeZaratustra` or automatic background scheduler.

#### `nietzsche-algo` â€” Graph Algorithm Library
Eleven built-in graph algorithms, all available via gRPC and HTTP:

| Algorithm | Type | RPC |
|---|---|---|
| PageRank | Centrality | `RunPageRank` |
| Louvain | Community | `RunLouvain` |
| Label Propagation | Community | `RunLabelProp` |
| Betweenness Centrality | Centrality | `RunBetweenness` |
| Closeness Centrality | Centrality | `RunCloseness` |
| Degree Centrality | Centrality | `RunDegreeCentrality` |
| WCC (Weakly Connected) | Component | `RunWCC` |
| SCC (Strongly Connected) | Component | `RunSCC` |
| A* Pathfinding | Pathfinding | `RunAStar` |
| Triangle Count | Structure | `RunTriangleCount` |
| Jaccard Similarity | Similarity | `RunJaccardSimilarity` |

#### `nietzsche-sensory` â€” Sensory Compression Layer
Multi-modal latent vector storage with progressive degradation:
- Stores latent representations for: **text, audio, image, fused** modalities
- Progressive degradation: `f32 -> f16 -> int8 -> PQ -> gone`
- Original shape metadata preserved for reconstruction
- Encoder version tracking for backward compatibility
- Persisted in RocksDB via graph storage

#### `nietzsche-cluster` â€” Distributed Foundation
Gossip-based cluster discovery and shard routing:
- `ClusterNode` â€” identity, role (primary/replica/coordinator), health
- `ClusterRegistry` â€” gossip-updated peer view
- `ClusterRouter` â€” shard selection
- Eventual consistency via gossip (no Raft in current phase)
- **Semantic CRDTs** (`crdt.rs`): conflict-free replicated data types for graph merge â€” add-wins node/edge sets, max-energy wins for concurrent updates, phantom-add-wins (irreversible), Lamport timestamp ordering. `GraphDelta` struct for gossip transmission with `apply_delta()` merge
- Configurable via `NIETZSCHE_CLUSTER_ENABLED`, `NIETZSCHE_CLUSTER_ROLE`, `NIETZSCHE_CLUSTER_SEEDS`

#### `nietzsche-hnsw-gpu` â€” GPU Vector Backend
NVIDIA cuVS CAGRA acceleration for vector search. See [GPU Acceleration](#gpu-acceleration) section.

#### `nietzsche-tpu` â€” TPU Vector Backend
Google TPU acceleration via PJRT C API. See [TPU Acceleration](#tpu-acceleration) section.

#### `nietzsche-cugraph` â€” GPU Graph Traversal
GPU-accelerated graph algorithms via NVIDIA cuGraph:
- cuGraph BFS/Dijkstra/PageRank on GPU
- Poincare GPU k-NN with custom CUDA kernel
- Dynamic FFI loader for `libcugraph.so` at runtime
- cudarc + NVRTC for Poincare kernel compilation
- Feature flag: `--features cuda`

#### `nietzsche-mcp` â€” Model Context Protocol Server
JSON-RPC 2.0 server for AI assistant integration (Claude, GPT, etc.):
- **19 tools**: graph CRUD, NQL query, KNN search, traversal, graph algorithms, diffusion, stats
- Stdin/stdout transport (standard MCP protocol)
- Parameter validation with typed `ParamValue` (String, Float, Int, Bool, Vector)
- 19 unit tests

#### `nietzsche-metrics` â€” Prometheus/OpenTelemetry Metrics
Observability export layer:
- **NODES_INSERTED**, **EDGES_INSERTED**, **QUERIES_EXECUTED** (CounterVec by collection)
- **QUERY_DURATION_SECONDS**, **KNN_DURATION_SECONDS**, **DIFFUSION_DURATION_SECONDS** (Histogram)
- **NODE_COUNT**, **EDGE_COUNT**, **DAEMON_COUNT**, **DAEMON_ENERGY_TOTAL** (Gauge)
- Singleton `MetricsRegistry` with Prometheus text format export (`/metrics`)
- 6 unit tests

#### `nietzsche-filtered-knn` â€” Filtered KNN with Roaring Bitmaps
Pre-filtered nearest-neighbor search using Roaring Bitmaps:
- **NodeFilter** enum: EnergyRange, NodeType, ContentField, ContentFieldExists, And, Or
- Energy range filter leverages `CF_ENERGY_IDX` for efficient range scans
- JSON dot-path navigation for content field filtering
- Poincare distance computation for multi-manifold KNN
- 15 integration tests

#### `nietzsche-named-vectors` â€” Multi-Vector per Node
Multiple named vector embeddings per node:
- `NamedVector { node_id, name, coordinates, metric }` with VectorMetric (Poincare, Cosine, Euclidean)
- Persisted in CF_META with key `nvec:{node_id}:{name}` (bincode serialization)
- `NamedVectorStore` with put/get/list/delete/delete_all operations
- 8 unit tests

#### `nietzsche-pq` â€” Product Quantization
Magnitude-preserving vector compression (NOT binary quantization â€” preserves hyperbolic depth):
- **Codebook** training via k-means clustering per sub-vector partition
- **PQEncoder** with encode/decode: M sub-vectors Ã— K=256 centroids
- **Asymmetric Distance Computation (ADC)** via precomputed DistanceTable
- KEY: `test_magnitude_preservation` proves PQ preserves `â€–xâ€–` = depth in Poincare ball
- Configurable: `PQConfig { m: 8, k: 256, max_iterations: 25 }`
- 12 unit tests

#### `nietzsche-secondary-idx` â€” Secondary Indexes
Arbitrary JSON field indexing for fast lookups:
- `IndexDef { name, field_path, index_type: String|Float|Int }`
- Persisted in CF_META: definitions at `idx_def:{name}`, entries at `sidx:{name}:{sortable_value}:{node_id}`
- Float encoding: IEEE 754 sign-magnitude to lexicographic order (16 hex chars)
- `SecondaryIndexBuilder` with create_index, drop_index, insert_entry, lookup, range_lookup
- 13 unit tests

#### `nietzsche-kafka` â€” Kafka Connect Sink
Change data capture sink for streaming mutations:
- `GraphMutation` enum: InsertNode, DeleteNode, InsertEdge, DeleteEdge, SetEnergy, SetContent
- `KafkaSink` with process_message/process_batch (BatchResult with succeeded/failed/errors)
- SetContent merges JSON fields into existing node content
- 9 unit tests

#### `nietzsche-table` â€” Relational Table Store (SQLite)
Bridging graph and relational paradigms:
- `TableSchema` with `ColumnDef { name, col_type, nullable, default }`
- Column types: Text, Integer, Float, Bool, Uuid, Json, **NodeRef** (FK to graph nodes)
- `TableStore` wrapping rusqlite::Connection with create/drop/insert/query/delete/list/schema
- Schema metadata persisted in `_nietzsche_table_meta` internal table
- File-backed or in-memory operation modes
- 15 unit tests

#### `nietzsche-media` â€” Media/Blob Store (OpenDAL)
Backend-agnostic media storage for files associated with graph nodes:
- Powered by **Apache OpenDAL** â€” supports local filesystem, S3, GCS, Azure, and more
- `MediaMeta { id, node_id, filename, media_type, content_type, size_bytes, created_at }`
- Media types: Image, Audio, Video, Document, Binary
- `MediaStore` with put/get/get_meta/delete/list_for_node/exists
- Flat key structure: `{node_id}/{media_id}` and `{node_id}/{media_id}.meta`
- 8 unit tests

#### `nietzsche-api` â€” Unified gRPC API
Single endpoint for all NietzscheDB capabilities â€” **71+ RPCs** over a single `NietzscheDB` service, including 6 multi-manifold geometry RPCs (Synthesis, CausalNeighbors, CausalChain, KleinPath, IsOnShortestPath). Every data-plane RPC accepts a `collection` field; empty -> `"default"`.

```protobuf
service NietzscheDB {
  // â”€â”€ Collection management â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc CreateCollection(CreateCollectionRequest)   returns (CreateCollectionResponse);
  rpc DropCollection(DropCollectionRequest)       returns (StatusResponse);
  rpc ListCollections(Empty)                      returns (ListCollectionsResponse);

  // â”€â”€ Graph CRUD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc InsertNode(InsertNodeRequest)     returns (NodeResponse);
  rpc GetNode(NodeIdRequest)            returns (NodeResponse);
  rpc DeleteNode(NodeIdRequest)         returns (StatusResponse);
  rpc UpdateEnergy(UpdateEnergyRequest) returns (StatusResponse);
  rpc InsertEdge(InsertEdgeRequest)     returns (EdgeResponse);
  rpc DeleteEdge(EdgeIdRequest)         returns (StatusResponse);
  rpc MergeNode(MergeNodeRequest)       returns (MergeNodeResponse);
  rpc MergeEdge(MergeEdgeRequest)       returns (MergeEdgeResponse);
  rpc IncrementEdgeMeta(IncrementEdgeMetaRequest) returns (IncrementEdgeMetaResponse);

  // â”€â”€ Batch Operations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc BatchInsertNodes(BatchInsertNodesRequest)   returns (BatchInsertNodesResponse);
  rpc BatchInsertEdges(BatchInsertEdgesRequest)   returns (BatchInsertEdgesResponse);

  // â”€â”€ Query & Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc Query(QueryRequest)               returns (QueryResponse);
  rpc KnnSearch(KnnRequest)             returns (KnnResponse);   // supports metadata filters
  rpc FullTextSearch(FullTextSearchRequest) returns (FullTextSearchResponse);
  rpc HybridSearch(HybridSearchRequest) returns (KnnResponse);

  // â”€â”€ Traversal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc Bfs(TraversalRequest)             returns (TraversalResponse);
  rpc Dijkstra(TraversalRequest)        returns (TraversalResponse);
  rpc Diffuse(DiffusionRequest)         returns (DiffusionResponse);

  // â”€â”€ Graph Algorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc RunPageRank(PageRankRequest)             returns (AlgorithmScoreResponse);
  rpc RunLouvain(LouvainRequest)               returns (AlgorithmCommunityResponse);
  rpc RunLabelProp(LabelPropRequest)           returns (AlgorithmCommunityResponse);
  rpc RunBetweenness(BetweennessRequest)       returns (AlgorithmScoreResponse);
  rpc RunCloseness(ClosenessRequest)           returns (AlgorithmScoreResponse);
  rpc RunDegreeCentrality(DegreeCentralityRequest) returns (AlgorithmScoreResponse);
  rpc RunWCC(WccRequest)                       returns (AlgorithmCommunityResponse);
  rpc RunSCC(SccRequest)                       returns (AlgorithmCommunityResponse);
  rpc RunAStar(AStarRequest)                   returns (AStarResponse);
  rpc RunTriangleCount(TriangleCountRequest)   returns (TriangleCountResponse);
  rpc RunJaccardSimilarity(JaccardRequest)     returns (SimilarityResponse);

  // â”€â”€ Lifecycle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc TriggerSleep(SleepRequest)        returns (SleepResponse);
  rpc InvokeZaratustra(ZaratustraRequest) returns (ZaratustraResponse);

  // â”€â”€ Sensory Compression â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc InsertSensory(InsertSensoryRequest) returns (StatusResponse);
  rpc GetSensory(NodeIdRequest)           returns (SensoryResponse);
  rpc Reconstruct(ReconstructRequest)     returns (ReconstructResponse);
  rpc DegradeSensory(NodeIdRequest)       returns (StatusResponse);

  // â”€â”€ Backup / Restore â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc CreateBackup(CreateBackupRequest)   returns (BackupResponse);
  rpc ListBackups(Empty)                  returns (ListBackupsResponse);
  rpc RestoreBackup(RestoreBackupRequest) returns (StatusResponse);

  // â”€â”€ ListStore â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc ListRPush(ListPushRequest)          returns (ListPushResponse);
  rpc ListLRange(ListRangeRequest)        returns (ListRangeResponse);
  rpc ListLen(ListLenRequest)             returns (ListLenResponse);

  // â”€â”€ Cache (NietzscheDB-compatible) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc CacheSet(CacheSetRequest)           returns (StatusResponse);
  rpc CacheGet(CacheGetRequest)           returns (CacheGetResponse);
  rpc CacheDel(CacheDelRequest)           returns (StatusResponse);
  rpc ReapExpired(ReapExpiredRequest)      returns (ReapExpiredResponse);

  // â”€â”€ Change Data Capture â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc SubscribeCDC(CdcRequest)            returns (stream CdcEvent);

  // â”€â”€ Multi-Manifold Geometry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc Synthesis(SynthesisRequest)                   returns (SynthesisResponse);
  rpc SynthesisMulti(SynthesisMultiRequest)         returns (SynthesisResponse);
  rpc CausalNeighbors(CausalNeighborsRequest)       returns (CausalNeighborsResponse);
  rpc CausalChain(CausalChainRequest)               returns (CausalChainResponse);
  rpc KleinPath(KleinPathRequest)                   returns (KleinPathResponse);
  rpc IsOnShortestPath(ShortestPathCheckRequest)     returns (ShortestPathCheckResponse);

  // â”€â”€ Cluster â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc ExchangeGossip(GossipRequest)       returns (GossipResponse);

  // â”€â”€ Schema Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc SetSchema(SetSchemaRequest)         returns (StatusResponse);
  rpc GetSchema(GetSchemaRequest)         returns (GetSchemaResponse);
  rpc ListSchemas(Empty)                  returns (ListSchemasResponse);

  // â”€â”€ Secondary Indexes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc CreateIndex(CreateIndexRequest)     returns (StatusResponse);
  rpc DropIndex(DropIndexRequest)         returns (StatusResponse);
  rpc ListIndexes(ListIndexesRequest)     returns (ListIndexesResponse);

  // â”€â”€ Admin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rpc GetStats(Empty)                     returns (StatsResponse);
  rpc HealthCheck(Empty)                  returns (StatusResponse);
}
```

#### `nietzsche-sdk` â€” Rust Client SDK
Async gRPC client with seed examples (`seed_100.rs`, `seed_1gb.rs`).

#### `nietzsche-server` â€” Production Binary
Standalone server binary with env-var-based configuration, background sleep and Zaratustra schedulers, TTL reaper, scheduled backup with auto-pruning, RBAC (Admin/Writer/Reader), cluster gossip, embedded HTTP dashboard, and graceful shutdown.

```bash
NIETZSCHE_DATA_DIR=/data/nietzsche \
NIETZSCHE_PORT=50051 \
NIETZSCHE_DASHBOARD_PORT=8080 \
NIETZSCHE_LOG_LEVEL=info \
NIETZSCHE_SLEEP_INTERVAL_SECS=3600 \
ZARATUSTRA_INTERVAL_SECS=600 \
nietzsche-server
```

---

## HTTP Dashboard & REST API

NietzscheDB ships with an embedded **React + Cosmograph 2.1** dashboard, compiled into the binary as a single HTML file. No external web server needed.

### Dashboard Tech Stack

| Component | Version |
|---|---|
| React | 19.2 |
| TypeScript | 5.9 |
| Cosmograph | 2.1 (GPU graph visualization) |
| Vite | 7.2 + vite-plugin-singlefile |
| Tailwind CSS | 4.1 |
| TanStack React Query | 5.90 |
| Radix UI | Component primitives |
| Recharts | 3.7 |

### Dashboard Pages

| Page | Features |
|---|---|
| Overview | Node/edge counts, uptime, version, system config |
| Collections | List, create, inspect collections with dimension/metric |
| Nodes | Browse, insert, delete nodes |
| Graph Explorer | Full Cosmograph 2.1 visualization with timeline, histograms (energy/depth/hausdorff), categorical bars (node_type/edge_type), search, color legend, selection tools |
| Data Explorer | NQL query editor, CRUD forms |
| Settings | Server configuration |

### REST API Endpoints

**Core:**
| Method | Endpoint | Description |
|---|---|---|
| GET | `/api/health` | `{status: "ok"}` |
| GET | `/api/stats` | Node/edge counts, version, uptime |
| GET | `/api/collections` | List all collections |
| GET | `/metrics` | Prometheus metrics |

**Data (CRUD):**
| Method | Endpoint | Description |
|---|---|---|
| GET | `/api/graph?collection=NAME&limit=N` | Nodes + edges for visualization |
| GET | `/api/node/:id` | Get single node |
| POST | `/api/node` | Insert node |
| DELETE | `/api/node/:id` | Delete node |
| POST | `/api/edge` | Insert edge |
| DELETE | `/api/edge/:id` | Delete edge |
| POST | `/api/batch/nodes` | Batch insert nodes |
| POST | `/api/batch/edges` | Batch insert edges |

**Query & Traversal:**
| Method | Endpoint | Description |
|---|---|---|
| POST | `/api/query` | Execute NQL query |
| POST | `/api/sleep` | Trigger sleep cycle |
| GET | `/api/search` | Full-text search |

**Graph Algorithms:**
| Method | Endpoint | Description |
|---|---|---|
| GET | `/api/algo/pagerank` | PageRank centrality |
| GET | `/api/algo/louvain` | Louvain community detection |
| GET | `/api/algo/labelprop` | Label propagation |
| GET | `/api/algo/betweenness` | Betweenness centrality |
| GET | `/api/algo/closeness` | Closeness centrality |
| GET | `/api/algo/degree` | Degree centrality |
| GET | `/api/algo/wcc` | Weakly connected components |
| GET | `/api/algo/scc` | Strongly connected components |
| GET | `/api/algo/triangles` | Triangle count |
| GET | `/api/algo/jaccard` | Jaccard similarity |

**Data Management:**
| Method | Endpoint | Description |
|---|---|---|
| POST | `/api/backup` | Create backup |
| GET | `/api/backup` | List backups |
| GET | `/api/export/nodes` | Export all nodes |
| GET | `/api/export/edges` | Export all edges |

---

## SDKs

### Python
```python
from nietzsche_db import NietzscheClient

db = NietzscheClient("localhost:50051")

# Insert a memory into hyperbolic space (||x|| < 1.0 required)
node_id = db.insert_node(embedding=[0.1, 0.2, 0.3], metadata={"text": "Nietzsche on memory"})

# KNN search
results = db.knn_search(embedding=[0.1, 0.2, 0.3], k=10)

# Run NQL query
results = db.query("MATCH (m:Memory) WHERE m.depth > 0.7 RETURN m LIMIT 5")

# Trigger sleep and reconsolidate
report = db.trigger_sleep(noise=0.02, adam_lr=0.005)
print(f"delta_hausdorff={report.hausdorff_delta:.3f}, committed={report.committed}")
```

### Go (sdk-papa-caolho)
```go
import nietzsche "sdk-papa-caolho"

client, _ := nietzsche.ConnectInsecure("localhost:50052")
defer client.Close()

// Insert node with Poincare embedding
node, _ := client.InsertNode(ctx, nietzsche.InsertNodeOpts{
    Coords:   []float64{0.1, 0.2, 0.3},
    Content:  map[string]string{"text": "first memory"},
    NodeType: "Semantic",
})

// KNN search
results, _ := client.KnnSearch(ctx, []float64{0.1, 0.2, 0.3}, 10, "")

// Graph algorithms
scores, _ := client.RunPageRank(ctx, nietzsche.PageRankOpts{Iterations: 20})

// Trigger sleep
sleep, _ := client.TriggerSleep(ctx, nietzsche.SleepOpts{Noise: 0.02})
fmt.Printf("deltaH=%.3f committed=%v\n", sleep.HausdorffDelta, sleep.Committed)
```

Go SDK covers all 71+ RPCs: collections, nodes, edges, batch operations, query, search, traversal, algorithms, backup, CDC, merge, sensory, indexes, lifecycle, and multi-manifold operations (Synthesis, CausalNeighbors, CausalChain, KleinPath, IsOnShortestPath).

### TypeScript & C++
Located in `sdks/ts/` and `sdks/cpp/`.

---

## Development Roadmap

```
PHASE 0   Foundation & environment          âœ… COMPLETE
PHASE 1   Node and edge model               âœ… COMPLETE
PHASE 2   Graph storage engine              âœ… COMPLETE
PHASE 3   Traversal engine                  âœ… COMPLETE
PHASE 4   NQL query language                âœ… COMPLETE
PHASE 5   L-System engine                   âœ… COMPLETE
PHASE 6   Fractal diffusion / Pregel        âœ… COMPLETE
PHASE 7   ACID transactions on graph        âœ… COMPLETE
PHASE 8   Reconsolidation (sleep cycle)     âœ… COMPLETE
PHASE 9   Public API + SDKs                 âœ… COMPLETE
PHASE 10  Benchmarks, hardening, production âœ… COMPLETE
PHASE 11  Sensory compression layer         âœ… COMPLETE
PHASE Z   Zaratustra evolution engine       âœ… COMPLETE
PHASE A+B Unified gRPC API (71+ RPCs)       âœ… COMPLETE
PHASE D   Merge semantics (upsert)          âœ… COMPLETE
PHASE G   Cluster foundation (gossip)       âœ… COMPLETE
PHASE GPU GPU acceleration (cuVS CAGRA)     âœ… COMPLETE
PHASE TPU TPU acceleration (PJRT)           âœ… COMPLETE

â”€â”€ Production Hardening Roadmap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
P0.1  TTL Reaper (background expiry)       âœ… COMPLETE
P0.2  RBAC (Admin/Writer/Reader roles)     âœ… COMPLETE
P0.3  Backup Hardening (scheduled+prune)   âœ… COMPLETE
P1.4  NQL CREATE / SET / DELETE            âœ… COMPLETE
P1.5  Metadata Secondary Indexes           âœ… COMPLETE
P1.6  Cluster Gossip Wiring                âœ… COMPLETE
P2.7  Encryption at-rest (AES-256-CTR)     âœ… COMPLETE
P2.8  Multi-hop Path NQL (BoundedBFS)      âœ… COMPLETE
P2.9  ListStore (RPUSH/LRANGE/LLEN)        âœ… COMPLETE
P3.10 Query Cost Estimator (EXPLAIN)       âœ… COMPLETE
P3.11 Hybrid BM25+ANN (RRF fusion)         âœ… COMPLETE
P3.12 Schema Validation (per-NodeType)     âœ… COMPLETE

â”€â”€ Consolidation Sprint (2026-02-21) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
C0.1  Bug fixes (5 real bugs)              âœ… COMPLETE
C0.2  Test coverage (+389 new tests)       âœ… COMPLETE
       Sprint 1: +166 (algo, zaratustra, gpu, graph, query, sparse, autotuner, snapshot)
       Sprint 2: +127 (tpu: 28, cugraph: 41, sdk: 28, wasm: 30)
       Sprint 3: +96  (embed: 49, cli: 47) â€” 100% module coverage
C1.1  NQL Time Functions (NOW/INTERVAL)    âœ… COMPLETE
C1.2  ListStore list_del method            âœ… COMPLETE
C2.1  SparseVector type                    âœ… COMPLETE
C2.2  HNSW Auto-tuner (ef_search)          âœ… COMPLETE
C2.3  Named Snapshots (time-travel)        âœ… COMPLETE

â”€â”€ Expansion Sprint (2026-02-21) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
E0.1  MCP Server (AI assistant tools)      âœ… COMPLETE  (19 tools, 19 tests)
E0.2  Prometheus/OTel metrics export       âœ… COMPLETE  (12 metrics, 6 tests)
E0.3  Filtered KNN + Roaring Bitmaps       âœ… COMPLETE  (5 filter types, 15 tests)
E0.4  Named Vectors (multi-vector/node)    âœ… COMPLETE  (3 metrics, 8 tests)
E0.5  Product Quantization (PQ)            âœ… COMPLETE  (magnitude-preserving, 12 tests)
E0.6  Secondary Indexes (arbitrary field)  âœ… COMPLETE  (3 index types, 13 tests)
E0.7  Kafka Connect Sink (CDC)             âœ… COMPLETE  (6 mutation types, 9 tests)
E0.8  Table Store (SQLite)                 âœ… COMPLETE  (7 column types, 15 tests)
E0.9  Media/Blob Store (OpenDAL)           âœ… COMPLETE  (5 media types, 8 tests)
E1.0  Go SDK batch RPCs                    âœ… COMPLETE  (42/42 RPCs)

â”€â”€ NQL 3.0 Sprint (2026-03-01) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NQL-8  OPTIONAL MATCH (left-outer-join)    âœ… COMPLETE
NQL-9  UNION / UNION ALL                   âœ… COMPLETE
NQL-10 CASE WHEN expression               âœ… COMPLETE
NQL-11 IS NULL / IS NOT NULL               âœ… COMPLETE
NQL-12 Regex matching (=~)                 âœ… COMPLETE
NQL-13 EXISTS subquery                     âœ… COMPLETE
NQL-14 UNWIND                              âœ… COMPLETE
NQL-15 SHORTEST_PATH                       âœ… COMPLETE
NQL-16 MATCH ELITES                        âœ… COMPLETE
NQL-17 MEASURE TENSION / MEASURE TGC       âœ… COMPLETE
NQL-18 FIND NEAREST                        âœ… COMPLETE
NQL-19 COLLECT aggregation                 âœ… COMPLETE
NQL-20 30+ built-in functions              âœ… COMPLETE  (string: 11, math: 10, cast: 4, null: 1)
NQL-21 5 physicist cognitive functions      âœ… COMPLETE  (Boltzmann, Helmholtz, Lyapunov, Prigogine, ErdÅ‘s)
NQL-22 Null-safe comparison semantics      âœ… COMPLETE  (SQL-like NULL propagation)

â”€â”€ EVA Compatibility Sprint (2026-02-21) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
A.1   Multi-Metric HNSW fix + DotProduct   âœ… COMPLETE  (Euclidean bug fixed, DotProduct added)
A.2   EmbeddedVectorStore as default       âœ… COMPLETE  (Mock â†’ Embedded, real HNSW by default)
B.2   KNN metadata filter push-down        âœ… COMPLETE  (MetadataFilter â†’ RoaringBitmap pre-filter)
D.1   MergeEdge ON MATCH + edge metadata   âœ… COMPLETE  (update_edge_metadata + WAL entries)
D.2   IncrementEdgeMeta RPC               âœ… COMPLETE  (atomic counter increment on edges)
E.1   Persistent secondary index registry  âœ… COMPLETE  (create/drop/list + backfill + startup load)
E.2   NQL executor index integration       âœ… COMPLETE  (auto O(log N) scan for indexed WHERE)
E.3   Index management gRPC RPCs           âœ… COMPLETE  (CreateIndex/DropIndex/ListIndexes)

â”€â”€ NQL & EVA Compatibility (2026-02-21) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NQL-1 MERGE statement (ON CREATE/ON MATCH)  âœ… COMPLETE  (node + edge MERGE with upsert)
NQL-2 Multi-hop typed path (*1..4)          âœ… COMPLETE  (BFS with depth + label filter)
NQL-3 SET with arithmetic expressions       âœ… COMPLETE  (n.count = n.count + 1, per-node eval)
NQL-4 CREATE with TTL support               âœ… COMPLETE  (ttl property â†’ expires_at auto-compute)
NQL-5 DETACH DELETE                         âœ… COMPLETE  (node + all incident edges)
NQL-6 Edge property access in WHERE/RETURN  âœ… COMPLETE  (edge alias -[r:TYPE]-> with r.field)
NQL-7 ORDER BY on edge properties           âœ… COMPLETE  (r.weight, r.created_at, etc.)
Ph.C  NietzscheDB-compatible cache RPCs           âœ… COMPLETE  (CacheSet/Get/Del + ReapExpired)
Ph.F  Sensory RPCs (fully connected)        âœ… COMPLETE  (insert/get/reconstruct/degrade)
Ph.G  Per-collection RwLock concurrency     âœ… COMPLETE  (DashMap + tokio::sync::RwLock)

â”€â”€ AGI & Advanced Features Sprint (2026-02-22) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AGI-1 EnergyCircuitBreaker (anti-tumor)    âœ… COMPLETE  (depth caps, BFS tumor detection, dampening)
AGI-2 Hegelian Dialectic Engine            âœ… COMPLETE  (contradictionâ†’tensionâ†’synthesis pipeline)
AGI-3 Semantic CRDTs (cluster merge)       âœ… COMPLETE  (add-wins, max-energy, phantom-add-wins)
AGI-4 Code-as-Data (NQL-as-node)           âœ… COMPLETE  (activatable queries, cooldown, exhaustion)
AGI-5 SchrÃ¶dinger Edges                    âœ… COMPLETE  (probabilistic collapse, decay, reinforce)
AGI-6 Valence/Arousal (emotional vectors)  âœ… COMPLETE  (diffusion modulation, Laplacian weighting)

â”€â”€ Multi-Manifold Sprint (2026-02-22) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MM-1  Klein model (pathfinding)            âœ… COMPLETE  (to_klein, to_poincare, colinearity O(1), 10 tests)
MM-2  Riemann sphere (synthesis)           âœ… COMPLETE  (synthesis, synthesis_multi, FrÃ©chet mean, 10 tests)
MM-3  Minkowski spacetime (causality)      âœ… COMPLETE  (dsÂ², classify, light_cone_filter, 8 tests)
MM-4  Manifold normalization layer         âœ… COMPLETE  (health checks, safe roundtrips, 10x error < 1e-4)
MM-5  Edge causality metadata              âœ… COMPLETE  (CausalType enum, minkowski_interval on Edge)
MM-6  6 new gRPC RPCs                      âœ… COMPLETE  (Synthesis, SynthesisMulti, CausalNeighbors, CausalChain, KleinPath, IsOnShortestPath)
MM-7  Go SDK manifold methods              âœ… COMPLETE  (6 methods + types + proto sync)

â”€â”€ Neural & RL Stack (2026-02-24) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NRL-1  PPO Engine (ONNX inference)          âœ… COMPLETE  (4 strategies, GrowthState, GrowthAction)
NRL-2  Neural Model Registry                âœ… COMPLETE  (load/get ONNX sessions, thread-safe)
NRL-3  GNN Engine (node importance)         âœ… COMPLETE  (predict, dual loss, zero-data distillation)
NRL-4  Training scripts (Python)            âœ… COMPLETE  (train_ppo.py, train_gnn.py, train_value_network.py)

â”€â”€ Nezhmetdinov Forgetting Engine (2026-02-24) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NZH-1  Vitality sigmoid function           âœ… COMPLETE  (V(n) = Ïƒ(wâ‚e+wâ‚‚H-wâ‚ƒÎ¾+wâ‚„Ï€+wâ‚…Îº-wâ‚†Ï„), batch, 8 tests)
NZH-2  Judgment/Verdict system             âœ… COMPLETE  (5 verdicts, MikhailThallReport, 6 tests)
NZH-3  HardBounds + NezhmetdinovConfig     âœ… COMPLETE  (immutable bounds, from_env, enforce, 7 tests)
NZH-4  Ricci curvature shield              âœ… COMPLETE  (degree-variance proxy, quick_veto, simulate, 5 tests)
NZH-5  Causal immunity (Minkowski)         âœ… COMPLETE  (timelike/lightlike/spacelike classify, 4 tests)
NZH-6  Deletion ledger (Merkle Tree)       âœ… COMPLETE  (receipts, root, inclusion proofs, 6 tests)
NZH-7  Void tracker (PoincarÃ© seeds)       âœ… COMPLETE  (coordinate capture, plausibility, capacity, 5 tests)
NZH-8  TGC calculator                      âœ… COMPLETE  (EMA smoothing, declining detection, 5 tests)
NZH-9  Elite drift tracker                 âœ… COMPLETE  (centroid tracking, drift threshold, 4 tests)
NZH-10 Anti-gaming (Goodhart)              âœ… COMPLETE  (5 violation types, 50% penalty, 5 tests)
NZH-11 Stability monitor                   âœ… COMPLETE  (3 collapses: elitist/minimalist/stationary, 5 tests)
NZH-12 Vitality variance health            âœ… COMPLETE  (4 classes: diverse/mono/chaotic/exhausted, 4 tests)
NZH-13 Friction calculator                 âœ… COMPLETE  (per-cycle friction scoring, 3 tests)
NZH-14 Zaratustra cycle orchestrator       âœ… COMPLETE  (master 4-Camada orchestration, 5 tests)
NZH-15 Telemetry writer (CSV)              âœ… COMPLETE  (format_cycle_summary, CycleTelemetry, 3 tests)
NZH-16 NezhmetdinovDaemon                  âœ… COMPLETE  (AgencyDaemon trait, full pipeline, 3 tests)
NZH-17 Reactor integration                 âœ… COMPLETE  (HardDelete + RecordDeletion intents)
NZH-18 Simulation binary                   âœ… COMPLETE  (5000 nodes Ã— 500 cycles, CSV output)
       Total: 18 new files, 15 submodules, 72 forgetting tests, 155 total agency tests
```

---

## Benchmarks

Run all benchmarks:
```bash
cargo bench --workspace
```

Individual suites:

| Suite | Command |
|---|---|
| Graph engine | `cargo bench -p nietzsche-graph` |
| Riemannian ops | `cargo bench -p nietzsche-sleep` |
| Chebyshev / diffusion | `cargo bench -p nietzsche-pregel` |
| Hyperbolic math | `cargo bench -p nietzsche-hyp-ops` |
| Distance metrics | `cargo bench -p nietzsche-core` |

### Representative results (ring graph, Apple M2)

| Benchmark | N | Time |
|---|---|---|
| `graph/insert_node` | 1 | ~18 us |
| `graph/insert_node_batch` | 100 | ~1.4 ms |
| `graph/scan_nodes` | 500 | ~3.8 ms |
| `graph/bfs` | chain-50 | ~52 us |
| `graph/dijkstra` | chain-50 | ~81 us |
| `riemannian/exp_map` | dim=256 | ~420 ns |
| `riemannian/adam_10_steps` | dim=64 | ~6.2 us |
| `chebyshev/apply_heat_kernel` | ring-40 | ~210 us |
| `chebyshev/laplacian_build` | ring-50 | ~390 us |

### Hyperbolic Math Benchmarks (`nietzsche-hyp-ops`)

| Benchmark | Dimension | Operations |
|---|---|---|
| `exp_map_zero` | 64d, 256d | Euclidean â†’ PoincarÃ© projection |
| `log_map_zero` | 64d | PoincarÃ© â†’ tangent space |
| `mobius_add` | 64d | Gyrovector addition |
| `poincare_distance` | 64d | Hyperbolic geodesic distance |
| `gyromidpoint` | 3Ã—256d | FrÃ©chet mean (multimodal fusion) |

### Cognitive Simulation: Forgetting Engine

Standalone binary `simulate_forgetting` runs a full 4-Camada Zaratustra cycle at scale:

| Parameter | Value |
|---|---|
| **Nodes** | 10,000 (1,000 signal + 9,000 noise) |
| **Edges** | ~50,000 undirected |
| **Cycles** | 100+ accelerated |
| **Metrics per cycle** | TGC (raw + EMA), H_s, E_g, Var(V), elite drift, deletion rate |
| **Output** | CSV telemetry with all 4 vital signs |
| **Validation** | Zero false positives (no signal nodes killed), noise converges to zero |

Three telemetry profiles: `D_foam` (void-born orphans), `E_anchored` (elite-parented), `F_dialectical` (elite + entropy polarization).

### Test Coverage

| Module | Tests | Key areas |
|---|---|---|
| `nietzsche-agency` | 155 | Event bus, 8 daemons, observer, reactor, desire, identity, counterfactual, dialectic, code-as-data |
| `nietzsche-agency/forgetting` | 72 | Vitality, judgment, bounds, Ricci, causal immunity, ledger, TGC, elite drift, anti-gaming, stability, variance, friction, Zaratustra cycle |
| `nietzsche-hyp-ops` | 40+ | All 4 geometries, manifold roundtrips, synthesis, Minkowski causality |
| `nietzsche-query` | 113+ | NQL parser, executor, all statement types (NQL 3.0: OPTIONAL MATCH, UNION, CASE WHEN, IS NULL, regex, EXISTS, 30+ functions) |
| `nietzsche-graph` | 50+ | Storage, traversal, merge, fulltext, schrodinger |
| **Total workspace** | 800+ | All 41 crates with unit + integration tests |

### Cross-Database Benchmark Suite (`benchmarks/`)

Modular plugin-based runner comparing NietzscheDB against Milvus, NietzscheDB, and ChromaDB:
- Throughput (Insert/Search QPS), Latency (P50/P95/P99)
- Recall@10, MRR@10, NDCG@10
- System Recall@10 (vs exact brute-force)
- Concurrency profile (C1/C10/C30)

---

## Production Deployment

### Docker Compose (recommended)

```yaml
# docker-compose.yaml
services:
  nietzsche:
    build: .
    ports:
      - "50052:50051"   # gRPC
      - "8080:8080"     # HTTP dashboard
    environment:
      NIETZSCHE_DATA_DIR:            /data/nietzsche
      NIETZSCHE_PORT:                "50051"
      NIETZSCHE_DASHBOARD_PORT:      "8080"
      NIETZSCHE_SLEEP_INTERVAL_SECS: "300"
      ZARATUSTRA_INTERVAL_SECS:      "600"
    volumes:
      - nietzsche_data:/data/nietzsche

  nietzsche:
    build:
      context: .
      dockerfile: deploy/docker/Dockerfile
    ports:
      - "50051:50051"
      - "50050:50050"
    environment:
      NIETZSCHE_ADDR: http://nietzsche:50052
    depends_on:
      - nietzsche
    volumes:
      - nietzsche_data:/data/nietzsche

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
```

### Docker (standalone)

```bash
# Build
docker build -t nietzsche-db:latest .

# Run
docker run -d \
  -p 50051:50051 \
  -p 8080:8080 \
  -v /data/nietzsche:/data/nietzsche \
  -e NIETZSCHE_LOG_LEVEL=info \
  -e NIETZSCHE_SLEEP_INTERVAL_SECS=300 \
  -e NIETZSCHE_DASHBOARD_PORT=8080 \
  --name nietzsche-db \
  nietzsche-db:latest
```

### Environment Variables

| Variable | Default | Description |
|---|---|---|
| `NIETZSCHE_DATA_DIR` | `/data/nietzsche` | RocksDB + WAL + collections root |
| `NIETZSCHE_PORT` | `50051` | gRPC listen port |
| `NIETZSCHE_DASHBOARD_PORT` | `8080` | HTTP dashboard port (0 = disabled) |
| `NIETZSCHE_LOG_LEVEL` | `info` | Tracing filter (`trace`, `debug`, `info`, `warn`, `error`) |
| `NIETZSCHE_SLEEP_INTERVAL_SECS` | `0` | Sleep cycle interval in seconds (0 = disabled) |
| `NIETZSCHE_SLEEP_NOISE` | `0.02` | Tangent-space perturbation magnitude |
| `NIETZSCHE_SLEEP_ADAM_STEPS` | `10` | RiemannianAdam steps per sleep cycle |
| `NIETZSCHE_HAUSDORFF_THRESHOLD` | `0.15` | Max delta-hausdorff before rollback |
| `NIETZSCHE_MAX_CONNECTIONS` | `1024` | Maximum concurrent gRPC connections |
| `NIETZSCHE_VECTOR_BACKEND` | `embedded` | `embedded` (HNSW), `gpu`, `tpu`, or empty (mock) |
| `NIETZSCHE_API_KEY` | â€” | Admin auth token for gRPC (backward compat) |
| `NIETZSCHE_API_KEY_ADMIN` | â€” | Admin role API key |
| `NIETZSCHE_API_KEY_WRITER` | â€” | Writer role API key (read + mutate) |
| `NIETZSCHE_API_KEY_READER` | â€” | Reader role API key (read only) |
| `NIETZSCHE_ENCRYPTION_KEY` | â€” | Base64-encoded 32-byte AES master key (empty = disabled) |
| `NIETZSCHE_TTL_REAPER_INTERVAL_SECS` | `60` | TTL reaper scan interval (0 = disabled) |
| `NIETZSCHE_BACKUP_INTERVAL_SECS` | `0` | Automatic backup interval (0 = disabled) |
| `NIETZSCHE_BACKUP_RETENTION_COUNT` | `5` | Max backups to keep (older ones pruned) |
| `NIETZSCHE_INDEXED_FIELDS` | â€” | CSV of metadata fields to index (e.g. `created_at,category`) |
| `ZARATUSTRA_INTERVAL_SECS` | `600` | Zaratustra cycle interval (0 = disabled) |
| `NIETZSCHE_CLUSTER_ENABLED` | `false` | Enable cluster mode |
| `NIETZSCHE_CLUSTER_NODE_NAME` | `nietzsche-0` | Human-readable node name |
| `NIETZSCHE_CLUSTER_ROLE` | `primary` | `primary`, `replica`, or `coordinator` |
| `NIETZSCHE_CLUSTER_SEEDS` | â€” | Comma-separated seed peer addresses |
| `PJRT_PLUGIN_PATH` | â€” | Path to `libtpu.so` for TPU backend |

### Health Check

```bash
# gRPC health (requires grpcurl)
grpcurl -plaintext localhost:50051 nietzsche.NietzscheDB/HealthCheck

# HTTP dashboard health
curl http://localhost:8080/api/health

# List all collections
curl http://localhost:8080/api/collections

# Graph data for visualization
curl "http://localhost:8080/api/graph?collection=eva_core&limit=500"
```

### CI / CD

**`.github/workflows/ci.yml`** â€” runs on every PR:

| Job | What it does |
|---|---|
| `lint` | `cargo fmt --check` + `cargo clippy -D warnings` |
| `test` | `cargo test --workspace --all-features` (requires `protoc` + `libclang`) |
| `bench-dry-run` | `cargo bench --no-run --workspace` (compile check) |
| `docker` | `docker build` (validates Dockerfile; no push on PRs) |

**`.github/workflows/deploy-gcp.yml`** â€” runs on push to `main`:

| Job | What it does |
|---|---|
| `build-and-push` | Builds Docker image, pushes to GCP Artifact Registry via WIF |
| `deploy` | SSH into GCP VM via OS Login, runs `docker compose up -d` |
| Health check | Verifies `GET /api/health` returns 200 |

---

## GPU Acceleration

NietzscheDB supports GPU-accelerated vector search via **NVIDIA cuVS CAGRA** and GPU graph traversal via **NVIDIA cuGraph**.

### Vector Search â€” `nietzsche-hnsw-gpu`

```
Insert â†’ CPU staging buffer (Vec<f32>)
               â”‚
               â”œâ”€â”€ n < 1,000 vectors  â†’ CPU linear scan
               â””â”€â”€ n >= 1,000 vectors â†’ CAGRA build on GPU (lazy, on first knn)
                                         â””â”€â”€ GPU search â†’ results back to CPU
```

- Lazy CAGRA index build: only constructs GPU index when first k-NN query arrives
- Dirty ratio rebuild: reconstructs when >= 10% of index modified
- Automatic fallback to CPU if GPU fails

### Graph Traversal â€” `nietzsche-cugraph`

- GPU-accelerated BFS, Dijkstra, PageRank via cuGraph FFI
- Custom CUDA kernel for Poincare distance computation (compiled via NVRTC)
- Dynamic `libcugraph.so` loading at runtime

### Build (GCP / Linux)

```bash
# 1. CUDA Toolkit 12.x + cuVS 24.6
apt-get install -y clang libclang-dev

# 2. Build with GPU support
cargo build --release --features gpu

# 3. Run with GPU backend
NIETZSCHE_VECTOR_BACKEND=gpu ./target/release/nietzsche-server
```

### Docker (GPU)

```dockerfile
# Dockerfile.gpu
FROM nvidia/cuda:12.4-devel-ubuntu22.04 AS builder
RUN apt-get update && apt-get install -y clang libclang-dev curl
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --default-toolchain nightly
COPY . .
RUN cargo build --release --features gpu

FROM nvidia/cuda:12.4-runtime-ubuntu22.04
COPY --from=builder /target/release/nietzsche-server /usr/local/bin/
EXPOSE 50051 8080
CMD ["nietzsche-server"]
```

```yaml
# docker-compose.gpu.yml
services:
  nietzsche-server:
    image: nietzsche-server:gpu
    runtime: nvidia
    environment:
      NIETZSCHE_VECTOR_BACKEND: gpu
      NIETZSCHE_DATA_DIR: /data/nietzsche
    ports:
      - "50051:50051"
      - "8080:8080"
    volumes:
      - nietzsche_data:/data/nietzsche
```

### GCP GPU Instance Recommendation

| Instance | GPU | VRAM | Best for |
|---|---|---|---|
| `g2-standard-4` | L4 | 24 GB | Production â€” best price/perf |
| `n1-standard-4` + T4 | T4 | 16 GB | Budget option |
| `a2-highgpu-1g` | A100 | 40 GB | Large-scale datasets |

### Feature Flags

```toml
# nietzsche-server/Cargo.toml
[features]
gpu = ["dep:nietzsche-hnsw-gpu"]   # enables GPU injection in main.rs

# nietzsche-hnsw-gpu/Cargo.toml
[features]
cuda = ["dep:cuvs", "dep:ndarray"] # enables actual CUDA calls
```

---

## TPU Acceleration

NietzscheDB supports Google **TPU**-accelerated vector search via the **PJRT C API**, targeting Cloud TPU VMs (v5e, v6e Trillium, v7 Ironwood).

### Architecture

```
Insert â†’ CPU staging buffer (Vec<f32>)
               â”‚
               â”œâ”€â”€ n < 1,000 vectors  â†’ CPU linear scan
               â””â”€â”€ n >= 1,000 vectors â†’ lazy MHLO compile (once)
                                         â”œâ”€â”€ upload %query  â†’ TPU
                                         â”œâ”€â”€ upload %matrix â†’ TPU
                                         â”œâ”€â”€ execute MHLO kernel
                                         â””â”€â”€ CPU: L2 norm correction
```

### Hardware Targets

| TPU | Generation | HBM |
|---|---|---|
| v5e | 5th gen | 16 GB/chip |
| v6e | Trillium | 32 GB/chip |
| v7 | **Ironwood** | **192 GB/chip** |

### Build (Cloud TPU VM)

```bash
PJRT_PLUGIN_PATH=/lib/libtpu.so \
cargo build --release --features tpu

PJRT_PLUGIN_PATH=/lib/libtpu.so \
NIETZSCHE_VECTOR_BACKEND=tpu \
./target/release/nietzsche-server
```

### Feature Flags

```toml
# nietzsche-server/Cargo.toml
[features]
tpu = ["dep:nietzsche-tpu", "nietzsche-tpu/tpu"]

# nietzsche-tpu/Cargo.toml
[features]
tpu = ["dep:pjrt"]
```

### GPU vs TPU

| Feature | GPU (cuVS CAGRA) | TPU (PJRT MHLO) |
|---|---|---|
| Index type | ANN graph (HNSW-like) | Exact dot-product batch |
| Best for | Ultra-low latency, single query | High throughput, large batch |
| Memory | GPU VRAM (CUDA managed) | TPU HBM (192 GB on Ironwood) |
| Cloud | GCP GPU instances | GCP Cloud TPU VMs |
| Feature flag | `--features gpu` | `--features tpu` |
| Env var | `NIETZSCHE_VECTOR_BACKEND=gpu` | `NIETZSCHE_VECTOR_BACKEND=tpu` |

CPU-only build (default) compiles and runs correctly â€” GPU/TPU paths simply not activated.

---

## Codebase Structure

```
NietzscheDB/
â”œâ”€â”€ Cargo.toml                â† unified Rust workspace (41 crates)
â”œâ”€â”€ rust-toolchain.toml       â† nightly channel
â”œâ”€â”€ Dockerfile                â† multi-stage production image
â”œâ”€â”€ docker-compose.yaml       â† nietzsche + nietzsche + prometheus + grafana
â”œâ”€â”€ .github/workflows/        â† CI + deploy pipelines
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ nietzsche-core/      â† Poincare HNSW, distance metrics, SIMD
â”‚   â”œâ”€â”€ nietzsche-vecstore/     â† mmap segments, WAL v3
â”‚   â”œâ”€â”€ nietzsche-hnsw/     â† HNSW graph, ArcSwap lock-free updates
â”‚   â”œâ”€â”€ nietzsche-baseserver/    â† gRPC server, multi-tenancy, replication
â”‚   â”œâ”€â”€ nietzsche-proto/     â† protobuf definitions
â”‚   â”œâ”€â”€ nietzsche-cli/       â† CLI tools (ratatui TUI)
â”‚   â”œâ”€â”€ nietzsche-embed/     â† ONNX + remote embedding
â”‚   â”œâ”€â”€ nietzsche-wasm/      â† WASM / browser / IndexedDB
â”‚   â”œâ”€â”€ nietzsche-rsdk/       â† NietzscheDB Rust client
â”‚   â”œâ”€â”€ nietzsche-graph/      â† multi-manifold graph engine     [Phases 1-3]
â”‚   â”œâ”€â”€ nietzsche-hyp-ops/    â† multi-manifold geometry (PoincarÃ©Â·KleinÂ·RiemannÂ·Minkowski)
â”‚   â”œâ”€â”€ nietzsche-query/      â† NQL parser + executor           [Phase 4]
â”‚   â”œâ”€â”€ nietzsche-lsystem/    â† L-System + Hausdorff pruning    [Phase 5]
â”‚   â”œâ”€â”€ nietzsche-pregel/     â† heat kernel diffusion           [Phase 6]
â”‚   â”œâ”€â”€ nietzsche-sleep/      â† sleep/reconsolidation cycle     [Phase 8]
â”‚   â”œâ”€â”€ nietzsche-zaratustra/ â† autonomous evolution engine     [Phase Z]
â”‚   â”œâ”€â”€ nietzsche-algo/       â† 11 graph algorithms
â”‚   â”œâ”€â”€ nietzsche-sensory/    â† sensory compression layer       [Phase 11]
â”‚   â”œâ”€â”€ nietzsche-cluster/    â† gossip cluster foundation       [Phase G]
â”‚   â”œâ”€â”€ nietzsche-wiederkehr/ â† DAEMON agents + Will to Power scheduler
â”‚   â”œâ”€â”€ nietzsche-dream/      â† dream queries (speculative exploration)
â”‚   â”œâ”€â”€ nietzsche-narrative/  â† narrative engine (story arc detection)
â”‚   â”œâ”€â”€ nietzsche-agency/     â† autonomous agency + counterfactual engine + TGC
â”‚   â”œâ”€â”€ nietzsche-rl/         â† PPO reinforcement learning (ONNX inference)
â”‚   â”œâ”€â”€ nietzsche-neural/     â† neural model registry (ONNX lifecycle)
â”‚   â”œâ”€â”€ nietzsche-gnn/        â† graph neural network engine
â”‚   â”œâ”€â”€ nietzsche-mcp/        â† MCP server for AI assistants (19 tools)
â”‚   â”œâ”€â”€ nietzsche-metrics/    â† Prometheus/OpenTelemetry metrics export
â”‚   â”œâ”€â”€ nietzsche-filtered-knn/ â† filtered KNN with Roaring Bitmaps
â”‚   â”œâ”€â”€ nietzsche-named-vectors/ â† multi-vector per node
â”‚   â”œâ”€â”€ nietzsche-pq/         â† Product Quantization (magnitude-preserving)
â”‚   â”œâ”€â”€ nietzsche-secondary-idx/ â† secondary indexes by arbitrary field
â”‚   â”œâ”€â”€ nietzsche-kafka/      â† Kafka Connect sink (CDC streaming)
â”‚   â”œâ”€â”€ nietzsche-table/      â† relational table store (SQLite)
â”‚   â”œâ”€â”€ nietzsche-media/      â† media/blob store (OpenDAL: S3, GCS, local)
â”‚   â”œâ”€â”€ nietzsche-api/        â† unified gRPC API (71+ RPCs)
â”‚   â”œâ”€â”€ nietzsche-sdk/        â† Rust client SDK
â”‚   â”œâ”€â”€ nietzsche-server/     â† production binary + dashboard
â”‚   â”œâ”€â”€ nietzsche-hnsw-gpu/   â† GPU vector search (cuVS CAGRA)
â”‚   â”œâ”€â”€ nietzsche-tpu/        â† TPU vector search (PJRT)
â”‚   â””â”€â”€ nietzsche-cugraph/    â† GPU graph traversal (cuGraph)
â”œâ”€â”€ dashboard/                â† React 19 + Cosmograph 2.1 + Tailwind 4
â”‚   â”œâ”€â”€ src/pages/            â† Overview, Collections, Nodes, Graph, Data, Settings
â”‚   â””â”€â”€ dist/                 â† single-file HTML (embedded in binary)
â”œâ”€â”€ sdks/
â”‚   â”œâ”€â”€ go/                   â† sdk-papa-caolho (71+ RPCs, full coverage)
â”‚   â”œâ”€â”€ python/               â† gRPC client + proto generation
â”‚   â”œâ”€â”€ ts/                   â† TypeScript SDK
â”‚   â””â”€â”€ cpp/                  â† C++ SDK
â”œâ”€â”€ scripts/                  â† benchmark, build-dashboard, build-wasm, verify
â”œâ”€â”€ benchmarks/               â† reproducible benchmark suite
â”œâ”€â”€ integrations/             â† LangChain Python + JS, LlamaIndex
â”œâ”€â”€ deploy/                   â† Docker, Kubernetes, WIF setup
â”œâ”€â”€ docs/                     â† NQL reference, architecture
â””â”€â”€ examples/                 â† HiveMind Tauri app, Python, TypeScript
```

---

## Build Profiles

```toml
# Release (production)
[profile.release]
lto = true
codegen-units = 1
strip = true
panic = "abort"
opt-level = 3

# Bench-fast (CI benchmarks)
[profile.bench-fast]
inherits = "release"
lto = "thin"
codegen-units = 4

# Perf (maximum native CPU optimization)
[profile.perf]
inherits = "release"
# RUSTFLAGS="-C target-cpu=native"
```

---

## Research Context: The Non-Euclidean Revolution

NietzscheDB closes gaps that no existing database fills. It is built on the realization that **Intelligence is not flat**.

- **Multi-Manifold Native**: While every other vector database (NietzscheDB, Milvus, Pinecone) uses Euclidean or Cosine distance as a flat metric, NietzscheDB operates across 4 non-Euclidean geometries: PoincarÃ© (Hierarchy), Klein (Straight-line Logic), Riemann (Synthesis), and Minkowski (Causality).
- **The Visual Audit Gap**: Traditional databases are black boxes. NietzscheDB integrates **Perspektive.js** as its Visual Cortex, allowing humans to physically see the database manifolds and audit decision-making via the Causal Scrubber.
- **Autonomous Metabolism**: NietzscheDB implements a formal **Sleep/Reconsolidation Cycle**. It doesn't just store data; it organizes it during downtime using Riemannian optimization and Hausdorff identity verification.
- **Dialectical Reasoning**: The built-in **Hegelian Dialectic Engine** allows the database to resolve contradictions by synthesizing opposites into abstract "synthesis" nodes.
- **Emotional Physics**: Valence and arousal fields on nodes alter heat diffusion propagation. Knowledge that "matters" (high arousal) spreads faster through the memory, mirroring biological cognitive priority.

---

## ğŸ”— LLM Integration Ecosystem

NietzscheDB provides a multi-layer integration stack for external AI models:

### Model Context Protocol (MCP)
AI assistants (Claude, GPT, Cursor, Windsurf) interact with NietzscheDB as a discoverable tool via JSON-RPC 2.0 (`nietzsche-mcp`). 19 tools exposed: graph CRUD, NQL query, KNN search, traversal, algorithms, diffusion, stats.

### Framework Integrations

| Framework | Module | Capabilities |
|---|---|---|
| **LangChain** | `sdks/python/nietzschedb/langchain.py` | `NietzscheVectorStore` â€” full VectorStore interface, `similarity_search_with_score()`, RAG pipelines with GPT-4/Claude |
| **LangGraph** | `sdks/python/nietzschedb/langgraph.py` | `NietzscheCheckpointer` â€” persistent agent state, thread-based conversation history. `NietzscheMemoryStore` â€” long-term agent memory with TTL and namespace isolation |
| **DSPy** | `sdks/python/nietzschedb/dspy.py` | `NietzscheRM` â€” hybrid BM25 + vector KNN retrieval module |
| **LlamaIndex** | `integrations/` | Vector store integration |

### Embedding Providers

| Provider | Class | Model |
|---|---|---|
| OpenAI | `OpenAIEmbedder` | text-embedding-3-small |
| Cohere | `CohereEmbedder` | embed-english-v3.0 |
| Voyage AI | `VoyageEmbedder` | voyage models |
| Google | `GoogleEmbedder` | Gemini embedding |
| HuggingFace | `SentenceTransformerEmbedder` | BAAI/bge-m3 (local) |
| OpenRouter | `OpenRouterEmbedder` | OpenAI-compatible API |

### Code-as-Data (NQL as Executable LLM Output)
LLM-generated NQL queries can be stored as `ActionNode` graph nodes. When a node's energy exceeds its `activation_threshold` (via heat diffusion / Will-to-Power), the stored query auto-executes. This transforms the database into a reactive rule engine where LLMs teach the graph autonomous behaviors.

### Adaptive Learning Pipeline
```
Health Metrics â†’ PPO Policy (ONNX) â†’ Growth Strategy â†’ Evolution â†’ Parameter Adjustment
         â†‘                                                              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Feedback Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Inference at runtime**: Pre-trained PPO and GNN models run via ONNX for real-time decisions
- **Offline training**: `scripts/models/train_ppo.py`, `train_gnn.py`, `train_value_network.py`
- **15 adaptive mechanisms**: RiemannianAdam, PPO, GNN, AutoTuner, adaptive thresholds, L-System evolution, Will-to-Power, neural threshold daemon, dream engine, reactor, evolution daemon, LTD, thermal perturbation, sensory consolidation, MCTS-based energy boost

### Key References & Inspiration
- **Hyperbolic Geometry of Complex Networks** (Krioukov et al., 2010)
- **Hyperbolic Neural Networks** (Ganea et al., NeurIPS 2018)
- **Riemannian Adaptive Optimization** (Becigneul & Ganea, ICLR 2019)
- **Beyond Euclidean Embeddings** â€” The foundation of Nietzsche's *Perspectivism* as a computational paradigm.

---

## Git Remotes

```bash
origin    https://github.com/JoseRFJuniorLLMs/NietzscheDB.git   # NietzscheDB Manifesto repo
upstream  https://github.com/YARlabs/nietzsche-db.git          # Upstream HNSW foundation
```

---

## License

NietzscheDB is licensed under the **AGPL-3.0**.  
Developed as the memory core for the **EVA AGI System**.

---

<p align="center">
  <img src="img/logo.jpg" alt="NietzscheDB" width="120px" /><br>
  <em>"He who has a why to live can bear almost any how."</em><br>
  â€” <strong>Friedrich Nietzsche</strong>
</p>

<p align="center">
  <strong>Retina of the AGI</strong> Â· Powered by <strong>Rust nightly</strong> Â· <strong>Perspektive.js 0.1.3</strong> Â· <strong>4 Manifolds</strong> Â· <strong>MCP + gRPC</strong> Â· <strong>GPU/TPU</strong> Â· <strong>Hegelian Engine</strong>
</p>
